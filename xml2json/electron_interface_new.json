[
    {
        "id": "api_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n      This method takes effect only when you are a host in a live streaming channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the\n                ongoing live broadcast. This applies to scenarios where all users in the channel can\n                watch a live show and interact with each other. After calling this method, the SDK\n                triggers the STREAM_INJECT_STATUS callback on the local client to\n                report the state of injecting the online media stream; after successfully injecting\n                the media stream, the stream joins the channel, and all users in the channel receive\n                the USER_JOINED callback, where uid is\n                    666.",
        "parameters": [
            {
                "url": "\n      The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: InjectStreamConfig."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n      ERR_INVALID_ARGUMENT (-2): The injected URL does not exist. Call this method again to inject the stream and ensure that the URL is valid.\n      ERR_NOT_READY (-3): The user is not in the channel.\n      ERR_NOT_SUPPORTED (-4): The channel is not a live streaming channel. Call\n                                setChannelProfile and set the channel profile to\n                            live streaming before calling this method.\n      ERR_NOT_INITIALIZED (-7): The SDK is not initialized. Ensure that the AgoraRtcEngine object is initialized before using this method."
    },
    {
        "id": "api_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.After calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the RTMP_STREAMING_STATE_CHANGED callback on the local client to report the state of adding a local stream to the CDN.\n   \n       \n  Call this method after joining a channel.\n  Ensure that you enable the RTMP Converter service before using this function. See\n                        Prerequisites in Push Streams to\n                            CDN.\n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "\n      Whether to enable transcoding. Transcoding in a CDN live streaming converts the audio and\n                            video streams before pushing them to the CDN server. It applies to\n                            scenarios where a channel has multiple broadcasters and composite layout\n                            is needed.\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true , ensure that you call the setLiveTranscoding method before this method.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n                        ERR_INVALID_ARGUMENT(-2): Invalid argument, usually because the URL address is null or the string length is 0.\n                        ERR_NOT_INITIALIZED(-7): You have not initialized the RTC engine when publishing the stream."
    },
    {
        "id": "api_addvideowatermark2",
        "name": "addVideoWatermark",
        "description": "Adds a watermark image to the local video.This method adds a PNG watermark image to the local video in the live streaming. Once the watermark image is added, all the audience in the channel (CDN audience included), and the capturing device can see and capture it. Agora supports adding only one watermark image onto the local video, and the newly watermark image replaces the previous one.\n   The watermark coordinates are dependent on the settings in the setVideoEncoderConfiguration method:\n  If the orientation mode of the encoding video (ORIENTATION_MODE) is fixed\n                        landscape, or landscape in adaptive mode, the watermark uses the landscape\n                        orientation.\n  If the orientation mode of the encoding video (ORIENTATION_MODE) is fixed\n                        portrait, or portrait in adaptive mode, the watermark uses the portrait\n                        orientation.\n  When setting the watermark position, the region must be less than the dimensions set in the setVideoEncoderConfiguration method. Otherwise, the watermark image will be cropped.\n       \n   \n   \n       \n  Ensure that you have called enableVideo before calling this method.\n  If you only want to add a watermark to the CDN live streaming, you can call this method or the setLiveTranscoding method.\n  This method supports adding a watermark image in the PNG file format only. Supported pixel formats of the PNG image are RGBA, RGB, Palette, Gray, and Alpha_gray.\n  If the dimensions of the PNG image differ from your settings in this method, the image will be cropped or zoomed to conform to your settings.\n  If you have enabled the local video preview by calling the startPreview method, you can use the visibleInPreview member to set whether or not the watermark is visible in the preview.\n  If you have enabled the mirror mode for the local video, the watermark on the local video is also mirrored. To avoid mirroring the watermark, Agora recommends that you do not use the mirror and watermark functions for the local video at the same time. You can implement the watermark function in your application layer.",
        "parameters": [
            {
                "watermarkUrl": "The local file path of the watermark image to be added. This method supports adding a watermark image from the local absolute or relative file path."
            },
            {
                "options": "The options of the watermark image to be added. For details, see WatermarkOptions."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingplayoutvolume",
        "name": "adjustAudioMixingPlayoutVolume",
        "description": "Adjusts the volume of audio mixing for local playback.You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume for local playback. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingpublishvolume",
        "name": "adjustAudioMixingPublishVolume",
        "description": "Adjusts the volume of audio mixing for publishing.This method adjusts the volume of audio mixing for publishing (sending to other users).\n   You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingvolume",
        "name": "adjustAudioMixingVolume",
        "description": "Adjusts the volume during audio mixing.This method adjusts the audio mixing volume on both the local client and remote clients.\n   \n       \n  Call this method after startAudioMixing.\n  Calling this method does not affect the volume of audio effect file playback invoked by the playEffect method.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value ranges between 0 and 100. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustplaybacksignalvolume",
        "name": "adjustPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of all remote users.This method adjusts the playback volume that is the mixed volume of all remote users.\n  As of v2.3.2, to mute the local audio, you need to call the adjustPlaybackSignalVolume and adjustAudioMixingPlayoutVolume methods at the same time, and set volume to 0.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_adjustrecordingsignalvolume",
        "name": "adjustRecordingSignalVolume",
        "description": "Adjusts the capturing signal volume.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "\n      The volume of the signal captured by the microphone. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.Since\n  v3.0.0\n       \n   \n   You can call this method as many times as necessary to adjust the playback volume of different remote users, or to repeatedly adjust the playback volume of the same remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "volume": "\n      The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_agorartcchannel_on",
        "name": "AgoraRtcChannel callbacks",
        "description": "AgoraRtcChannel.on provides callbacks that report events and statistics of a specified channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_agorartcengine_on",
        "name": "AgoraRtcEngine callbacks",
        "description": "AgoraRtcEngine.on reports runtime events to the application.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_clearvideowatermarks",
        "name": "clearVideoWatermarks",
        "description": "Removes the watermark image from the video stream.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_complain",
        "name": "complain",
        "description": "Allows a user to complain about the call quality after a call ends.This method allows users to complain about the quality of the call. Call this method after the user leaves the channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT).\n  -3 (ERR_NOT_READY)."
    },
    {
        "id": "api_createChannel",
        "name": "createChannel",
        "description": "Creates and gets an AgoraRtcChannel object.You can call this method multiple times to create multiple AgoraRtcChannel objects,\n                and then call the joinChannel methods of each AgoraRtcChannel to join multiple channels at the same time.\n   After joining multiple channels, you can simultaneously subscribe to the the audio and video streams of all the channels, but publish a stream in only one channel at one time.",
        "parameters": [
            {
                "channelId": "\n      The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel name enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  \n \n     The parameter does not have a default value. You must set it.\n     Do not set this parameter as the empty string \"\". Otherwise, the SDK returns ERR_REFUSED(5).\n \n      \n  "
            }
        ],
        "returns": "A pointer to the AgoraRtcChannel instance, if the method call succeeds.\n       If the call fails, returns null."
    },
    {
        "id": "api_createdatastream1",
        "name": "createDataStream",
        "description": "Creates a data stream.Deprecated:\n  This method is deprecated as of v2.4.0. Please use createDataStreamWithConfig instead.\n       \n   \n   Each user can create up to five data streams during the lifecycle of AgoraRtcEngine.\n   \n       \n  Call this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as false.",
        "parameters": [
            {
                "reliable": "Whether or not the data stream is reliable:\n      true: The recipients receive the data from the sender within five seconds. If the recipient does not receive the data within five seconds, the SDK triggers the STREAM_MESSAGE_ERROR callback and returns an error code.\n      false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is reported for any delay or missing data stream.\n  "
            },
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            }
        ],
        "returns": "0: The data stream is successfully created.\n       < 0: Fails to create the data stream. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_createdatastream2",
        "name": "createDataStreamWithConfig",
        "description": "Creates a data stream.Creates a data stream. Each user can create up to five data streams in a\n                single channel.  \n            Compared with createDataStream, this method does not\n                support data reliability. If a data packet is not received five seconds after it was\n                sent, the SDK directly discards the data.",
        "parameters": [
            {
                "config": "The configurations for the data stream. See DataStreamConfig."
            }
        ],
        "returns": "ID of the created data stream, if the method call succeeds.\n       < 0: Failure. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_destroyrenderer",
        "name": "destroyRenderer",
        "description": "Destroys the video renderer.You can call this method to destroy the video renderer after calling setView.",
        "parameters": [
            {
                "user": "The user of the video. See User."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_disableaudio",
        "name": "disableAudio",
        "description": "Disables the audio module.This method disables the internal engine and can be called anytime after initialization. It is still valid after leaveChannel.\n                This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the audio modules separately:\n                    enableLocalAudio: Whether to enable the microphone to create the local audio stream.\n                    muteLocalAudioStream: Whether to publish the local audio stream.\n                    muteRemoteAudioStream: Whether to subscribe and play the remote audio stream.\n                    muteAllRemoteAudioStreams: Whether to subscribe to and play all remote audio streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_disablelastmiletest",
        "name": "disableLastmileTest",
        "description": "Disables the network connection quality test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_disablevideo",
        "name": "disableVideo",
        "description": "Disables the video module.This method disables video. You can call this method either before or after joining a channel. If you call it before joining a channel, an audio call starts when you join the channel. If you call it after joining a channel, a video call switches to an audio call. Call the enableVideo method to enable video.A successful call of this method triggers the USER_ENABLE_VIDEO(false) callback on the remote client.\n   \n       This method affects the internal engine and can be called after leaveChannel.\n       This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableaudio",
        "name": "enableAudio",
        "description": "Enables the audio module.The audio mode is enabled by default.\n   \n       This method enables the internal engine and can be called anytime after initialization. It is still valid after leaveChannel.\n       This method enables the audio module and takes some time to take effect. Agora recommends using the following API methods to control the audio module separately:\n  enableLocalAudio: Whether to enable the microphone to create the local audio stream.\n  muteLocalAudioStream: Whether to publish the local audio stream.\n  muteRemoteAudioStream: Whether to subscribe and play the remote audio stream.\n  muteAllRemoteAudioStreams: Whether to subscribe to and play all remote audio streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableaudiovolumeindication",
        "name": "enableAudioVolumeIndication",
        "description": "Enables the reporting of users' volume indication.This method enables the SDK to regularly report the volume information of the local user who sends a stream and remote users (up to three) whose instantaneous volumes are the highest to the app. Once you call this method and users send streams in the channel, the SDK triggers the AUDIO_VOLUME_INDICATION callback at the time interval set in this method.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "interval": "Sets the time interval between two consecutive volume indications:\n ≤ 0: Disables the volume indication.\n > 0: Time interval (ms) between two consecutive volume indications. We recommend a setting greater than 200 ms. Do not set this parameter to less than 10 milliseconds, otherwise the AUDIO_VOLUME_INDICATION callback will not be triggered.\n      \n  "
            },
            {
                "smooth": "The smoothing factor sets the sensitivity of the audio volume indicator. The value ranges between 0 and 10. The recommended value is 3. The greater the value, the more sensitive the indicator."
            },
            {
                "report_vad": "\n      \n true: Enable the voice activity detection of the local user. Once it is enabled, the vad parameter of the AUDIO_VOLUME_INDICATION callback reports the voice activity status of the local user.\n false: (Default) Disable the voice activity detection of the local user. Once it is disabled, the vad parameter of the AUDIO_VOLUME_INDICATION callback does not report the voice activity status of the local user, except for the scenario where the engine automatically detects the voice activity of the local user.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enabledeeplearningdenoise",
        "name": "enableDeepLearningDenoise",
        "description": "Enables or disables deep-learning noise reduction.Since\n  v3.3.0\n       \n   \n   The SDK enables traditional noise reduction mode by default to reduce most of the stationary background noise. If you need to reduce most of the non-stationary background noise, Agora recommends enabling deep-learning noise reduction as follows:\n       Ensure that the dynamic library is integrated in your project: libagora_ai_denoise_extension.dll\n       Call enableDeepLearningDenoise(true).\n   \n   Deep-learning noise reduction requires high-performance devices. The deep-learning noise reduction is enabled only when the device supports this function. For example, the following devices and later models are known to support deep-learning noise reduction:\n       iPhone 6S\n       MacBook Pro 2015\n       iPad Pro (2nd generation)\n       iPad mini (5th generation)\n       iPad Air (3rd generation)\n   \n   After successfully enabling deep-learning noise reduction, if the SDK detects that the device performance is not sufficient, it automatically disables deep-learning noise reduction and enables traditional noise reduction.\n   If you call enableDeepLearningDenoise(true) or the SDK automatically disables deep-learning noise reduction in the channel, when you need to re-enable deep-learning noise reduction, you need to call leaveChannel first, and then call enableDeepLearningDenoise(true).\n   \n       This method dynamically loads the library, so Agora recommends calling this method before joining a channel.\n       This method works best with the human voice. Agora does not recommend using this method for audio containing music.",
        "parameters": [
            {
                "enabled": "Whether to enable deep-learning noise reduction.\n      true: (Default) Enable deep-learning noise reduction.\n      false: Disable deep-learning noise reduction.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -157 (ERR_MODULE_NOT_FOUND): The dynamic library for enabling deep-learning noise reduction is not integrated."
    },
    {
        "id": "api_enabledualstreammode",
        "name": "enableDualStreamMode",
        "description": "Enables/Disables dual-stream mode.This method enables or disables dual streams. If a remote user enables dual-stream mode, use this method to subscribe to the high-quality or low-quality video stream. The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "\n      \n true: Enables dual-stream mode.\n false: Disables dual-stream mode.\n      \n  "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.Since\n                         v3.1.0\n                    \n               \n               In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "\n                              Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption. See EncryptionConfig."
            }
        ],
        "returns": "0: Success.\n                    \n                         < 0: Failure.\n                              -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the\n                                   parameter with a valid value.\n                              -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK\n                                   fails to load the external encryption library. Check the\n                                   enumeration or reload the external encryption library.\n                              -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize\n                                   the AgoraRtcEngine instance before calling this\n                                   method."
    },
    {
        "id": "api_enablelastmiletest",
        "name": "enableLastmileTest",
        "description": "Enables the network connection quality test.This method tests the quality of the users' network connections. By default, this function is disabled. This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    Before an audience switches to a host, call this method to check the uplink network quality.\n                \n            \n            Regardless of the scenario, enabling this method consumes extra network traffic and affects the call quality. After receiving the LASTMILE_QUALITY callback, call disableLastmileTest to stop the test, and then join the channel or switch to the host.\n            \n                \n                    Do not use this method together with startLastmileProbeTest.\n                    Do not call any other methods before receiving the LASTMILE_QUALITY callback. Otherwise, the callback may be interrupted by other methods, and hence may not be triggered.\n                    A host should not call this method after joining a channel (when in a call).\n                    If you call this method to test the last mile network quality, the SDK consumes the bandwidth of a video stream, whose bitrate corresponds to the bitrate you set in setVideoEncoderConfiguration. After joining a channel, whether you have called disableLastmileTest or not, the SDK automatically stops consuming the bandwidth.",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_enablelocalaudio",
        "name": "enableLocalAudio",
        "description": "Disables/Re-enables the local audio function.The audio function is enabled by default. This method disables or re-enables the local audio function to stop or restart local audio capturing.\n   This method does not affect receiving or playing the remote audio streams, and enableLocalAudio(false) applies to scenarios where the user wants to receive remote audio streams without sending any audio stream to other users in the channel.\n   Once the local audio function is disabled or re-enabled, the SDK triggers the LOCAL_AUDIO_STATE_CHANGED callback, which reports LOCAL_AUDIO_STREAM_STATE_STOPPED(0) or LOCAL_AUDIO_STREAM_STATE_RECORDING(1).\n       This method is different from muteLocalAudioStream:\n                                enableLocalVideo: Disables/Re-enables the\n                                    local audio capturing and processing. If you disable or\n                                    re-enable local audio capturing using the\n                                        enableLocalAudio method, the local user\n                                    might hear a pause in the remote audio playback.\n                                muteLocalAudioStream: Sends/Stops sending\n                                    the local audio streams.\n                            \n                               \n       You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "\n      true: (Default) Re-enable the local audio function, that is, to start the local audio capturing device (for example, the microphone).\n      false: Disable the local audio function, that is, to stop local audio capturing.\n       \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablelocalvideo",
        "name": "enableLocalVideo",
        "description": "Enables/Disables the local video capture.This method disables or re-enables the local video capturer, and does not affect receiving the remote video stream.\n   After calling enableVideo, the local video capturer is enabled by default.\n                You can call enableLocalVideo(false) to disable the local video capturer. If you want to re-enable it, call\n                            enableLocalVideo(true).\n   After the local video capturer is successfully disabled or re-enabled, the SDK triggers the\n                    USER_ENABLE_LOCAL_VIDEO callback on the remote client.\n   \n       \n  You can call this method either before or after joining a channel.\n  This method enables the internal engine and is valid after leaveChannel.",
        "parameters": [
            {
                "enabled": "\n      Whether to enable the local video capture:\n      \n true: (Default) Enables the local video capture.\n false: Disables the local video capture. Once the local video is disabled, the remote users can no longer receive the video stream of this user, while this user can still receive the video streams of the other remote users. When set to false, this method does not require a local camera.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableloopbackrecording",
        "name": "enableLoopbackRecording",
        "description": "Enables loopback audio capture.If you enable loopback audio capturing, the output of the sound card is mixed into the audio stream sent to the other end.\n       \n  \n      macOS does not support loopback capturing of the default sound card. If you need to use this method, please use a virtual sound card and pass its name to the deviceName parameter. Agora has tested and recommends using soundflower.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "Whether to enableloopback capture:\n true: Enable loopback audio capture.\n false: (Default) Disable loopback capture.\n      "
            },
            {
                "deviceName": "The device name of the sound card. The default value is null (the default sound card). If the user uses a virtual sound card, such as \"Soundflower\", the virtual sound card name \"Soundflower\" can be passed to this parameter, and the SDK finds the corresponding virtual sound card device and starts collecting."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_enableplugin",
        "name": "enablePlugin",
        "description": "Enable or disable the specified plug-in.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin. You can get it from PluginInfo."
            },
            {
                "enabled": "Whether to enable the plug-in:\n                            true: Enable the plug-in.\n                            false: Disable the plug-in.\n                        "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_enablesoundpositionindication",
        "name": "enableSoundPositionIndication",
        "description": "Enables/Disables stereo panning for remote users.Ensure that you call this method before joining a channel to enable stereo panning for remote users so that the local user can track the position of a remote user by calling setRemoteVoicePosition.",
        "parameters": [
            {
                "enabled": "Whether to enable stereo panning for remote users:\n true: Enable stereo panning.\n false: Disable stereo panning.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablevideo",
        "name": "enableVideo",
        "description": "Enables the video module.Call this method either before joining a channel or during a call. If this method is called before joining a channel, the call starts in the video mode. Call the disableVideo method to disable the video mode.A successful call of this method triggers the REMOTE_VIDEO_STATE_CHANGED callback on the remote client.\n                \n                    This method enables the internal engine and is valid after leaveChannel.\n                    This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablewebsdkinteroperability",
        "name": "enableWebSdkInteroperability",
        "description": "Enables interoperability with the Agora Web SDK (applicable only in the live streaming scenarios).Deprecated:\n  As of v3.0.0, the Native SDK automatically enables interoperability with the Web SDK, so you no longer need to call this method.\n       \n   \n   This method enables or disables interoperability with the Agora Web SDK. If the channel has Web SDK users, ensure that you call this method, or the video of the Native user will be a black screen for the Web user.\n   This method is only applicable in live streaming scenarios, and interoperability is enabled by default in communication scenarios.",
        "parameters": [
            {
                "enabled": "Whether to enable interoperability with the Agora Web SDK:\n                            true: Enable interoperability.\n                            false: (Default) Disable\n                                interoperability.\n                        "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingcurrentposition",
        "name": "getAudioMixingCurrentPosition",
        "description": "Retrieves the playback position (ms) of the music file.Retrieves the playback position (ms) of the audio.\n            You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The current playback position of the audio mixing, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingduration2",
        "name": "getAudioMixingDuration",
        "description": "Retrieves the duration (ms) of the music file.Since\n                    v3.4.0\n                \n            \n            Call this method after joining a channel.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               "
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the total duration (ms) of the specified music file.\n                < 0: Failure."
    },
    {
        "id": "api_getaudiomixingplayoutvolume",
        "name": "getAudioMixingPlayoutVolume",
        "description": "Retrieves the audio mixing volume for local playback.This method helps troubleshoot audio volume‑related issues.\n            You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingpublishvolume",
        "name": "getAudioMixingPublishVolume",
        "description": "Retrieves the audio mixing volume for publishing.This method helps troubleshoot audio volume‑related issues.\n            You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getaudioplaybackdevices",
        "name": "getAudioPlaybackDevices",
        "description": "Retrieves the audio playback device associated with the device ID.",
        "parameters": [],
        "returns": "An array of the audio playback devices. See Device."
    },
    {
        "id": "api_getaudiorecordingdevices",
        "name": "getAudioRecordingDevices",
        "description": "Retrieves the audio recording device associated with the device ID.",
        "parameters": [],
        "returns": "An array of the audio recording devices. See Device."
    },
    {
        "id": "api_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.When a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID.\n   \n       0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.Since\n                    v2.3.2\n                \n            \n            You can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": "The current connection state of the SDK. See CONNECTION_STATE_TYPE."
    },
    {
        "id": "api_geteffectcurrentposition",
        "name": "getEffectCurrentPosition",
        "description": "Retrieves the playback position of the audio effect file.Call this method after playEffect.",
        "parameters": [
            {
                "sound": "Audio effect ID. Ensure that this parameter matches the soundId set in playEffect."
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the playback position (ms) of the specified audio effect file.\n                < 0: Failure."
    },
    {
        "id": "api_geteffectduration",
        "name": "getEffectDuration",
        "description": "Retrieves the duration of the audio effect file.Call this method after joining a channel.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               "
            }
        ],
        "returns": "≥ 0: A successful method call. Returns the total duration (ms) of the specified audio effect file.\n                < 0: Failure."
    },
    {
        "id": "api_geteffectsvolume",
        "name": "getEffectsVolume",
        "description": "Retrieves the volume of the audio effects.The volume is an integer ranging from 0 to 100. The default value is 100, the original volume.\n   Call this method after playEffect.",
        "parameters": [],
        "returns": "Volume of the audio effects, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_geterrordescription",
        "name": "getErrorDescription",
        "description": "Gets the warning or error description.",
        "parameters": [
            {
                "code": "The error code or warning code reported by the SDK."
            }
        ],
        "returns": "The specific error or warning description. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_getplaybackdevice",
        "name": "getCurrentAudioPlaybackDevice",
        "description": "Retrieves the audio playback device associated with the device ID.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            The audio playback device. See Device."
    },
    {
        "id": "api_getplaybackdevicemute",
        "name": "getAudioPlaybackDeviceMute",
        "description": "Retrieves whether the audio playback device is muted.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            \ntrue: The audio playback device is muted.\nfalse: The audio playback device is unmuted."
    },
    {
        "id": "api_getplaybackdevicevolume",
        "name": "getAudioPlaybackVolume",
        "description": "Retrieves the volume of the audio playback device.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
    },
    {
        "id": "api_getpluginparameter",
        "name": "getPluginParameter",
        "description": "Gets the parameter of a specified plugin.If you want to pass the JSON string to the C++ layer when using the plugin, you need to call getPluginParameter and setPluginParameter to get and set the plugin parameters.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin. You can get it from PluginInfo."
            },
            {
                "key": "The key."
            }
        ],
        "returns": "The value corresponding to the key."
    },
    {
        "id": "api_getplugins",
        "name": "getPlugins",
        "description": "Gets the plugins.After the method call of registerPlugin, you can call this method to get registered plugins.",
        "parameters": [],
        "returns": "An array of the Plugin objects."
    },
    {
        "id": "api_getrecordingdevice",
        "name": "getCurrentAudioRecordingDevice",
        "description": "Gets the current audio recording device.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            The audio recording device. See Device."
    },
    {
        "id": "api_getrecordingdevicemute",
        "name": "getAudioRecordingDeviceMute",
        "description": "Gets the microphone's mute status.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            \n                            true: The microphone is muted.\n                            false: The microphone is unmuted."
    },
    {
        "id": "api_getrecordingdevicevolume",
        "name": "getAudioRecordingVolume",
        "description": "Retrieves the volume of the audio recording device.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            The volume of the audio recording device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
    },
    {
        "id": "api_getscreensinfo",
        "name": "getScreensInfo",
        "description": "Gets the screen information.You need to call this method to get the screen information before sharing the screen by a display ID (macOS) or ScreenRect (Windows).\n            This method can get the information of multiple screens.",
        "parameters": [],
        "returns": "Objects that contain the screen information. The screen information on macOS and Windows is different. You can ignore the details and directly use the returned objects for screen sharing."
    },
    {
        "id": "api_getuserinfobyuid",
        "name": "getUserInfoByUid",
        "description": "Gets the user information by passing in the user ID.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers the USER_INFO_UPDATED callback on the local client. \n   After receiving the callback, you can call this method to get the user account of the remote user from the UserInfo object by passing in the user ID.",
        "parameters": [
            {
                "uid": "User ID. It is mandatory."
            },
            {
                "userInfo": "Identifiers of a user. See UserInfo for details."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getuserinfobyuseraccount",
        "name": "getUserInfoByUserAccount",
        "description": "Gets the user information by passing in the user account.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers the USER_INFO_UPDATED callback on the local client.\n   After receiving the callback, you can call this method to get the user ID of the remote user from the UserInfo object by passing in the user account.",
        "parameters": [
            {
                "userAccount": "The user account. It is mandatory."
            },
            {
                "userInfo": "Identifiers of a user. See UserInfo for details."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getversion",
        "name": "getVersion",
        "description": "Gets the SDK version.",
        "parameters": [],
        "returns": "The SDK version number. The format is a string, such as 3.3.0."
    },
    {
        "id": "api_getvideodevices",
        "name": "getVideoDevices",
        "description": "Gets the list of video devices.",
        "parameters": [],
        "returns": "An array of the video devices. See Device."
    },
    {
        "id": "api_getwindowsinfo",
        "name": "getWindowsInfo",
        "description": "Gets the window information.Before sharing a window through a window ID that specifies the window, you need to call this method to get the window information.\n            This method can get the information of multiple windows.",
        "parameters": [],
        "returns": "An array of WindowInfo objects. See WindowInfo."
    },
    {
        "id": "api_ichannel_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n      This method applies to the Native SDK v2.4.1 and later.\n      This method takes effect only when you are a host in a live streaming channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the\n                ongoing live broadcast. This applies to scenarios where all users in the channel can\n                watch a live show and interact with each other. After calling this method, the SDK\n                triggers the STREAM_INJECT_STATUS callback on the local client to\n                report the state of injecting the online media stream; after successfully injecting\n                the media stream, the stream joins the channel, and all users in the channel receive\n                the USER_JOINED callback, where uid is\n                    666.",
        "parameters": [
            {
                "url": "\n      The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: InjectStreamConfig."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n      ERR_INVALID_ARGUMENT (-2): The injected URL does not exist. Call this method again to inject the stream and ensure that the URL is valid.\n      ERR_NOT_READY (-3): The user is not in the channel.\n      ERR_NOT_SUPPORTED (-4): The channel is not a live streaming channel. Call\n                                setChannelProfile and set the channel profile to\n                            live streaming before calling this method.\n      ERR_NOT_INITIALIZED (-7): The SDK is not initialized. Ensure that the AgoraRtcEngine object is initialized before using this method."
    },
    {
        "id": "api_ichannel_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.Call this method after joining a channel.\n  Ensure that you enable the RTMP Converter service before using this function. See\n                        Prerequisites in Push Streams to\n                            CDN.\n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n        After calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the RTMP_STREAMING_STATE_CHANGED callback on the local client to report the state of adding a local stream to the CDN.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "Whether to enable transcoding. Transcoding in a CDN live streaming converts the audio and\n                            video streams before pushing them to the CDN server. It applies to\n                            scenarios where a channel has multiple broadcasters and composite layout\n                            is needed.\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true , ensure that you call the setLiveTranscoding method before this method.\n       "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n                        ERR_INVALID_ARGUMENT(-2): Invalid argument, usually because the URL address is null or the string length is 0.\n                        ERR_NOT_INITIALIZED(-7): You have not initialized the RTC engine when publishing the stream."
    },
    {
        "id": "api_ichannel_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.Since\n  v3.0.0\n       \n   \n   You can call this method as many times as necessary to adjust the playback volume of different remote users, or to repeatedly adjust the playback volume of the same remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "volume": "\n      The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            },
            {
                "userId": "The ID of the remote user."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_channelId",
        "name": "channelId",
        "description": "Gets the current channel ID.",
        "parameters": [],
        "returns": "The current channel ID, if the method call succeeds.\n       The empty string \"\", if the method call fails."
    },
    {
        "id": "api_ichannel_createdatastream1",
        "name": "createDataStream",
        "description": "Creates a data stream.Call this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as false.\n       \n   \n        Each user can create up to five data streams during the lifecycle of AgoraRtcEngine.\n   \n       \n  Deprecated:\n  This method is deprecated as of v2.4.0. Please use createDataStreamWithConfig instead.",
        "parameters": [
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            },
            {
                "reliable": "\n                        Whether or not the data stream is reliable:\n                                true: The recipients receive the data from the sender within five seconds. If the recipient does not receive the data within five seconds, the SDK triggers the STREAM_MESSAGE_ERROR callback and returns an error code.\n                                false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is reported for any delay or missing data stream.\n                            \n                    "
            }
        ],
        "returns": "Returns the stream ID, if the method call is successful.\n       0: The data stream is successfully created.\n       < 0: Fails to create the data stream. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_ichannel_createdatastream2",
        "name": "createDataStreamWithConfig",
        "description": "Creates a data stream.Compared with createDataStream, this method does not\n                support data reliability. If a data packet is not received five seconds after it was\n                sent, the SDK directly discards the data.\n        Creates a data stream. Each user can create up to five data streams in a\n                single channel.  \n            \n       \n  Since\n  v3.3.0. Use this method instead of createDataStream.",
        "parameters": [
            {
                "streamId": "Output parameter. Pointer to the ID of the created data stream."
            },
            {
                "config": "The configurations for the data stream. See DataStreamConfig."
            }
        ],
        "returns": "0: The data stream is successfully created.\n       ID of the created data stream, if the method call succeeds.\n       < 0: Failure. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_ichannel_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.Since\n                         v3.1.0\n                    \n               \n               In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "\n                              Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption. See EncryptionConfig."
            }
        ],
        "returns": "0: Success.\n                    \n                         < 0: Failure.\n                              -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the\n                                   parameter with a valid value.\n                              -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK\n                                   fails to load the external encryption library. Check the\n                                   enumeration or reload the external encryption library.\n                              -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize\n                                   the AgoraRtcEngine instance before calling this\n                                   method."
    },
    {
        "id": "api_ichannel_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.When a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID.\n   \n       0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.Since\n                    v2.3.2\n                \n            \n            You can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": "The current connection state of the SDK. See CONNECTION_STATE_TYPE."
    },
    {
        "id": "api_ichannel_joinchannel",
        "name": "joinChannel",
        "description": "Joins the channel with a user ID.joinChannel\n                   \n               \n           \n           \n      \n Does not contain the channelId parameter, because channelId is specified when creating the AgoraRtcChannel object.\n You need to fill in the channelId that can identify the channel.\n      \n      \n Users can join multiple channels simultaneously by creating multiple AgoraRtcChannel objects and calling the joinChannel methods of each object.\n Users can join only one channel.\n      \n      \n By default, the SDK does not publish any stream after the user joins the channel. You need to call the publish method to do that.\n By default, the SDK publishes streams once the user joins the channel.\n      \n  \n       \n   \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different UIDs for different channels.\n  If you want to join the same channel from different devices, ensure that the user IDs in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n      "
            },
            {
                "uid": "User ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. This parameter is a 32-bit unsigned integer with a value ranging from 1 to 232 -1. If the user ID is not assigned (or set as 0), the SDK assigns a user ID and reports it in the JOIN_CHANNEL_SUCCESS callback. Your app must maintain this user ID."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an AgoraRtcChannel object with the same channel name.\n      You have joined and published a stream in an AgoraRtcChannel channel created by the AgoraRtcChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the AgoraRtcEngine instance before calling this method."
    },
    {
        "id": "api_ichannel_joinchannelwithuseraccount",
        "name": "joinChannelWithUserAccount",
        "description": "Joins the channel with a user account.Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different user accounts for different channels.\n  If you want to join the same channel from different devices, ensure that the user accounts in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n "
            },
            {
                "token": "\n    The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an AgoraRtcChannel object with the same channel name.\n      You have joined and published a stream in an AgoraRtcChannel channel created by the AgoraRtcChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the AgoraRtcEngine instance before calling this method."
    },
    {
        "id": "api_ichannel_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.This method lets the user leave the channel, for example, by hanging up or exiting the call. This method releases all resources related to the session. This method call is asynchronous, and the user has not left the channel when the method call returns.\n   After calling joinChannel, you must call leaveChannel to end the call, otherwise the next call cannot be started.\n   No matter whether you are currently in a call or not, you can call leaveChannel without side effects.\n   A successful call of this method triggers the following callbacks: \n                    The local client: LEAVE_CHANNEL.\n                    The remote client: USER_OFFLINE, if the user\n                        joining the channel is in the COMMUNICATION profile, or is a host in the\n                        LIVE_BROADCASTING profile.\n                \n   \n       \n  If you call the leaveChannel method immediately after calling release, the SDK will not be able to trigger the LEAVE_CHANNEL callback.\n  If you call the leaveChannel method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.",
        "parameters": [
            {
                "mute": "Whether to subscribe to the audio streams of all remote users:\n                                true: Do not subscribe to the\n                                    audio streams of all remote users.\n                                false: (Default) Subscribe to\n                                    the audio streams of all remote users by default.\n                            \n                        \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the video streams of all remote users.\n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The user ID of the specified user."
            },
            {
                "mute": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user by default.\n false: (Default) Subscribe to the audio stream of the specified user by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.",
        "parameters": [
            {
                "userId": "\n      The user ID of the specified user.\n  "
            },
            {
                "mute": "Whether to stop subscribing to the video stream of the specified user.\n      true:Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_onactivespeaker",
        "name": "ACTIVE_SPEAKER",
        "description": "Occurs when the most active speaker is detected.After a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of users is no less than two and an active speaker exists, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker is always the same user, the SDK triggers the ACTIVE_SPEAKER callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": "The user ID of the most active speaker."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onaudiopublishstatechanged",
        "name": "AUDIO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the audio publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onaudiosubscribestatechanged",
        "name": "AUDIO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the audio subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelerror",
        "name": "CHANNEL_ERROR",
        "description": "The error code AgoraRtcChannel reported.",
        "parameters": [
            {
                "rtcChannel": "AgoraRtcChannel."
            },
            {
                "err": "The error code. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelmediarelayevent",
        "name": "CHANNEL_MEDIA_RELAY_EVENT",
        "description": "Reports events during the media stream relay.",
        "parameters": [
            {
                "code": "The event code of channel media relay. See CHANNEL_MEDIA_RELAY_EVENT."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelmediarelaystatechanged",
        "name": "CHANNEL_MEDIA_RELAY_STATE_CHANGED",
        "description": "Occurs when the state of the media stream relay changes.The SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "code": "The error code of the channel media replay. See CHANNEL_MEDIA_RELAY_ERROR."
            },
            {
                "state": "The state code. See CHANNEL_MEDIA_RELAY_STATE."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelwarning",
        "name": "CHANNEL_WARNING",
        "description": "Reports the warning code of AgoraRtcChannel.",
        "parameters": [
            {
                "rtcChannel": "AgoraRtcChannel."
            },
            {
                "warn": "Warning codes. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The warning message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onclientrolechanged",
        "name": "CLIENT_ROLE_CHANGED",
        "description": "Occurs when the user role switches in the interactive live streaming.The SDK triggers this callback when the local user uses the setClientRole method to change the user role after joining the channel.",
        "parameters": [
            {
                "newRole": "Role that the user switches to: CLIENT_ROLE_TYPE."
            },
            {
                "oldRole": "Role that the user switches from: CLIENT_ROLE_TYPE."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onconnectionlost",
        "name": "CONNECTION_LOST",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.The SDK triggers this callback when it cannot connect to the server 10 seconds after calling the joinChannel method, regardless of whether it is in the channel.",
        "parameters": [
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onconnectionstatechanged",
        "name": "CONNECTION_STATE_CHANGED",
        "description": "Occurs when the network connection state changes.When the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "reason": "The reason for a connection state change. See CONNECTION_CHANGED_REASON_TYPE."
            },
            {
                "state": "The current connection state. See CONNECTION_STATE_TYPE."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onjoinchannelsuccess",
        "name": "JOIN_CHANNEL_SUCCESS",
        "description": "Occurs when a user joins a channel.This callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "channelId": "The channel ID."
            },
            {
                "uid": "User ID. If you have specified a user ID in joinChannel, the ID will be returned here; otherwise, the SDK returns an ID automatically assigned by the Agora server."
            },
            {
                "elapsed": "The time elapsed (in milliseconds) from the local user calling joinChannel till this event."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onleavechannel",
        "name": "LEAVE_CHANNEL",
        "description": "Occurs when a user leaves a channel.When a user leaves the channel by using the leaveChannel method, the SDK uses this callback to notify the app when the user leaves the channel. With this callback, the app gets the channel information, such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onmetadatareceived",
        "name": "METADATA_RECEIVED",
        "description": "Occurs when the local user receives Metadata.",
        "parameters": [
            {
                "metadata": "The received metadata. See Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onnetworkquality",
        "name": "NETWORK_QUALITY",
        "description": "Reports the last mile network quality of each user in the channel.This callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate, average RTT, and jitter of the downlink network. See QUALITY_TYPE."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the uplink network. This parameter is a quality rating helping you understand how well the current uplink network conditions can support the selected video encoder configuration. For example, a 1000 Kbps uplink network may be adequate for video frames with a resolution of 640 × 480 and a frame rate of 15 fps in the LIVE_BROADCASTING profile, but might be inadequate for resolutions higher than 1280 × 720. See QUALITY_TYPE."
            },
            {
                "uid": "User ID. The network quality of the user with this user ID is reported. If the uid is 0, the local network quality is reported."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onreadytosendmetadata",
        "name": "READY_TO_SEND_METADATA",
        "description": "Occurs when the SDK is ready to send Metadata.This callback is triggered when the SDK is ready to receive and send Metadata. After receiving this callback, you can call sendMetadata to send the media metadata.",
        "parameters": [
            {
                "metadata": "Media metadata See Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrejoinchannelsuccess",
        "name": "REJOIN_CHANNEL_SUCCESS",
        "description": "Occurs when a user rejoins the channel.When a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this callback."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremoteaudiostatechanged",
        "name": "REMOTE_AUDIO_STATE_CHANGED",
        "description": "Occurs when the remote audio state changes.Since\n                        v2.9.0\n                    \n                \n               When the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": "The reason of the remote audio state change, see REMOTE_AUDIO_STATE_REASON."
            },
            {
                "state": "The state of the remote audio, see REMOTE_AUDIO_STATE."
            },
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremoteaudiostats",
        "name": "REMOTE_AUDIO_STATS",
        "description": "Reports the transport-layer statistics of each remote audio stream.The SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotesubscribefallbacktoaudioonly",
        "name": "REMOTE_SUBSCRIBE_FALLBACK_TO_AUDIO_ONLY",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.If you call setRemoteSubscribeFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor downlink conditions, or when the remote media stream switches back to the video after the downlink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n      \n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotevideostatechanged",
        "name": "REMOTE_VIDEO_STATE_CHANGED",
        "description": "Occurs when the remote video state changes.Since\n                        v2.9.0\n                    \n                \n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": "The reason for the remote video state change, see REMOTE_VIDEO_STATE_REASON."
            },
            {
                "state": "The state of the remote video, see REMOTE_VIDEO_STATE."
            },
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotevideostats",
        "name": "REMOTE_VIDEO_STATS",
        "description": "Reports the transport-layer statistics of each remote video stream.Reports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. See RemoteVideoStats."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrequesttoken",
        "name": "REQUEST_TOKEN",
        "description": "Occurs when the token expires.When the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n            Once you receive this callback, generate a new token on your app server, and call joinChannel to rejoin the channel.",
        "parameters": [
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtcstats",
        "name": "RTC_STATS",
        "description": "Reports the statistics of the current call.The SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": "\n      Statistics of the RTC engine, see RtcStats for details.\n  "
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtmpstreamingevent",
        "name": "RTMP_STREAMING_EVENT",
        "description": "Reports events during the RTMP or RTMPS streaming.Since\n  v3.1.0",
        "parameters": [
            {
                "eventCode": "The event code of the streaming. See RTMP_STREAMING_EVENT."
            },
            {
                "url": "The RTMP or RTMPS streaming URL."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtmpstreamingstatechanged",
        "name": "RTMP_STREAMING_STATE_CHANGED",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.The SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "errCode": "The detailed error information for streaming, see RTMP_STREAM_PUBLISH_ERROR."
            },
            {
                "state": "The RTMP or RTMPS streaming state, see RTMP_STREAM_PUBLISH_STATE. When the streaming status is RTMP_STREAM_PUBLISH_STATE_FAILURE (4), you can view the error information in the errorCode parameter."
            },
            {
                "url": "The CDN streaming URL."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreaminjectedstatus",
        "name": "STREAM_INJECTED_STATUS",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.",
        "parameters": [
            {
                "status": "State of the externally injected stream: INJECT_STREAM_STATUS."
            },
            {
                "uid": "User ID."
            },
            {
                "url": "The URL address of the externally injected stream."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreammessage",
        "name": "STREAM_MESSAGE",
        "description": "Occurs when the local user receives the data stream from the remote user.The SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "data": "The data received."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreammessageerror",
        "name": "STREAM_MESSAGE_ERROR",
        "description": "Occurs when the local user does not receive the data stream from the remote user.The SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "code": "The error code. See Error Codes and Warning Codes."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_ontokenprivilegewillexpire",
        "name": "TOKEN_PRIVILEGE_WILL_EXPIRE",
        "description": "Occurs when the token expires in 30 seconds.When the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token. Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_ontranscodingupdated",
        "name": "TRANSCODING_UPDATED",
        "description": "Occurs when the publisher's transcoding is updated.If you call the setLiveTranscoding method to set the LiveTranscoding class for the first time, the SDK does not trigger this callback.\n        When the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the TRANSCODING_UPDATED callback to report the update information.",
        "parameters": [
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onuserjoined",
        "name": "USER_JOINED",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.In a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n  A remote user/host joins the channel by calling the joinChannel method.\n  A remote user switches the user role to the host by calling the setClientRole method after joining the channel.\n  A remote user/host rejoins the channel after a network interruption.\n  The host injects an online media stream into the channel by calling the addInjectStreamUrl method.",
        "parameters": [
            {
                "uid": "The ID of the user or host who joins the channel."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            },
            {
                "elapsed": "Time delay (ms) fromthe local user calling joinChannel until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onuseroffline",
        "name": "USER_OFFLINE",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.There are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections. It's recommended to use the Agora RTM SDK for reliable offline detection.",
        "parameters": [
            {
                "reason": "Reason why the user goes offline: USER_OFFLINE_REASON_TYPE."
            },
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideopublishstatechanged",
        "name": "VIDEO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the video publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "null": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideosizechanged",
        "name": "VIDEO_SIZE_CHANGED",
        "description": "Occurs when the video size or rotation of a specified user changes.",
        "parameters": [
            {
                "rotation": "The rotation information. The value range is [0,360)."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "uid": "The ID of the user whose video size or rotation changes. uid is 0 for the local user."
            },
            {
                "rtcChannel": "AgoraRtcChannel."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideosubscribestatechanged",
        "name": "VIDEO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the video subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "null": ""
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_publish",
        "name": "publish",
        "description": "Publish local audio and video streams to the channel.The call of this method must meet the following requirements, otherwise the SDK returns -5(ERR_REFUSED):\n  This method only supports publishing audio and video streams to the channel corresponding to the current AgoraRtcChannel object.\n  In the interactive live streaming channel, only a host can call this method. To switch the client role, call setClientRole of the current AgoraRtcChannel object.\n  You can publish a stream to only one channel at a time. For details on joining multiple channels, see the advanced guide Join Multiple Channels.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      -5 (ERR_REFUSED): The request is rejected."
    },
    {
        "id": "api_ichannel_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.Call this method before joinChannel.\n  This method applies only to interactive live streaming.",
        "parameters": [
            {
                "observer": "Pointers to the registered metadata observer. See ."
            },
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA.\n                        For details, see METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_release",
        "name": "release",
        "description": "Releases the AgoraRtcChannel instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Create and\n                            initialize the AgoraRtcChannel instance before calling this\n                            method."
    },
    {
        "id": "api_ichannel_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.After a successful method, the SDK triggers the USER_OFFLINE callback\n                with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.\n       \n   \n        After a successful method call, the SDK triggers RTMP_STREAMING_STATE_CHANGED on the local client to report the result of deleting the address.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese characters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_renewtoken",
        "name": "renewToken",
        "description": "Renews the token.Passes a new token to the SDK. A token expires after a certain period of time. The app should get a new token and call this method to pass the token to the SDK. Failure to do so results in the SDK disconnecting from the server.\n                    The SDK triggers the TOKEN_PRIVILEGE_WILL_EXPIRE callback.\n                    The CONNECTION_STATE_CHANGED callback reports CONNECTION_CHANGED_TOKEN_EXPIRED(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_sendmetadata",
        "name": "sendMetadata",
        "description": "Sends media metadata.After a successful method call of registerMediaMetadataObserver, the SDK triggers the READY_TO_SEND_METADATA callback, and then you can call this method to send media metadata.\n            If the metadata is sent successfully, the SDK triggers the METADATA_RECEIVED callback on the receiver.",
        "parameters": [
            {
                "metadata": "Media metadata. See Metadata."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_ichannel_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.Sends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the STREAM_MESSAGE callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the STREAM_MESSAGE_ERROR callback on the remote client.\n   \n       Ensure that you call createDataStreamWithConfig to create a data channel before calling this method.\n       In live streaming scenarios, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStreamWithConfig."
            },
            {
                "message": "The message to be sent."
            },
            {
                "length": "The length of the data."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setclientrole1",
        "name": "setClientRole",
        "description": "Sets the user role in an interactive live streaming channel.You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:The local client: CLIENT_ROLE_CHANGED.The remote client: USER_JOINED or USER_OFFLINE (USER_OFFLINE_BECOME_AUDIENCE).\n   This method applies only to interactive live streaming.",
        "parameters": [
            {
                "role": "\n      The user role in the interactive live streaming. See CLIENT_ROLE_TYPE.\n  "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -1(ERR_FAILED): A general error occurs (no specified reason).\n -2(ERR_INALID_ARGUMENT): The parameter is invalid.\n -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_setclientrole2",
        "name": "setClientRoleWithOptions",
        "description": "Sets the user role and level in an interactive live streaming channel.You can call this method either before or after joining the channel to set the user role as audience or host.\n   \n       \n  Since\n  v3.2.0\n       \n   \n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:\n       The local client: CLIENT_ROLE_CHANGED.\n       The remote client: USER_JOINED or USER_OFFLINE.\n   \n   \n       \n       This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).\n       The difference between this method and \n      The user role determines the permissions that the SDK grants to a user, such as permission to send local streams, receive remote streams, and push streams to a CDN address.\n      The user level determines the level of services that a user can enjoy within the permissions of the user's role. For example, an audience can choose to receive remote streams with low latency or ultra-low latency. Levels affect prices.\n    setClientRole[1/2] is that this method can set the user level in addition to the user role.",
        "parameters": [
            {
                "role": "The user role in a live interactive streaming. See CLIENT_ROLE_TYPE."
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       \n  Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n       \n  If you need to resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream (false), and specify the user ID.\n  If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream (false) multiple times.",
        "parameters": [
            {
                "mute": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            \n       \n  Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   \n       If you need to resume subscribing to the video streams of remote users in the channel, do the following:\n       \n  If you need to resume subscribing to a single user, call muteRemoteVideoStream(false) and specify the ID of the remote user you want to subscribe to.\n  If you want to resume subscribing to multiple users, call muteRemoteVideoStream(false) multiple times.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.The Agora SDK supports built-in encryption. The default encryption is AES-128-XTS. Call this method to use other encryption modes. All users in the same channel must use the same encryption mode and secret. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   \n       \n  Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.\n       \n   \n   Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "\n      Encryption mode.\n     \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     \"\": When setting as an empty string, the encryption mode is set as\n                                        \"aes-128-xts\" by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.Do not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.\n       \n   \n        Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If the secret is not set or secret is set as null, the built-in encryption is disabled.\n   \n       \n  Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.This method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the TRANSCODING_UPDATED callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n   This method sets the video layout and audio settings for CDN live streaming. The SDK triggers the TRANSCODING_UPDATED callback when you call this method to update the transcoding setting.",
        "parameters": [
            {
                "transcoding": "\n      The transcoding configurations for CDN live streaming. See LiveTranscoding."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setmaxmetadatasize",
        "name": "setMaxMetadataSize",
        "description": "Sets the maximum size of the media metadata.After calling registerMediaMetadataObserver, you can call this method to set the maximum size of the media metadata.",
        "parameters": [
            {
                "size": "The maximum size of media metadata."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote video streams.The method result returns in the API_CALL_EXECUTED callback.\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n   Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-quality video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n   Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.Since\n                         v2.4.0\n                    \n               \n               Prioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See PRIORITY_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "Sets the stream type of the remote video.The method result returns in the API_CALL_EXECUTED callback.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n               Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "userId": "User ID."
            },
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the sound position and gain of a remote user.This method sets the sound position and gain of a remote user.\n   When the local user calls this method to set the sound position of a remote user, the sound difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a real sense of space. This method applies to massively multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n  This method requires hardware support. For the best sound positioning, we recommend using a stereo speaker.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "pan": "The sound position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: the remote sound comes from the front.\n -1.0: the remote sound comes from the left.\n 1.0: the remote sound comes from the right.\n      \n  "
            },
            {
                "gain": "The gain of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original gain of the remote user). The smaller the value, the less the gain."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE_CHANGED and CHANNEL_MEDIA_RELAY_EVENT callbacks, and these callbacks return the state and events of the media stream relay.\n  If the CHANNEL_MEDIA_RELAY_STATE_CHANGED callback returns RELAY_STATE_RUNNING(2) and RELAY_OK(0), and the CHANNEL_MEDIA_RELAY_EVENT callback returns RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL(4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the CHANNEL_MEDIA_RELAY_STATE_CHANGED callback returns RELAY_STATE_FAILURE(3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a live streaming channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE_CHANGED callback. If the callback reports RELAY_STATE_IDLE(0) and RELAY_OK(0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE_CHANGED callback with the RELAY_ERROR_SERVER_NO_RESPONSE(2) or RELAY_ERROR_SERVER_CONNECTION_LOST(8) status code. You can call the leaveChannel method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_unpublish",
        "name": "unpublish",
        "description": "Stops publishing a stream to the channel.If you call this method in a channel where you are not publishing streams, the SDK returns\n                    -5 (ERR_REFUSED).",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      -5 (ERR_REFUSED): The request is rejected."
    },
    {
        "id": "api_ichannel_unregistermediametadataobserver",
        "name": "unregisterMediaMetadataObserver",
        "description": "Unregisters the media metadata observer.",
        "parameters": [
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA. For details, see METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_ichannel_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.After the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_EVENT callback with the RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL(7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_initialize",
        "name": "initializeWithContext",
        "description": "Initializes AgoraRtcEngine.Before calling other APIs, you must call initializeWithContext to create an AgoraRtcEngine object.",
        "parameters": [
            {
                "config": "\n                        Configurations for the AgoraRtcEngine instance. For details, see RtcEngineContext.\n                    "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2(ERR_INVALID_ARGUMENT): An invalid parameter is used.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -22(ERR_RESOURCE_LIMITED): The resource is limited. The SDK fails to allocate resources because your app uses too many system resources or system resources are insufficient.\n  -101(ERR_INVALID_APP_ID): The App ID is invalid."
    },
    {
        "id": "api_ivideodevicemanager_getdevice",
        "name": "getCurrentVideoDevice",
        "description": "Retrieves the video capture device that is in use.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n   \n            The video capture device. See Device."
    },
    {
        "id": "api_ivideodevicemanager_setdevice",
        "name": "setVideoDevice",
        "description": "Specifies the video capture device with the device ID.Plugging or unplugging a device does not change its device ID.",
        "parameters": [
            {
                "deviceId": "The device ID. You can get the device ID by calling getVideoDevices.\n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_joinchannel2",
        "name": "joinChannel",
        "description": "Joins a channel with the user ID, and configures whether to automatically subscribe to the audio or video streams.Since\n  v3.3.0\n       \n   \n            This method joins an Agora RTC channel. Users with the same App ID in the same channel can talk to each other, and multiple users in the same channel can start a group chat.\n            A successful call of this method triggers the following callbacks:\n                The local client: The JOINED_CHANNEL and CONNECTION_STATE_CHANGED callbacks.\n                The remote client: USER_JOINED, if the user joining the channel is in the communication profile, or is a host in the live streaming profile.\n            \n            When the connection between the client and Agora's server is interrupted due to poor network conditions, the SDK tries reconnecting to the server. When the local client successfully rejoins the channel, the SDK triggers the REJOIN_CHANNEL_SUCCESS callback on the local client.",
        "parameters": [
            {
                "token": "\n    The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n      "
            },
            {
                "channelId": "\n      The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel name enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "uid": "User ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. A 32-bit unsigned integer with a value ranging from 1 to 232-1. If the user ID is not assigned (or set to 0), the SDK assigns and returns a user ID in the JOINED_CHANNEL callback. Your application must record and maintain the returned user ID, because the SDK does not do so."
            },
            {
                "options": "The channel media options. See ChannelMediaOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an AgoraRtcChannel object with the same channel name.\n      You have joined and published a stream in an AgoraRtcChannel channel created by the AgoraRtcChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the AgoraRtcEngine instance before calling this method."
    },
    {
        "id": "api_joinchannelwithuseraccount2",
        "name": "joinChannelWithUserAccount",
        "description": "Joins the channel with a user account, and configures whether to automatically subscribe to audio or video streams after joining the channel.Since\n  v3.3.0\n       \n   \n   This method allows a user to join the channel with the user account. After the user successfully joins the channel, the SDK triggers the following callbacks:\n  The local client: LOCAL_USER_REGISTERED, JOINED_CHANNEL and the CONNECTION_STATE_CHANGED callbacks.\n  The remote client: The USER_JOINED callback if the user is in the COMMUNICATION profile, and the USER_INFO_UPDATED callback if the user is a host in the LIVE_BROADCASTING profile.\n       \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "channelId": "\n      The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel name enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n      "
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an AgoraRtcChannel object with the same channel name.\n      You have joined and published a stream in an AgoraRtcChannel channel created by the AgoraRtcChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the AgoraRtcEngine instance before calling this method."
    },
    {
        "id": "api_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.This method releases all resources related to the session. This method call is asynchronous, and the user has not left the channel when the method call returns.\n   After calling joinChannel, you must call leaveChannel to end the call, otherwise the next call cannot be started.\n   A successful call of this method triggers the following callbacks:\n                    The local client: LEAVE_CHANNEL.\n                    The remote client: USER_OFFLINE, if the user joining the channel is in the communication profile, or is a host in the live streaming profile.\n                \n   \n       \n  If you call the leaveChannel method immediately after calling release, the SDK will not be able to trigger the LEAVE_CHANNEL callback.\n  If you call the leaveChannel method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.",
        "parameters": [
            {
                "mute": "Whether to subscribe to the audio streams of all remote users:\n                                true: Do not subscribe to the\n                                    audio streams of all remote users.\n                                false: (Default) Subscribe to\n                                    the audio streams of all remote users by default.\n                            \n                        \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the video streams of all remote users.\n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_mutelocalaudiostream",
        "name": "muteLocalAudioStream",
        "description": "Stops or resumes publishing the local audio stream.A successful call of this method triggers the USER_MUTE_AUDIO callback on the remote client.\n   \n       \n  This method does not affect any ongoing audio recording, because it does not disable the microphone.\n  You can call this method either before or after joining a channel. If you call the setChannelProfile method after this method, the SDK resets whether or not to stop publishing the local audio according to the channel profile and user role. Therefore, Agora recommends calling this method after the setChannelProfile method.",
        "parameters": [
            {
                "mute": "Whether to stop publishing the local audio stream.\n  \n      true: Stop publishing the local audio stream.\n      false: (Default) Resumes publishing the local audio stream.\n  \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_mutelocalvideostream",
        "name": "muteLocalVideoStream",
        "description": "Stops or resumes publishing the local video stream.A successful call of this method triggers the USER_MUTE_VIDEO callback on the remote client.\n            \n                    \n                        This method executes faster than the enableLocalVideo(false) method, which controls the sending of the local video stream.\n                        This method does not affect any ongoing video recording, because it does not disable the camera.\n                        You can call this method either before or after joining a channel. If you call setChannelProfile after this method, the SDK resets whether or not to stop publishing the local video according to the channel profile and user role. Therefore, Agora recommends calling this method after the setChannelProfile method.",
        "parameters": [
            {
                "mute": "\n                        Whether to stop publishing the local video stream.\n                            true: Stop publishing the local video stream.\n                            false: (Default) Publish the local video stream.\n                        \n                        \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The user ID of the specified user."
            },
            {
                "mute": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user by default.\n false: (Default) Subscribe to the audio stream of the specified user by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.",
        "parameters": [
            {
                "userId": "\n      The user ID of the specified user.\n  "
            },
            {
                "mute": "Whether to stop subscribing to the video stream of the specified user.\n      true:Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_onactivespeaker",
        "name": "ACTIVE_SPEAKER",
        "description": "Occurs when the most active speaker is detected.After a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of users is no less than two and an active speaker exists, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker is always the same user, the SDK triggers the ACTIVE_SPEAKER callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": "The user ID of the most active speaker."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onapicallexecuted",
        "name": "API_CALL_EXECUTED",
        "description": "Occurs when a method is executed by the SDK.",
        "parameters": [
            {
                "err": "The error code returned by the SDK when the method call fails. For detailed error information and troubleshooting methods, see Error Code and Warning Code. If the SDK returns 0, then the method call is successful."
            },
            {
                "api": "The method executed by the SDK."
            },
            {
                "result": "The result of the method call."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onapierror",
        "name": "API_ERROR",
        "description": "Occurs when an error occurs in Electron.During the SDK runtime, the SDK triggers this callback when an error occurs in Electron.",
        "parameters": [
            {
                "apiType": "The internal engine. You can ignore this parameter."
            },
            {
                "msg": "The error message. A typical reason is incorrect parameter setting in the API call, for example invalid value or incorrect number of parameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiodevicestatechanged",
        "name": "AUDIO_DEVICE_STATE_CHANGED",
        "description": "Occurs when the audio device state changes.This callback notifies the application that the system's audio device state is changed. For example, a headset is unplugged from the device.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "The device type. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "The device state. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiodevicevolumechanged",
        "name": "AUDIO_DEVICE_VOLUME_CHANGED",
        "description": "Occurs when the volume on the playback or audio capture device, or the volume in the application changes.",
        "parameters": [
            {
                "deviceType": "The device type. See MEDIA_DEVICE_TYPE."
            },
            {
                "volume": "The volume value. The range is [0, 255]."
            },
            {
                "muted": "Whether the audio device is muted:\n      true: The audio device is muted.\n      false: The audio device is not muted.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudioeffectfinished",
        "name": "AUDIO_EFFECT_FINISHED",
        "description": "Occurs when the playback of the local audio effect file finishes.This callback occurs when the local audio effect file finishes playing.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiomixingfinished",
        "name": "AUDIO_MIXING_FINISHED",
        "description": "Occurs when the playback of the local music file finishes.Deprecated:\n  This method is deprecated as of v2.4.0. Use AUDIO_MIXING_STATE_CHANGED instead.\n       \n   \n   After you call startAudioMixing to play a local music file, this callback occurs when the playback finishes. If the call of startAudioMixing fails, the ERROR callback returns the error code WARN_AUDIO_MIXING_OPEN_ERROR.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onaudiomixingstatechanged",
        "name": "AUDIO_MIXING_STATE_CHANGED",
        "description": "Occurs when the playback state of the music file changes.This callback occurs when the playback state of the music file changes, and reports the current state and error code.",
        "parameters": [
            {
                "state": "The playback state of the music file. See AUDIO_MIXING_STATE_TYPE. "
            },
            {
                "reason": "The error code. See AUDIO_MIXING_ERROR_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiopublishstatechanged",
        "name": "AUDIO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the audio publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiosubscribestatechanged",
        "name": "AUDIO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the audio subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiovolumeindication",
        "name": "AUDIO_VOLUME_INDICATION",
        "description": "Reports the volume information of users.By default, this callback is disabled. You can enable it by calling enableAudioVolumeIndication. Once this callback is enabled and users send streams in the channel, the SDK triggers the AUDIO_VOLUME_INDICATION callback at the time interval set in enableAudioVolumeIndication. The SDK triggers two independent AUDIO_VOLUME_INDICATION callbacks simultaneously, which separately report the volume information of the local user who sends a stream and the remote users (up to three) whose instantaneous volumes are the highest.\n   After you enable this callback, calling muteLocalAudioStream affects the SDK's behavior as follows:\n  If the local user stops publishing the audio stream, the SDK stops triggering the local user's callback.\n  20 seconds after a remote user whose volume is one of the three highest stops publishing the audio stream, the callback excludes this user's information; 20 seconds after all remote users stop publishing audio streams, the SDK stops triggering the callback for remote users.",
        "parameters": [
            {
                "speakers": "The volume information of the users, see AudioVolumeInfo. An empty speakers array in the callback indicates that no remote user is in the channel or sending a stream at the moment."
            },
            {
                "totalVolume": "\n      The volume of the speaker. The value ranges between 0 (lowest volume) and 255 (highest volume).\n     In the callback for the local user, totalVolume is the volume of the local user who sends a stream.\n     In the callback for remote users, totalVolume is the sum of the volume of all remote users (up to three) whose instantaneous volumes are the highest. If the user calls startAudioMixing, then totalVolume is the volume after audio mixing.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncameraexposureareachanged",
        "name": "CAMERA_EXPOSURE_AREA_CHANGED",
        "description": "Occurs when the camera exposure area changes.",
        "parameters": [
            {
                "x": "The x coordinate of the changed camera exposure area."
            },
            {
                "y": "The y coordinate of the changed camera exposure area."
            },
            {
                "width": "The width of the changed camera exposure area."
            },
            {
                "height": "The height of the changed exposure area."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncamerafocusareachanged",
        "name": "CAMERA_FOCUS_AREA_CHANGED",
        "description": "Occurs when the camera focus area changes.This method applies to mobile platforms only.",
        "parameters": [
            {
                "x": "The x coordinate of the changed camera focus area."
            },
            {
                "y": "The y coordinate of the changed camera focus area."
            },
            {
                "width": "The width of the changed camera focus area."
            },
            {
                "height": "The height of the changed camera focus area."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncameraready",
        "name": "CAMERA_READY",
        "description": "Occurs when the camera turns on and is ready to capture the video.Deprecated:\n  \n                        This callback is deprecated. Please use LOCAL_VIDEO_STREAM_STATE_CAPTURING(1) in LOCAL_VIDEO_STATE_CHANGED instead.\n                    \n       \n   \n   This callback indicates that the camera has been successfully turned on and you can start to capture video.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onchannelmediarelayevent",
        "name": "CHANNEL_MEDIA_RELAY_EVENT",
        "description": "Reports events during the media stream relay.",
        "parameters": [
            {
                "code": "The event code of channel media relay. See CHANNEL_MEDIA_RELAY_EVENT."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onchannelmediarelaystatechanged",
        "name": "CHANNEL_MEDIA_RELAY_STATE",
        "description": "Occurs when the state of the media stream relay changes.The SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "state": "The state code. See CHANNEL_MEDIA_RELAY_STATE."
            },
            {
                "code": "The error code of the channel media replay. See CHANNEL_MEDIA_RELAY_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onclientrolechanged",
        "name": "CLIENT_ROLE_CHANGED",
        "description": "Occurs when the user role switches in the interactive live streaming.The SDK triggers this callback when the local user switches the user role by calling setClientRoleWithOptions after joining the channel.",
        "parameters": [
            {
                "oldRole": "Role that the user switches from: CLIENT_ROLE_TYPE."
            },
            {
                "newRole": "Role that the user switches to: CLIENT_ROLE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onconnectionbanned",
        "name": "CONNECTION_BANNED",
        "description": "Occurs when the connection is banned by the Agora server.Deprecated:\n  Please use CONNECTION_STATE_CHANGED instead.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectioninterrupted",
        "name": "CONNECTION_INTERRUPTED",
        "description": "Occurs when the connection between the SDK and the server is interrupted.Deprecated:\n  Please use CONNECTION_STATE_CHANGED instead.\n       \n   \n   The SDK triggers this callback when it loses connection with the server for more than four seconds after the connection is established. After triggering this callback, the SDK tries to reconnect to the server. You can use this callback to implement pop-up reminders. The difference between this callback and CONNECTION_LOST is:\n       The SDK triggers the CONNECTION_INTERRUPTED callback when it loses connection with the server for more than four seconds after it successfully joins the channel.\n       The SDK triggers the CONNECTION_LOST callback when it loses connection with the server for more than 10 seconds, whether or not it joins the channel.\n   If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectionlost",
        "name": "CONNECTION_LOST",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.The SDK triggers this callback when it cannot connect to the server 10 seconds after calling the joinChannel method, regardless of whether it is in the channel. If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectionstatechanged",
        "name": "CONNECTION_STATE_CHANGED",
        "description": "Occurs when the network connection state changes.Since\n  v2.3.2\n       \n   \n   When the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "state": "The current connection state. See CONNECTION_STATE_TYPE."
            },
            {
                "reason": "The reason for a connection state change. See CONNECTION_CHANGED_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onerror",
        "name": "ERROR",
        "description": "Reports an error during SDK runtime.This callback indicates that an error occurs during SDK runtime. In most cases, the SDK cannot fix the issue and resume running. The SDK requires the application to take action or informs the user about the issue. For example, the SDK reports an ERR_START_CALL error when failing to initialize a call. The app informs the user that the call initialization failed and invokes the leaveChannel method to leave the channel.",
        "parameters": [
            {
                "err": "The error code. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalaudioframe",
        "name": "FIRST_LOCAL_AUDIO_FRAME",
        "description": "Occurs when the engine sends the first local audio frame.Deprecated:\n  This callback is deprecated as of v3.1.0, please use the FIRST_LOCAL_AUDIO_FRAME_PUBLISHED callback instead.",
        "parameters": [
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalaudioframepublished",
        "name": "FIRST_LOCAL_AUDIO_FRAME_PUBLISHED",
        "description": "Occurs when the first audio frame is published.Since\n                    v3.1.0\n                \n            \n            The SDK triggers this callback under one of the following circumstances:\n                    The local client enables the audio module and calls joinChannel successfully.\n                    The local client calls muteLocalAudioStream(true) and muteLocalAudioStream(false) in sequence.\n                    The local client calls disableAudio and enableAudio in sequence.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalvideoframe",
        "name": "FIRST_LOCAL_VIDEO_FRAME",
        "description": "Occurs when the first local video frame is rendered.The SDK triggers this callback when the first local video frame is displayed/rendered on the local video view.",
        "parameters": [
            {
                "width": "The width (px) of the first local video frame."
            },
            {
                "height": "The height (px) of the first local video frame."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback. If\n                              you call startPreview before calling joinChannel, then this parameter is the time elapsed\n                              from calling the startPreview method until the SDK\n                              triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalvideoframepublished",
        "name": "FIRST_LOCAL_VIDEO_FRAME_PUBLISHED",
        "description": "Occurs when the first video frame is published.Since\n  v3.1.0\n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n  The local client enables the video module and calls joinChannel successfully.\n  The local client calls muteLocalVideoStream(true) and muteLocalVideoStream(false) in sequence.\n  The local client calls disableVideo and enableVideo in sequence.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremoteaudiodecoded",
        "name": "FIRST_REMOTE_AUDIO_DECODED",
        "description": "Occurs when the SDK decodes the first remote audio frame for playback.Deprecated:\n  Deprecated as of v3.0.0. Please use REMOTE_AUDIO_STATE_CHANGED instead.\n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n                    The remote user joins the channel and sends the audio stream.\n                    The remote user stops sending the audio stream and re-sends it after 15 seconds. The remote user stops sending the audio stream and re-sends it after 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalAudioStream to stop sending the audio stream.\n                            The remote user calls disableAudio to disable audio.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremoteaudioframe",
        "name": "FIRST_REMOTE_AUDIO_FRAME",
        "description": "Occurs when the SDK receives the first audio frame from a specific remote user.Deprecated:\n  This callback is deprecated as of v3.0.0. Please use REMOTE_AUDIO_STATE_CHANGED instead.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremotevideodecoded",
        "name": "FIRST_REMOTE_VIDEO_DECODED",
        "description": "Occurs when the first remote video frame is received and decoded.Deprecated:\n  Deprecated as of v2.9.0, please use the REMOTE_VIDEO_STATE_CHANGED callback with the following parameters:\n      REMOTE_VIDEO_STATE_STARTING (1).\n      REMOTE_VIDEO_STATE_DECODING (2).\n  \n  \n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n                    The remote user joins the channel and sends the video stream.\n                    The remote user stops sending the video stream and re-sends it after 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves the channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalVideoStream to stop sending the video stream.\n                            The remote user calls disableVideo to disable video.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremotevideoframe",
        "name": "FIRST_REMOTE_VIDEO_FRAME",
        "description": "Occurs when the first remote video frame is rendered.The SDK triggers this callback when the first local video frame is displayed/rendered on the local video view. The application can retrieve the time elapsed (the elapsed parameter) from a user joining the channel until the first video frame is displayed.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "Time elapsed(ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onjoinchannelsuccess",
        "name": "JOINED_CHANNEL",
        "description": "Occurs when a user joins a channel.This callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the user who joins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlastmileproberesult",
        "name": "LASTMILE_PROBE_RESULT",
        "description": "Reports the last mile network probe result.Since\n                    v2.4.0\n                \n            \n            The SDK triggers this callback within 30 seconds after the app calls startLastmileProbeTest.",
        "parameters": [
            {
                "result": "The uplink and downlink last mile network probe test result. See LastmileProbeResult."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlastmilequality",
        "name": "LASTMILE_QUALITY",
        "description": "Reports the last mile network quality of the local user once every two seconds.This callback reports the last-mile network conditions of the local user before the user joins the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   After the app calls enableLastmileTest, the SDK triggers this callback once every two seconds.",
        "parameters": [
            {
                "quality": "The last mile network quality. See QUALITY_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onleavechannel",
        "name": "LEAVE_CHANNEL",
        "description": "Occurs when a user leaves a channel.This callback notifies the app that the user leaves the channel by calling leaveChannel. From this callback, the app can get information such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalaudiostatechanged",
        "name": "LOCAL_AUDIO_STATE_CHANGED",
        "description": "Occurs when the local audio stream state changes.Since\n                    v2.9.0\n                \n            \n            When the state of the local audio stream changes (including the state of the audio capture and encoding), the SDK triggers this callback to report the current state. This callback allows you to troubleshoot issues when audio exceptions occur.\n            When the state is LOCAL_AUDIO_STREAM_STATE_FAILED(3), you can view the error information in the error parameter.",
        "parameters": [
            {
                "state": "The state of the local audio. See LOCAL_AUDIO_STREAM_STATE."
            },
            {
                "error": "Local audio state error codes. See LOCAL_AUDIO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalaudiostats",
        "name": "LOCAL_AUDIO_STATS",
        "description": "Reports the statistics of the local audio stream.The SDK triggers this callback once every two seconds.",
        "parameters": [
            {
                "stats": "Local audio statistics. See LocalAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalpublishfallbacktoaudioonly",
        "name": "LOCAL_PUBLISH_FALLBACK_TO_AUDIO_ONLY",
        "description": "Occurs when the published media stream falls back to an audio-only stream due to poor network conditions or switches back to the video after the network conditions improve.If you call setLocalPublishFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   If the local stream fallbacks to the audio-only stream, the remote user receives the USER_MUTE_VIDEO callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n      \n true: The published stream falls back to audio-only due to poor network conditions.\n false: The published stream switches back to the video after the network conditions improve.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocaluserregistered",
        "name": "LOCAL_USER_REGISTERED",
        "description": "Occusr when the local use registers a user account.Since\n  v2.8.0\n       \n   \n   After the local user successfully calls registerLocalUserAccount to register the user account or calls joinChannelWithUserAccount to join a channel, the SDK triggers the callback and informs the local user's UID and User Account.",
        "parameters": [
            {
                "uid": "The ID of the local user."
            },
            {
                "userAccount": "The user account of the local user."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalvideostatechanged",
        "name": "LOCAL_VIDEO_STATE_CHANGED",
        "description": "Occurs when the local video stream state changes.Since\n                    v2.4.1\n                \n            \n            When the state of the local video stream changes (including the state of the video capture and encoding), the SDK triggers this callback to report the current state. This callback indicates the state of the local video stream, including camera capturing and video encoding, and allows you to troubleshoot issues when exceptions occur.\n            The SDK triggers the LOCAL_VIDEO_STATE_CHANGED callback with the state code LOCAL_VIDEO_STREAM_STATE_FAILED and error code LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE in the following situations:\n                    The app switches to the background, and the system gets the camera resource.\n                    The camera starts normally, but does not output video for four consecutive seconds.\n                \n            \n            When the camera outputs the captured video frames, if the video frames are the same for 15 consecutive frames, the SDK triggers the LOCAL_VIDEO_STATE_CHANGED callback with the state code LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE and error code LOCAL_VIDEO_STREAM_STATE_CAPTURING. Note that the video frame duplication detection is only available for video frames with a resolution greater than 200 × 200, a frame rate greater than or equal to 10 fps, and a bitrate less than 20 Kbps.\n            For some device models, the SDK does not trigger this callback when the state of the local video changes while the local video capturing device is in use, so you have to make your own timeout judgment.",
        "parameters": [
            {
                "localVideoState": "The state of the local video, see LOCAL_VIDEO_STREAM_STATE."
            },
            {
                "error": "The detailed error information, see LOCAL_VIDEO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalvideostats",
        "name": "LOCAL_VIDEO_STATS",
        "description": "Reports the statistics of the local video stream.The SDK triggers this callback once every two seconds to report the statistics of the local video stream.",
        "parameters": [
            {
                "stats": "The statistics of the local video stream. See LocalVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onmediaenginestartcallsuccess",
        "name": "MEDIA_ENGINE_START_CALL_SUCCESS",
        "description": "Occurs when the media engine call starts.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onmetadatareceived",
        "name": "METADATA_RECEIVED",
        "description": "Occurs when the local user receives Metadata.",
        "parameters": [
            {
                "metadata": "The received metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onmicrophoneenabled",
        "name": "MICROPHONE_ENABLED",
        "description": "Occurs when the microphone is enabled/disabled.Deprecated:\n                    \n                        This callback is deprecated as of v2.9.0. Please use the LOCAL_AUDIO_STATE_CHANGED callback:\n                                LOCAL_AUDIO_STREAM_STATE_STOPPED(0).\n                                LOCAL_AUDIO_STREAM_STATE_RECORDING(1).\n                            \n                    \n                \n            \n            The SDK triggers this callback when the local user resumes or stops capturing the local audio stream by calling the enableLocalAudio method.",
        "parameters": [
            {
                "enabled": "\n                        Whether the microphone is enabled/disabled:\n                                true: The microphone is enabled.\n                                false: The microphone is disabled.\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onnetworkquality",
        "name": "NETWORK_QUALITY",
        "description": "Reports the last mile network quality of each user in the channel.This callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "uid": "User ID. The network quality of the user with this user ID is reported. If the uid is 0, the local network quality is reported."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the uplink network. This parameter is a quality rating helping you understand how well the current uplink network conditions can support the selected video encoder configuration. For example, a 1000 Kbps uplink network may be adequate for video frames with a resolution of 640 × 480 and a frame rate of 15 fps in the LIVE_BROADCASTING profile, but might be inadequate for resolutions higher than 1280 × 720. See QUALITY_TYPE."
            },
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate, average RTT, and jitter of the downlink network. See QUALITY_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onnetworktypechanged",
        "name": "NETWORK_TYPE_CHANGED",
        "description": "Occurs when the local network type changes.Since\n  v2.4.1\n       \n   \n   This callback occurs when the connection state of the local user changes. You can get the connection state and reason for the state change in this callback. When the network connection is interrupted, this callback indicates whether the interruption is caused by a network type change or poor network conditions.",
        "parameters": [
            {
                "type": "The type of the local network connection. See NETWORK_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onreadytosendmetadata",
        "name": "READY_TO_SEND_METADATA",
        "description": "Occurs when the SDK is ready to send Metadata.This callback is triggered when the SDK is ready to receive and send Metadata.\n   Ensure that the size of the Metadata does not exceed the value set in the  callback.",
        "parameters": [
            {
                "metadata": "The metadata to be sent."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrejoinchannelsuccess",
        "name": "REJOIN_CHANNEL_SUCCESS",
        "description": "Occurs when a user rejoins the channel.When a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "channelId": "The name of the channel."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiomixingbegin",
        "name": "REMOTE_AUDIO_MIXING_BEGIN",
        "description": "Occurs when a remote user starts audio mixing.When a remote user calls startAudioMixing to play the background music, the SDK reports this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiomixingend",
        "name": "REMOTE_AUDIO_MIXING_END",
        "description": "Occurs when a remote user finishes audio mixing.The SDK triggers this callback when a remote user finishes audio mixing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiostatechanged",
        "name": "REMOTE_AUDIO_STATE_CHANGED",
        "description": "Occurs when the remote audio state changes.Since\n                        v2.9.0\n                    \n                \n               When the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "state": "The state of the remote audio, see REMOTE_AUDIO_STATE."
            },
            {
                "reason": "The reason of the remote audio state change, see REMOTE_AUDIO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiostats",
        "name": "REMOTE_AUDIO_STATS",
        "description": "Reports the transport-layer statistics of each remote audio stream.The SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiotransportstats",
        "name": "REMOTE_AUDIO_TRANSPORT_STATS",
        "description": "Reports the transport-layer statistics of each remote audio stream.Deprecated:\n      This callback is deprecated, please use REMOTE_AUDIO_STATS instead.\n  \n       \n   \n            This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives an audio packet from a remote user. During a call, when the user receives the audio packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the audio streams."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the receiver."
            },
            {
                "rxKBitrate": "Bitrate of the received audio (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotesubscribefallbacktoaudioonly",
        "name": "REMOTE_SUBSCRIBE_FALLBACK_TO_AUDIO_ONLY",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.If you call setRemoteSubscribeFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor downlink conditions, or when the remote media stream switches back to the video after the downlink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "isFallbackOrRecover": "\n      \n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideostatechanged",
        "name": "REMOTE_VIDEO_STATE_CHANGED",
        "description": "Occurs when the remote video state changes.Since\n                        v2.9.0\n                    \n                \n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "state": "The state of the remote video, see REMOTE_VIDEO_STATE."
            },
            {
                "reason": "The reason for the remote video state change, see REMOTE_VIDEO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideostats",
        "name": "REMOTE_VIDEO_STATS",
        "description": "Reports the transport-layer statistics of each remote video stream.Reports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. See RemoteVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideotransportstats",
        "name": "REMOTE_VIDEO_TRANSPORT_STATS",
        "description": "Reports the transport-layer statistics of each remote video stream.Deprecated:\n  This callback is deprecated, please use REMOTE_VIDEO_STATS instead.\n       \n   \n   This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives a video packet from a remote user.\n   During a call, when the user receives the video packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the video packets."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "The packet loss rate (%) of the video packet sent from the remote user."
            },
            {
                "rxKBitRate": "The bitrate of the received video (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrequesttoken",
        "name": "REQUEST_TOKEN",
        "description": "Occurs when the token expires.When the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n   Once you receive this callback, generate a new token on your app server, and call joinChannel to rejoin the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onrtcstats",
        "name": "RTC_STATS",
        "description": "Reports the statistics of the current call.The SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": "\n      Statistics of the RTC engine, see RtcStats for details.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrtmpstreamingevent",
        "name": "RTMP_STREAMING_EVENT",
        "description": "Reports events during the RTMP or RTMPS streaming.Since\n  v3.1.0",
        "parameters": [
            {
                "url": "The RTMP or RTMPS streaming URL."
            },
            {
                "eventCode": "The event code of the streaming. See RTMP_STREAMING_EVENT."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrtmpstreamingstatechanged",
        "name": "RTMP_STREAMING_STATE_CHANGED",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.The SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "url": "The CDN streaming URL."
            },
            {
                "state": "The RTMP or RTMPS streaming state, see RTMP_STREAM_PUBLISH_STATE. When the streaming status is RTMP_STREAM_PUBLISH_STATE_FAILURE (4), you can view the error information in the errorCode parameter."
            },
            {
                "errCode": "The detailed error information for streaming, see RTMP_STREAM_PUBLISH_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreaminjectedstatus",
        "name": "STREAM_INJECT_STATUS",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.",
        "parameters": [
            {
                "url": "The URL address of the externally injected stream."
            },
            {
                "uid": "User ID."
            },
            {
                "status": "State of the externally injected stream: INJECT_STREAM_STATUS."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreammessage",
        "name": "STREAM_MESSAGE",
        "description": "Occurs when the local user receives the data stream from the remote user.The SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "data": "The data received."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreammessageerror",
        "name": "STREAM_MESSAGE_ERROR",
        "description": "Occurs when the local user does not receive the data stream from the remote user.The SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "code": "The error code. See Error Codes and Warning Codes."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreampublished",
        "name": "STREAM_PUBLISHED",
        "description": "Occurs when an RTMP or RTMPS stream is published.Deprecated:\n  v3.0.0\n       \n   \n   This method is deprecated, please use RTMP_STREAMING_STATE_CHANGED instead.\n   Reports the result of publishing an RTMP or RTMPS stream.",
        "parameters": [
            {
                "url": "The CDN streaming URL."
            },
            {
                "error": "\n      Error codes of the RTMP or RTMPS streaming.\n                                ERR_OK (0): The publishing succeeds.\n                                ERR_FAILED (1): The publishing fails.\n                                ERR_INVALID_ARGUMENT (-2): Invalid argument used. If you do not call setLiveTranscoding to configure LiveTranscoding before calling addPublishStreamUrl, the SDK reports ERR_INVALID_ARGUMENT.\n                                ERR_TIMEDOUT (10): The publishing timed out.\n                                ERR_ALREADY_IN_USE (19): The chosen URL address is alreadyin usefor CDN live streaming.\n                                ERR_ENCRYPTED_STREAM_NOT_ALLOWED_PUBLISH (130): You cannot publish an encrypted stream.\n                                ERR_PUBLISH_STREAM_CDN_ERROR (151): CDN related error. Remove the original URL address and add a new one by calling the removePublishStreamUrl and addPublishStreamUrl methods.\n                                ERR_PUBLISH_STREAM_NUM_REACH_LIMIT (152): The host manipulates more than 10 URLs. Delete the unnecessary URLs before adding new ones.\n                                ERR_PUBLISH_STREAM_NOT_AUTHORIZED (153): The host manipulates other hosts' URLs. Please check your app logic.\n                                ERR_PUBLISH_STREAM_INTERNAL_SERVER_ERROR: An error occurs in Agora's streaming server. Call the removePublishStreamUrl method to publish the streaming again.\n                                ERR_PUBLISH_STREAM_FORMAT_NOT_SUPPORTED (156): The format of the CDN streaming URL is not supported. Check whether the URL format is correct.\n                            \n                        \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreamunpublished",
        "name": "STREAM_UNPUBLISHED",
        "description": "Occurs when an RTMP or RTMPS stream is removed.Deprecated:\n  v3.0.0\n       \n   \n   This method is deprecated, please use RTMP_STREAMING_STATE_CHANGED instead.",
        "parameters": [
            {
                "url": "The URL of the removed RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ontokenprivilegewillexpire",
        "name": "TOKEN_PRIVILEGE_WILL_EXPIRE",
        "description": "Occurs when the token expires in 30 seconds.When the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token.\n   Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ontranscodingupdated",
        "name": "TRANSCODING_UPDATED",
        "description": "Occurs when the publisher's transcoding is updated.When the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the TRANSCODING_UPDATED callback to report the update information.\n   If you call the setLiveTranscoding method to set the LiveTranscoding class for the first time, the SDK does not trigger this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onuserenablelocalvideo",
        "name": "USER_ENABLE_LOCAL_VIDEO",
        "description": "Occurs when a specific remote user enables/disables the local video capturing function.The SDK triggers this callback when the remote user resumes or stops capturing the video stream by calling the enableLocalVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "Whether the specified remote user enables/disables the local video capturing function:\n true: Enable. Other users in the channel can see the video of this remote user.\n false: Disable. Other users in the channel can no longer receive the video stream from this remote user, while this remote user can still receive the video streams from other users.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserenablevideo",
        "name": "USER_ENABLE_VIDEO",
        "description": "Occurs when a remote user enables/disables the video module.Once the video module is disabled, the user can only use a voice call. The user cannot send or receive any video.\n   The SDK triggers this callback when a remote user enables or disables the video module by calling the enableVideo or disableVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "\n      \n true: Enable.\n false: Disable.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserinfoupdated",
        "name": "USER_INFO_UPDATED",
        "description": "Occurs when the SDK gets the user ID and user account of the remote user.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object (userInfo), and triggers this callback on the local client.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userInfo": "The UserInfo object that contains the user ID and user account of the remote user. See UserInfo for details."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserjoined",
        "name": "USER_JOINED",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.In a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n   A remote user/host joins the channel by calling the joinChannel method.\n   A remote user switches the user role to the host by calling the setClientRoleWithOptions method after joining the channel.\n   A remote user/host rejoins the channel after a network interruption.\n   The host injects an online media stream into the channel by calling the addInjectStreamUrl method.",
        "parameters": [
            {
                "uid": "The ID of the user or host who joins the channel."
            },
            {
                "elapsed": "Time delay (ms) fromthe local user calling joinChannel until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onusermuteaudio",
        "name": "USER_MUTE_AUDIO",
        "description": "Occurs when a remote user's audio stream playback pauses/resumes.The SDK triggers this callback when the remote user stops or resumes sending the audio stream by calling the muteLocalAudioStream method.\n   This callback does not work properly when the number of users (in the COMMUNICATION profile) or hosts (in the LIVE_BROADCASTING profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "User ID."
            },
            {
                "muted": "Whether the remote user's audio stream is muted/unmuted:\n      true: Muted.\n      false: Unmuted.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onusermutevideo",
        "name": "USER_MUTE_VIDEO",
        "description": "Occurs when a remote user's video stream playback pauses/resumes.The SDK triggers this callback when the remote user stops or resumes sending the video stream by calling the muteLocalVideoStream method.\n   This callback does not work properly when the number of users (in the COMMUNICATION profile) or hosts (in the LIVE_BROADCASTING profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "muted": "Whether the remote user's video stream playback is paused/resumed:\n true: Paused.\n false: Resumed.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuseroffline",
        "name": "USER_OFFLINE",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.There are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections. It's recommended to use the Agora RTM SDK for reliable offline detection.",
        "parameters": [
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "reason": "Reason why the user goes offline: USER_OFFLINE_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideodevicestatechanged",
        "name": "VIDEO_DEVICE_STATE_CHANGED",
        "description": "Occurs when the video device state changes.This callback reports the change of system video devices, such as being unplugged or removed. On a Windows device with an external camera for video capturing, the video disables once the external camera is unplugged.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "Media device types. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "Media device states. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideopublishstatechanged",
        "name": "VIDEO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the video publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "The previous publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "newState": "The current publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideosizechanged",
        "name": "VIDEO_SIZE_CHANGED",
        "description": "Occurs when the video size or rotation of a specified user changes.",
        "parameters": [
            {
                "uid": "The ID of the user whose video size or rotation changes. uid is 0 for the local user."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "rotation": "The rotation information. The value range is [0,360)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideostopped",
        "name": "VIDEO_STOPPED",
        "description": "Occurs when the video stops playing.Deprecated:\n  Deprecated as of v2.4.1. Please use LOCAL_VIDEO_STATE_CHANGED(0) in the LOCAL_VIDEO_STREAM_STATE_STOPPED callback instead.\n       \n   \n   The application can use this callback to change the configuration of the view (for example, displaying other pictures in the view) after the video stops playing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onvideosubscribestatechanged",
        "name": "VIDEO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the video subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onwarning",
        "name": "WARNING",
        "description": "Reports a warning during SDK runtime.Occurs when a warning occurs during SDK runtime. In most cases, the app can ignore the warnings reported by the SDK because the SDK can usually fix the issue and resume running. For example, when losing connection with the server, the SDK may report WARN_LOOKUP_CHANNEL_TIMEOUT and automatically try to reconnect.",
        "parameters": [
            {
                "warn": "Warning codes. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "Warning description."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_pausealleffects",
        "name": "pauseAllEffects",
        "description": "Pauses all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pauseaudiomixing",
        "name": "pauseAudioMixing",
        "description": "Pauses playing and mixing the music file.Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pauseeffect",
        "name": "pauseEffect",
        "description": "Pauses a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_playeffect3",
        "name": "playEffect",
        "description": "This method plays the specified local or online audio effect file.To play multiple audio effect files at the same time, call this method multiple times with different soundId and filePath. For the best user experience, Agora recommends playing no more than three audio effect files at the same time. After the playback of an audio effect file completes, the SDK triggers the AUDIO_EFFECT_FINISHED callback.Call this method after joining a channel.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique.If you have preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as soundId in preloadEffect.\n  "
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               If you have preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as filePath in preloadEffect.\n           "
            },
            {
                "loopCount": "The number of times the audio effect loops:\n          ≥ 0: The number of playback times. For example, 1 means loop one time, which means play the audio effect two times in total.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            },
            {
                "pitch": "The pitch of the audio effect. The value range is 0.5 to 2.0. The default value is 1.0, which means the original pitch. The lower the value, the lower the pitch."
            },
            {
                "pan": "The spatial position of the audio effect. The value range is 1 to10000.\n               -1.0: The audio effect displays to the left.\n               0.0: The audio effect displays ahead.\n               1.0: The audio effect displays to the right.\n           \n  "
            },
            {
                "gain": "The volume of the audio effect. The value range is 1 to10000. The default value is 100.0, which means the original volume. The smaller the value, the less the gain."
            },
            {
                "publish": "Whether to publish the audio effect to the remote users.\n          true: Publish the audio effect to the remote users. Both the local user and remote users can hear the audio effect.\n          false: Do not publish the audio effect to the remote users. Only the local user can hear the audio effect.\n      \n  "
            },
            {
                "startPos": "\n                        The playback position (ms) of the audio effect file.\n                    "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_preloadeffect",
        "name": "preloadEffect",
        "description": "Preloads a specified audio effect file into the memory.To ensure smooth communication, limit the size of the audio effect file. We recommend using this method to preload the audio effect before calling joinChannel. Supported audio formats: mp3, aac, m4a, 3gp, and wav.\n            This method does not support online audio effect files.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               "
            }
        ],
        "returns": "0: Success.\n  < 0: Failure."
    },
    {
        "id": "api_rate",
        "name": "rate",
        "description": "Allows a user to rate a call after the call ends.Ensure that you call this method after leaving a channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "rating": "The rating of the call. The value is between 1 (lowest score) and 5 (highest score). If you set a value out of this range, the SDK returns the -2 (ERR_INVALID_ARGUMENT) error."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT).\n  -3(ERR_NOT_READY)."
    },
    {
        "id": "api_registerlocaluseraccount",
        "name": "registerLocalUserAccount",
        "description": "Registers a user account.Since\n  v2.8.0\n       \n   \n   Once registered, the user account can be used to identify the local user when the user joins the channel. After the registration is successful, the user account can identify the identity of the local user, and the user can use it to join the channel.\n   After the user successfully registers a user account, the SDK triggers the LOCAL_USER_REGISTERED callback on the local client, reporting the user ID and user account of the local user.\n   This method is optional. To join a channel with a user account, you can choose either of the following ways:\n       First call registerLocalUserAccount to register the Account, and then call joinChannelWithUserAccount to join the channel.\n       Call the joinChannelWithUserAccount method to join the channel.\n   \n   The difference between the two ways is that the time elapsed between calling the registerLocalUserAccount method and joining the channel is shorter than directly calling joinChannelWithUserAccount.\n   \n       \n  Ensure that you set the userAccount parameter. Otherwise, this method does not take effect.\n  Ensure that the user account is unique in the channel.\n  To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.",
        "parameters": [
            {
                "appId": "The App ID of your project on Agora Console."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null. Supported characters are (89 in total):\n      The 26 lowercase English letters: a to z.\n      The 26 uppercase English letters: A to Z.\n      All numeric characters: 0 to 9.\n      Space\n      \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.Since\n                    v2.4.1\n                \n            \n   \n       \n  \n      Call this method before joinChannel.\n      This method applies only to interactive live streaming.",
        "parameters": [
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA.\n                        For details, see METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_registerplugin",
        "name": "registerPlugin",
        "description": "Registers a plugin.After registering the plugin, you can use the functionality of the plugin in the SDK. For example, if you want to use a FaceUnity plugin, you can integrate the plugin file into the SDK's project project file first, and then call this method to register the plugin.\n            Agora provides the following approaches for using the plugin:\n                    Call getPlugins and use the enable, disable, setParameter, and getParameter methods in Plugin to enable or disable the plugin, set plugin parameters, and get plugin parameters.\n                    Call enablePlugin, setPluginParameter, and getPluginParameter to enable or disable the plugin, set plugin parameters, and get plugin parameters.",
        "parameters": [
            {
                "pluginInfo": "Plugin information. See PluginInfo."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_release",
        "name": "release",
        "description": "Releases the AgoraRtcEngine instance.This method releases all resources used by the Agora SDK. Use this method for apps in which users occasionally make voice or video calls. When users do not make calls, you can free up resources for other operations.\n   After a successful method call, you can no longer use any method or callback in the SDK anymore. If you want to use the real-time communication functions again, you must call initializeWithContext to create a new AgoraRtcEngine instance.\n   If you want to create a new AgoraRtcEngine instance after destroying the current one, ensure that you wait till the release method execution to complete.",
        "parameters": [
            {
                "sync": "\n      \n true: Synchronous call. Agora suggests calling this method in a sub-thread to avoid congestion in the main thread because the synchronous call and the app cannot move on to another task until the resources used by AgoraRtcEngine are released. Besides, you cannot call release in any method or callback of the SDK. Otherwise, the SDK cannot release the resources until the callbacks return results, which may result in a deadlock. The SDK automatically detects the deadlock and converts this method into an asynchronous call, causing the test to take additional time.\n          false: Asynchronous call. The app can move on to another task, no matter the resources used by AgoraRtcEngine are released or not. Do not immediately uninstall the SDK's dynamic library after the call, or it may cause a crash due to the SDK clean-up thread not quitting.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.\n   After a successful method, the SDK triggers the USER_OFFLINE callback\n                with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.After a successful method call, the SDK triggers RTMP_STREAMING_STATE_CHANGED on the local client to report the result of deleting the address.\n   \n       \n           Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese characters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_renewtoken",
        "name": "renewToken",
        "description": "Renews the token.Passes a new token to the SDK. A token expires after a certain period of time. In the following two cases, the app should call this method to pass in a new token. Failure to do so will result in the SDK disconnecting from the server.\n       The SDK triggers the TOKEN_PRIVILEGE_WILL_EXPIRE callback.\n       The CONNECTION_STATE_CHANGED callback reports CONNECTION_CHANGED_TOKEN_EXPIRED(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_resumealleffects",
        "name": "resumeAllEffects",
        "description": "Resumes playing all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_resumeaudiomixing",
        "name": "resumeAudioMixing",
        "description": "Resumes playing and mixing the music file.This method resumes playing and mixing the music file. Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_resumeeffect",
        "name": "resumeEffect",
        "description": "Resumes playing a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_sendcustomreportmessage",
        "name": "sendCustomReportMessage",
        "description": "Sends custom report messages.Since\n  v3.1.0\n       \n   \n   Agora supports reporting and analyzing customized messages. This function is in the beta stage with a free trial. The ability provided in its beta test version is reporting a maximum of 10 message pieces within 6 seconds, with each message piece not exceeding 256 bytes and each string not exceeding 100 bytes. To try out this function, contact support@agora.io and discuss the format of customized messages with us.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_sendmetadata",
        "name": "sendMetadata",
        "description": "Sends media metadata.After a successful method call of registerMediaMetadataObserver, the SDK triggers the READY_TO_SEND_METADATA callback, and then you can call this method to send media metadata.\n            If the metadata is sent successfully, the SDK triggers the METADATA_RECEIVED callback on the receiver.",
        "parameters": [
            {
                "metadata": "Media metadata See Metadata."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.Sends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the STREAM_MESSAGE callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the STREAM_MESSAGE_ERROR callback on the remote client.\n   \n       Ensure that you call createDataStreamWithConfig to create a data channel before calling this method.\n       In live streaming scenarios, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStreamWithConfig."
            },
            {
                "data": "The message to be sent."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaddonlogfile",
        "name": "setAddonLogFile",
        "description": "Sets log file for the Electron layer of the\n        SDK.",
        "parameters": [
            {
                "filePath": "The full path to the log file for the Electron layer of the SDK. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setaudioeffectparameters",
        "name": "setAudioEffectParameters",
        "description": "Sets parameters for SDK preset audio effects.Since\n  v3.2.0\n       \n   \n   Call this method to set the following parameters for the local user who sends an audio stream:\n  3D voice effect: Sets the cycle period of the 3D voice effect.\n  Pitch correction effect: Sets the basic mode and tonic pitch of the pitch correction effect. Different songs have different modes and tonic pitches. Agora recommends bounding this method with interface elements to enable users to adjust the pitch correction interactively.\n       \n   \n   After setting the audio parameters, all users in the channel can hear the effect.\n   \n       \n  You can call this method either before or after joining a channel.\n  To get better audio effect quality, Agora recommends calling setAudioProfile and setting the scenario as AUDIO_SCENARIO_GAME_STREAMING (3) before calling this method.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT (6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setAudioEffectParameters, Agora recommends not calling the following methods, because they can override setAudioEffectParameters:\n setAudioEffectPreset\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for the preset audio effect.\n 3D voice effect: ROOM_ACOUSTICS_3D_VOICE\nCall setAudioProfile and set the profile parameter to AUDIO_PROFILE_MUSIC_STANDARD_STEREO (3) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5) before setting this enumerator; otherwise, the enumerator setting does not take effect.\nIf the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n     \n \n Pitch correction effect: PITCH_CORRECTION. To achieve better audio effect quality, Agora recommends calling and setting the setAudioProfile profile parameter to AUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5) before setting this enumerator.\n      \n  "
            },
            {
                "param1": "\n      \n If you set preset to ROOM_ACOUSTICS_3D_VOICE, the param1 indicates the cycle period of the 3D voice effect. The value range is [1,60] and the unit is seconds. The default value is 10 seconds, indicating that the voice moves around you every 10 seconds.\n If you set preset to PITCH_CORRECTION, param1 sets the basic mode of the pitch correction effect:\n1: (Default) Natural major scale.\n2: Natural minor scale.\n3: Japanese pentatonic scale.\n     \n \n      \n  "
            },
            {
                "param2": "\n      \n If you set preset to ROOM_ACOUSTICS_3D_VOICE, you need to set param2 to 0.\n If you set preset to PITCH_CORRECTION, the param2 indicates the tonic pitch of the pitch correction effect:\n1: A\n2: A#\n3: B\n4: (Default) C\n5: C#\n6: D\n7: D#\n8: E\n9: F\n10: F#\n11: G\n12: G#\n     \n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudioeffectpreset",
        "name": "setAudioEffectPreset",
        "description": "Sets an SDK preset audio effect.Since\n  v3.2.0\n       \n   \n   Call this method to set an SDK preset audio effect for the local user who sends an audio stream. This audio effect does not change the gender characteristics of the original voice. After setting an audio effect, all users in the channel can hear the effect.\n   You can set different audio effects for different scenarios. See Set the Voice Beautifier and Audio Effects.\n   To get better audio effect quality, Agora recommends calling setAudioProfile and setting the scenario as AUDIO_SCENARIO_GAME_STREAMING (3) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT (6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  If you call setAudioEffectPreset and set the preset parameter to enumerators except for ROOM_ACOUSTICS_3D_VOICE or PITCH_CORRECTION, do not call setAudioEffectParameters; otherwise, setAudioEffectPreset will be overridden.\n  After calling setAudioEffectPreset, Agora recommends not calling the following methods, because they can override setAudioEffectPreset:\n         setVoiceBeautifierPreset\n         setLocalVoiceReverbPreset\n         setLocalVoiceChanger\n         setLocalVoicePitch\n         setLocalVoiceEqualization\n         setLocalVoiceReverb\n         setVoiceBeautifierParameters\n         setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for SDK preset audio effects. See AUDIO_EFFECT_PRESET."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudiomixingpitch",
        "name": "setAudioMixingPitch",
        "description": "Sets the pitch of the local music file.Since\n  v3.0.1\n       \n   \n   When a local music file is mixed with a local human voice, call this method to set the pitch of the local music file only.\n            You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [
            {
                "pitch": "Sets the pitch of the local music file by the chromatic scale. The default value is 0, which means keeping the original pitch. The value ranges from -12 to 12, and the pitch value between consecutive values is a chromatic value. The greater the absolute value of this parameter, the higher or lower the pitch of the local music file."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudiomixingposition",
        "name": "setAudioMixingPosition",
        "description": "Sets the audio mixing position.Call this method to set the playback position of the music file to a different starting position (the default plays from the beginning).\n            You need to call this method after calling startAudioMixing and receiving the AUDIO_MIXING_STATE_CHANGED(PLAY) callback.",
        "parameters": [
            {
                "pos": "Integer. The playback position (ms)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudioprofile",
        "name": "setAudioProfile",
        "description": "Sets the audio parameters and application scenarios.This method needs to be set before joinChannel. If you call this method after joinChannel, the settings do not take effect.\n  In the COMMUNICATION and LIVE_BROADCASTING profiles, the bitrate may be different from your settings due to network self-adaptation.\n  In scenes requiring high-quality audio, such as online music tutoring, Agora recommends you set profile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) and scenario as AUDIO_SCENARIO_GAME_STREAMING(3).",
        "parameters": [
            {
                "profile": "\n      The sample rate, bitrate, encoding mode, and the number of channels. See AUDIO_PROFILE_TYPE.\n  "
            },
            {
                "scenario": "The audio application scenario. See AUDIO_SCENARIO_TYPE. Under different audio scenarios, the device uses different volume types. For details, see What is the difference between the in-call volume and the media volume?"
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setbeautyeffectoptions",
        "name": "setBeautyEffectOptions",
        "description": "Sets the image enhancement options.Since\n  v3.0.0 (Windows), v3.2.0 (macOS)\n       \n   \n   Enables or disables image enhancement and sets the options.\n   Call this method after enableVideo.",
        "parameters": [
            {
                "enabled": "Whether to enable the image enhancement function:\n      true: Enable the image enhancement function.\n      false: (Default) Disable the image enhancement function.\n  "
            },
            {
                "options": "The image enhancement options. See BeautyOptions."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameracapturerconfiguration",
        "name": "setCameraCapturerConfiguration",
        "description": "Sets the camera capture configuration.For a video call or the interactive live video streaming, generally the SDK controls the camera output parameters. When the default camera capturer settings do not meet special requirements or cause performance problems, we recommend using this method to set the camera capturer configuration:\n                    If the resolution or frame rate of the captured raw video data is higher\n                        than those set by setVideoEncoderConfiguration, processing\n                        video frames requires extra CPU and RAM usage and degrades performance.\n                        Agora recommends setting the camera capture configuration as CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE (1) to avoid such\n                        problems.\n                    If you do not need a local video preview or are willing to sacrifice preview\n                        quality, we recommend setting the camera capturer configuration as CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE (1) to optimize CPU\n                        and RAM usage.\n                    If you want better quality for the local video preview, we recommend setting\n                        the camera capturer configuration as CAPTURER_OUTPUT_PREFERENCE_PREVIEW(2).\n                    To customize the width and height of the video image captured by the local camera, set the camera capture configuration as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3).\n                \n            \n   Call this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "config": "The camera capturer configuration. See CameraCapturerConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setchannelprofile",
        "name": "setChannelProfile",
        "description": "Sets the channel profile.Sets the profile of the Agora channel. The Agora SDK differentiates channel profiles and applies optimization algorithms accordingly. For example, it prioritizes smoothness and low latency for a video call and prioritizes video quality for interactive live video streaming.\n   \n       \n  To ensure the quality of real-time communication, Agora recommends that all users in a channel use the same channel profile.\n  This method must be called and set before joinChannel, and cannot be set again after entering the channel.",
        "parameters": [
            {
                "profile": "\n      The channel profile. See CHANNEL_PROFILE_TYPE.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n      -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setclientrole1",
        "name": "setClientRole",
        "description": "Sets the user role in an interactive live streaming channel.You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:The local client: CLIENT_ROLE_CHANGED.The remote client: USER_JOINED or USER_OFFLINE (USER_OFFLINE_BECOME_AUDIENCE).\n   This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).",
        "parameters": [
            {
                "role": "\n      The user role in the interactive live streaming. See CLIENT_ROLE_TYPE.\n  "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -1(ERR_FAILED): A general error occurs (no specified reason).\n -2(ERR_INALID_ARGUMENT): The parameter is invalid.\n -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setclientrole2",
        "name": "setClientRoleWithOptions",
        "description": "Sets the user role and level in an interactive live streaming channel.Since\n  v3.2.0\n       \n   \n   You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:\n      The local client: CLIENT_ROLE_CHANGED.\n      The remote client: USER_JOINED or USER_OFFLINE.\n   \n   The difference between this method and setClientRole[1/2] is that this method can set the user level in addition to the user role.\n      The user role determines the permissions that the SDK grants to a user, such as permission to send local streams, receive remote streams, and push streams to a CDN address.\n      The user level determines the level of services that a user can enjoy within the permissions of the user's role. For example, an audience can choose to receive remote streams with low latency or ultra-low latency. Levels affect prices.\n    \n   This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).",
        "parameters": [
            {
                "role": "The user role in a live interactive streaming. See CLIENT_ROLE_TYPE."
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setcloudproxy",
        "name": "setCloudProxy",
        "description": "Sets the Agora cloud proxy service.Since\n                    3.3.0\n                \n            \n            When the user's firewall restricts the IP address and port, refer to Use Cloud Proxy to add the specific IP\n                addresses and ports to the firewall whitelist; then, call this method to enable the\n                cloud proxy and set the cloud proxyType as UDP_PROXY.\n            After successfully connecting to the cloud proxy, the SDK triggers the CONNECTION_STATE_CHANGED (CONNECTION_STATE_CONNECTING,CONNECTION_CHANGED_SETTING_PROXY_SERVER) callback.\n            To disable the cloud proxy that has been set, call setCloudProxy\n                (NONE_PROXY).\n            To change the cloud proxy type that has been set, call setCloudProxy (NONE_PROXY) first, and then call setCloudProxy and pass the value that you expect in\n                    proxyType.\n            \n                \n                    Agora recommends that you call this method before joining the channel or after leaving the channel.\n                    When you use the cloud proxy for the UDP protocol, the services for pushing streams to CDN and co-hosting across channels are not available.",
        "parameters": [
            {
                "proxyType": "The type of the cloud proxy. See CLOUD_PROXY_TYPE . This parameter is required. The SDK reports an error if you do not pass in a value."
            }
        ],
        "returns": "0: Success.\n                \n                    < 0: Failure.\n                        -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n                        -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n  If you need to resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream (false), and specify the user ID.\n  If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream (false) multiple times.",
        "parameters": [
            {
                "mute": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.Deprecated:\n           This method is deprecated as of v3.3.0.\n       \n   \n            Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:If you need to resume subscribing to the audio stream of a specified user, call muteRemoteVideoStream (false), and specify the user ID.\n                    If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteVideoStream (false) multiple times.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_seteffectposition",
        "name": "setEffectPosition",
        "description": "Sets the playback position of an audio effect file.After a successful setting, the local audio effect file starts playing at the specified position.\n            Call this method after playEffect.",
        "parameters": [
            {
                "soundId": "Audio effect ID. Ensure that this parameter matches the soundId set in playEffect."
            },
            {
                "pos": "The playback position (ms) of the audio effect file."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_seteffectsvolume",
        "name": "setEffectsVolume",
        "description": "Sets the volume of the audio effects.Call this method after playEffect.",
        "parameters": [
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.Deprecated:\n  This method is deprecated from v3.2.0. Please use the enableEncryption method instead.\n       \n   \n   The Agora SDK supports built-in encryption. The default encryption is AES-128-XTS. Call this method to use other encryption modes. All users in the same channel must use the same encryption mode and secret. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "\n      Encryption mode.\n     \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     \"\": When setting as an empty string, the encryption mode is set as\n                                        \"aes-128-xts\" by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.Deprecated:\n  This method is deprecated from v3.2.0. Please use the enableEncryption method instead.\n       \n   \n   Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If the secret is not set or secret is set as null, the built-in encryption is disabled.\n   \n       \n  Do not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_sethighqualityaudioparameters",
        "name": "setHighQualityAudioParameters",
        "description": "Set audio high quality options.Deprecated:\n  This method is deprecated. Agora does not recommend using this method. If you want to set the audio high-quality options, use the setAudioProfile method instead.",
        "parameters": [
            {
                "fullband": "Whether to enable full-band codec (48-kHz sample rate). Not compatible with SDK versions before v1.7.4.\n      \n true: Enable full-band codec.\n false: Disable full-band codec.\n      \n  "
            },
            {
                "stereo": "Whether to enable stereo codec. Not compatible with SDK versions before v1.7.4.\n      \n true: Enable stereo codec.\n false: Disable stereo codec.\n      \n  "
            },
            {
                "fullBitrate": "High bitrate mode. Recommended in voice-only mode.\n      \n true: Enable high-bitrate mode.\n false: Disable high-bitrate mode.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.This method sets the video layout and audio settings for CDN live streaming. The SDK triggers the TRANSCODING_UPDATED callback when you call this method to update the transcoding setting.\n   \n       \n  This method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the TRANSCODING_UPDATED callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "transcoding": "\n      The transcoding configurations for CDN live streaming. See LiveTranscoding."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalpublishfallbackoption",
        "name": "setLocalPublishFallbackOption",
        "description": "Sets the fallback option for the published video stream based on the network conditions.An unstable network affects the audio and video quality in a video call or interactive live video streaming. If option is set as STREAM_FALLBACK_OPTION_AUDIO_ONLY(2), the SDK disables the upstream video but enables audio only when the network conditions deteriorate and cannot support both video and audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the published video stream falls back to audio-only or when the audio-only stream switches back to the video, the SDK triggers the LOCAL_PUBLISH_FALLBACK_TO_AUDIO_ONLY callback.\n   \n       \n  Agora does not recommend using this method for CDN live streaming, because the remote CDN live user will have a noticeable lag when the published video stream falls back to STREAM_FALLBACK_OPTION_AUDIO_ONLY(2).\n  Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "The stream fallback option.\n STREAM_FALLBACK_OPTION_DISABLED (0): (Default) No fallback behavior for the published video stream when the uplink network condition is poor. The stream quality is not guaranteed.\n STREAM_FALLBACK_OPTION_AUDIO_ONLY (2): The published video stream falls back to audio only when the uplink network condition is poor.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvideomirrormode",
        "name": "setLocalVideoMirrorMode",
        "description": "Sets the local video mirror mode.Deprecated:\n           Deprecated as of v3.0.0.\n           Please use setView instead.",
        "parameters": [
            {
                "mode": "The local video mirror mode. See VIDEO_MIRROR_MODE_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicechanger",
        "name": "setLocalVoiceChanger",
        "description": "Sets the local voice changer option.Deprecated:\n           Deprecated from v3.2.0. Use the following methods instead:\n                   setAudioEffectPreset : Audio effects.\n                   setVoiceBeautifierPreset : Voice beautifier effects.\n                   setVoiceConversionPreset : Voice conversion effects.\n               \n            \n       \n   \n   This method can be used to set the local voice effect for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n  VOICE_CHANGER_XXX: Changes the local voice to an old man, a little boy, or the Hulk. Applies to the voice talk scenario.\n  VOICE_BEAUTY_XXX: Beautifies the local voice by making it sound more vigorous, resounding, or adding spacial resonance. Applies to the voice talk and singing scenario.\n  GENERAL_VOICE_BEAUTY_XXX: Adds gender-based beautification effect to the local voice. Applies to the voice talk scenario. For a male voice: Adds magnetism to the voice. For a male voice: Adds magnetism to the voice. For a female voice: Adds freshness or vitality to the voice.\n       \n   \n   \n       \n  To achieve better voice effect quality, Agora recommends setting the profile parameter in setAudioProfile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceReverbPreset, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Voice Changer and Reverberation.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "voiceChanger": "The local voice changer option. The default value is VOICE_CHANGER_OFF, which means the original voice. For details, see VOICE_CHANGER_PRESET. The gender-based beatification effect works best only when assigned a proper gender. Use GENERAL_BEAUTY_VOICE_MALE_MAGNETIC for male and use GENERAL_BEAUTY_VOICE_FEMALE_FRESH and GENERAL_BEAUTY_VOICE_FEMALE_VITALITY for female. Failure to do so can lead to voice distortion."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoiceequalization",
        "name": "setLocalVoiceEqualization",
        "description": "Sets the local voice equalization effect.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "bandFrequency": "The band frequency. The value ranges between 0 and 9, representing the respective 10-band center frequencies of the voice effects, including 31, 62, 125, 250, 500, 1k, 2k, 4k, 8k, and 16k Hz. See AUDIO_EQUALIZATION_BAND_FREQUENCY."
            },
            {
                "bandGain": "The gain of each band in dB. The value ranges between -15 and 15. The default value is 0."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicepitch",
        "name": "setLocalVoicePitch",
        "description": "Changes the voice pitch of the local speaker.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "pitch": "The value ranges between 0.5 and 2.0. The lower the value, the lower the pitch. The default value is 1 (no change to the pitch)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicereverb",
        "name": "setLocalVoiceReverb",
        "description": "Sets the local voice reverberation.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbKey": "The reverberation key. Agora provides 5 reverberation keys: AUDIO_REVERB_TYPE."
            },
            {
                "value": "The value of the reverberation key."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicereverbpreset",
        "name": "setLocalVoiceReverbPreset",
        "description": "Sets the local voice reverberation option, including the virtual stereo.Deprecated:\n  This method is deprecated as of v2.4.0. Agora recommends using setAudioEffectPreset and setVoiceBeautifierPreset instead.\n       \n   \n   This method sets the local voice reverberation for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n   \n       \n  When using the enumeration value prefixed with AUDIO_REVERB_FX, please make sure to set the profile parameter in setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before calling this method, otherwise, the method setting is invalid.\n  When calling this method with AUDIO_VIRTUAL_STEREO, Agora recommends setting the profile parameter in setAudioProfile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceChanger, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Voice Changer and Reverberation.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbPreset": "The local voice reverberation option. The default value is AUDIO_REVERB_OFF, which means the original voice. For details, see AUDIO_REVERB_PRESET.\n      To achieve better voice effects, Agora recommends the enumeration whose name begins with AUDIO_REVERB_FX."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlogfile",
        "name": "setLogFile",
        "description": "Sets the log files that the SDK outputs.Deprecated:\n  This method is deprecated as of v2.4.0. Use initializeWithContext to set the log file path instead.\n       \n   \n   By default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n   Ensure that you call this method immediately after initializing AgoraRtcEngine, otherwise, the output log may not be complete.",
        "parameters": [
            {
                "filePath": "\n                        The absolute path of the log files. The default file path is C: \\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files.\n                    "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlogfilesize",
        "name": "setLogFileSize",
        "description": "Sets the size of a log file that the SDK outputs.Deprecated:\n                    v3.3.0. Use logConfig in initializeWithContext instead.\n                \n            \n            By default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n            If you want to set the size of the log file, you need to call this method before setLogFile, otherwise, the log will be cleared.",
        "parameters": [
            {
                "fileSizeInKBytes": "The size (KB) of a log file. The default value is 1024 KB. If you set fileSizeInKByte to 1024 KB, the maximum aggregate size of the log files output by the SDK is 5 MB. if you set fileSizeInKByte to less than 1024 KB, the setting is invalid, and the maximum size of a log file is still 1024 KB."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setlogfilter",
        "name": "setLogFilter",
        "description": "Sets the log output level of the SDK.Deprecated:\n  v3.3.0. Use logConfig in initializeWithContext instead.\n       \n   \n   This method sets the output log level of the SDK. You can use one or a combination of the log filter levels. The log level follows the sequence of OFF, CRITICAL, ERROR, WARNING, INFO, and DEBUG. Choose a level to see the logs preceding that level.\n   If, for example, you set the log level to WARNING, you see the logs within levels CRITICAL, ERROR, and WARNING.",
        "parameters": [
            {
                "filter": "The output log level of the SDK. See LOG_FILTER_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setmaxmetadatasize",
        "name": "setMaxMetadataSize",
        "description": "Sets the maximum size of the media metadata.After calling registerMediaMetadataObserver, you can call this method to set the maximum size of the media metadata.",
        "parameters": [
            {
                "size": "The maximum size of media metadata."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setplaybackdevice",
        "name": "setAudioPlaybackDevice",
        "description": "Sets the audio playback device.",
        "parameters": [
            {
                "deviceId": "The ID of the audio playback device. You can get the device ID by calling getAudioPlaybackDevices. Plugging or unplugging the audio device does not change the device ID.\n                        "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackdevicemute",
        "name": "setAudioPlaybackDeviceMute",
        "description": "Mutes the audio playback device.",
        "parameters": [
            {
                "mute": "Whether to mute the audio playback device:\n      true: Mute the audio playback device.\n      false: Unmute the audio playback device.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackdevicevolume",
        "name": "setAudioPlaybackVolume",
        "description": "Sets the volume of the audio playback device.",
        "parameters": [
            {
                "volume": "The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setpluginparameter",
        "name": "setPluginParameter",
        "description": "Sets the parameter of a specified\n        plugin.After getting the value using getPluginParameter, you can call this method to pass a JSON string containing a key and a value to the C++ layer.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin. You can get it from PluginInfo."
            },
            {
                "parameter": "A JSON string containing a key and a value."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setrecordingaudioframeparameters",
        "name": "setRecordingAudioFrameParameters",
        "description": "Sets the format of the captured raw audio\n        data.After calling registerPlugin to register a plugin and get the captured raw audio data, you can call this method to set the sample rate and number of audio channels of the raw data returned by the SDK.\n            \n                \n                    Ensure that you call this method before joining a channel.\n                    The SDK calculates the sampling interval based on the\n                            samplesPerCall, sampleRate and\n                            channel parameters set in this\n                            method.Sample interval (sec) =\n                            samplePerCall/(sampleRate × channel). Ensure that the\n                        sample interval ≥ 0.01 (s).",
        "parameters": [
            {
                "sampleRate": "The sample rate returned in the callback, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz."
            },
            {
                "channel": "The number of channels returned by the SDK. You can set is as 1 or 2:\n                                1: Mono.\n                                2: Stereo.\n                            "
            },
            {
                "mode": "The use mode of the returned data, see RAW_AUDIO_FRAME_OP_MODE_TYPE."
            },
            {
                "samplesPerCall": "The number of samples returned by the SDK. Usually set as 1024 for RTMP or RTMPS streaming."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setrecordingdevice",
        "name": "setAudioRecordingDevice",
        "description": "Sets the audio capture device.",
        "parameters": [
            {
                "deviceId": "The ID of the audio capture device. You can get the device ID by calling getAudioRecordingDevices. Plugging or unplugging the audio device does not change the device ID.\n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingdevicemute",
        "name": "setAudioRecordingDeviceMute",
        "description": "Sets the mute status of the audio capture device.",
        "parameters": [
            {
                "mute": "Whether to mute the audio capture device:\n      true: Mute the audio capture device.\n      false: Unmute the audio capture device.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingdevicevolume",
        "name": "setAudioRecordingVolume",
        "description": "Sets the volume of the audio capture device.",
        "parameters": [
            {
                "volume": "The volume of the audio recording device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote video streams.Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-quality video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n   The method result returns in the API_CALL_EXECUTED callback.\n   You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremotesubscribefallbackoption",
        "name": "setRemoteSubscribeFallbackOption",
        "description": "Sets the fallback option for the remote video stream based on the network conditions.Unreliable network conditions affect the overall quality of the interactive live streaming. If option is set as STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW(1) or STREAM_FALLBACK_OPTION_AUDIO_ONLY(2), the SDK automatically switches the video from a high stream to a low stream or disables the video when the downlink network conditions cannot support both audio and video to guarantee the quality of the audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the remote video stream falls back to audio-only or when the audio-only stream switches back to the video, the SDK triggers the REMOTE_SUBSCRIBE_FALLBACK_TO_AUDIO_ONLY callback.\n               Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "See STREAM_FALLBACK_OPTIONS. The default option is STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW(1)."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.Since\n                         v2.4.0\n                    \n               \n               Prioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See PRIORITY_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "Sets the stream type of the remote video.Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n               The method result returns in the API_CALL_EXECUTED callback.\n               You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "userId": "User ID."
            },
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the sound position and gain of a remote user.This method sets the sound position and gain of a remote user.\n   When the local user calls this method to set the sound position of a remote user, the sound difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a real sense of space. This method applies to massively multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n  This method requires hardware support. For the best sound positioning, we recommend using a stereo speaker.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "pan": "The sound position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: the remote sound comes from the front.\n -1.0: the remote sound comes from the left.\n 1.0: the remote sound comes from the right.\n      \n  "
            },
            {
                "gain": "The gain of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original gain of the remote user). The smaller the value, the less the gain."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrendermode",
        "name": "setRenderMode",
        "description": "Sets the rendering mode.",
        "parameters": [
            {
                "mode": "The rendering mode. See RENDER_MODE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setscreencapturecontenthint",
        "name": "setScreenCaptureContentHint",
        "description": "Sets the content hint for screen sharing.Since\n  v2.4.0\n       \n   \n   A content hint suggests the type of the content being shared, so that the SDK applies different optimization algorithms to different types of content. If you don't call this method, the default content hint is CONTENT_HINT_NONE.\n   You can call this method either before or after you start screen sharing.",
        "parameters": [
            {
                "contentHint": "The content hint for screen sharing. See VideoContentHint."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvideoencoderconfiguration",
        "name": "setVideoEncoderConfiguration",
        "description": "Sets the video encoder configuration.Sets the encoder configuration for the local video.\n   You can call this method either before or after joining a channel. If the user does not need to reset the video encoding properties after joining the channel, Agora recommends calling this method before enableVideo to reduce the time to render the first video frame.",
        "parameters": [
            {
                "config": "Video profile. See VideoEncoderConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvideoprofile",
        "name": "setVideoProfile",
        "description": "Sets the video encoder configuration.Deprecated:\n  This method is deprecated as of v2.3. Please use the setVideoEncoderConfiguration method instead.\n       \n   \n   This method sets the video encoder configuration. You can call this method either before or after joining a channel. If the user does not need to reset the video encoding properties after joining the channel, Agora recommends calling this method before enableVideo to reduce the time to render the first video frame.",
        "parameters": [
            {
                "profile": "Video profile. See VIDEO_PROFILE_TYPE."
            },
            {
                "swapWidthAndHeight": "The SDK outputs video with a fixed width and height according to the video profile (profile) you selected. This parameter sets whether to swap width and height of the video:\n  \n      true: Swap the width and height.\n      false: (Default) Do not swap the width and height.\n  \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setvideoqualityparameters",
        "name": "setVideoQualityParameters",
        "description": "Sets the preferences for high-quality video. (LIVE_BROADCASTING only).Deprecated:\n                    Deprecated as of v2.4.0. Agora recommends using the degradationPreference parameter in the VideoEncoderConfiguration class to set the preferences for high-quality video.",
        "parameters": [
            {
                "preferFrameRateOverImageQuality": "\n                        Whether to prioritize smoothness or image quality.\n                                true: Prioritizes smoothness.\n                                false: (Default) Prioritizes the image quality.\n                            \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setvideorenderdimension",
        "name": "setVideoRenderDimension",
        "description": "Sets the rendering resolution of the local video in the JavaScript layer.The Agora SDK automatically controls the video rendering in the JavaScript layer. If the display resolution is too low, you can call this method to adjust the resolution.\n            \n                \n                    This method affects only the local display.\n                    To ensure the video quality, adjust the video resolution accordingly when you set the frame rate. See setVideoRenderFPS.",
        "parameters": [
            {
                "user": "The user of the video. See User."
            },
            {
                "width": "Width (pixel) of the video frame. The default value is 360."
            },
            {
                "height": "Height (pixel) of the video frame. The default value is 640."
            },
            {
                "channelId": "The ID of the channel in which the video is rendered. Set this parameter in multi-channel scenarios only."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvideorenderfps",
        "name": "setVideoRenderFPS",
        "description": "Sets the rendering frame rate of the local video in the JavaScript layer.The Agora SDK automatically controls the video rendering in the JavaScript layer. If the display frame rate is too low, you can call this method to adjust the frame rate.\n            \n                \n                    This method affects only the local display.\n                    To ensure the video quality, adjust the frame rate accordingly when you set the resolution. See setVideoRenderDimension.",
        "parameters": [
            {
                "fps": "The rendering frame rate (fps) of the local video. The maximum value is 30 fps."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setview",
        "name": "setView",
        "description": "Configures the video renderer.",
        "parameters": [
            {
                "renderConfig": "Configurations for the video renderer. See RendererConfig."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_setvoicebeautifierparameters",
        "name": "setVoiceBeautifierParameters",
        "description": "Sets parameters for the preset voice beautifier effects.Since\n  v3.3.0\n       \n   \n   Call this method to set a gender characteristic and a reverberation effect for the singing beautifier effect. This method sets parameters for the local user who sends an audio stream. After setting the audio parameters, all users in the channel can hear the effect.\n   For better voice effects, Agora recommends that you call setAudioProfile and set scenario to AUDIO_SCENARIO_GAME_STREAMING(3) and profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter of setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT(6), otherwise, the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierParameters, Agora recommends not calling the following methods, because they can override setVoiceBeautifierParameters:\n setAudioEffectPreset\n setAudioEffectParameters\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for the preset audio effect:\n SINGING_BEAUTIFIER: Singing beautifier effect.\n      \n  "
            },
            {
                "param1": "The gender characteristics options for the singing voice:\n 1: A male-sounding voice.\n 2: A female-sounding voice.\n      \n  "
            },
            {
                "param2": "The reverberation effect options for the singing voice:\n 1: The reverberation effect sounds like singing in a small room.\n 2: The reverberation effect sounds like singing in a large room.\n 3: The reverberation effect sounds like singing in a hall.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvoicebeautifierpreset",
        "name": "setVoiceBeautifierPreset",
        "description": "Sets a preset voice beautifier effect.Since\n  v3.2.0\n       \n   \n   Call this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting a voice beautifier effect, all users in the channel can hear the effect. You can set different audio effects for different scenarios. For details, see Set the Voice Beautifier and Audio Effects.\n   For better voice effects, Agora recommends that you call setAudioProfile and set scenario to AUDIO_SCENARIO_GAME_STREAMING(3) and profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT (6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierPreset, Agora recommends not calling the following methods, because they can override setVoiceBeautifierPreset:\n setAudioEffectPreset\n setAudioEffectParameters\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The preset voice beautifier effect option: VOICE_BEAUTIFIER_PRESET."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvoiceconversionpreset",
        "name": "setVoiceConversionPreset",
        "description": "Sets a preset voice beautifier effect.Since\n                    v3.3.1\n                \n            \n            Call this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting an audio effect, all users in the channel can hear the effect. You can set different audio effects for different scenarios. See Set the Voice Beautifier and Audio Effects.\n            To achieve better audio effect quality, Agora recommends that you call setAudioProfile and set the profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) and scenario to AUDIO_SCENARIO_GAME_STREAMING(3) before calling this method.\n            \n                \n                    You can call this method either before or after joining a channel.\n                    Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1)\n                    This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n                    After calling setVoiceConversionPreset, Agora recommends not calling the following methods, because they can override setVoiceConversionPreset:\n                            setAudioEffectPreset\n                            setAudioEffectParameters\n                            setVoiceBeautifierPreset\n                            setVoiceBeautifierParameters\n                            setLocalVoiceReverbPreset\n                            setLocalVoiceChanger\n                            setLocalVoicePitch\n                            setLocalVoiceEqualization\n                            setLocalVoiceReverb",
        "parameters": [
            {
                "preset": "The options for the preset voice beautifier effects: VOICE_CONVERSION_PRESET."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setvolumeofeffect",
        "name": "setVolumeOfEffect",
        "description": "Sets the volume of a specified audio effect.Call this method after playEffect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            },
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiodeviceloopbacktest",
        "name": "startAudioDeviceLoopbackTest",
        "description": "Starts an audio device loopback test.This method tests whether the local audio capture device and playback device are working properly. After calling this method, the audio capture device records the local audio, and the audio playback device plays the sampled audio. The SDK triggers two independent AUDIO_VOLUME_INDICATION callbacks at the time interval set in this method, which reports the volume information of the sampling device (uid = 0) and the volume information of the playback device(uid = 1) respectively.\n   \n       Ensure that you call this method before joining a channel.\n       This method tests local audio devices and does not report the network conditions.",
        "parameters": [
            {
                "indicationInterval": "The time interval(ms) at which the SDK triggers the AUDIO_VOLUME_INDICATION callback. We recommend a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the AUDIO_VOLUME_INDICATION callback."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiomixing",
        "name": "startAudioMixing",
        "description": "Starts playing and mixing the music file.Deprecated:\n                    This method is deprecated as of v3.4.0. Please use startAudioMixing instead.\n                \n            \n   \n            This method mixes the specified local or online audio file with the audio from the microphone, or replaces the microphone's audio with the specified local or remote audio file. A successful method call triggers the AUDIO_MIXING_STATE_CHANGED(PLAY) callback. When the audio mixing file playback finishes, the SDK triggers the AUDIO_MIXING_STATE_CHANGED(STOPPED) callback on the local client.\n   \n       \n           Call this method after joining a channel. If you need to call startAudioMixing multiple times, ensure that the time interval between calling this method is more than 500 ms.\n           If the local audio mixing file does not exist, or if the SDK does not support the file format or cannot access the music file URL, the SDK returns WARN_AUDIO_MIXING_OPEN_ERROR = 701.\n           If you need to play an online music file, Agora does not recommend using the redirected URL address. Some Android devices may fail to open a redirected URL address.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               "
            },
            {
                "loopback": "Whether to only play music files on the local client:\n          true: Only play music files on the local client so that only the local user can hear the music.\n          false: Publish music files to remote clients so that both the local user and remote users can hear the music.\n      \n  "
            },
            {
                "replace": "Whether to replace the audio captured by the microphone with a music file:\n          true: Replace the audio captured by the microphone with a music file. Users can only hear the music.\n          false: Do not replace the audio captured by the microphone with a music file. Users can hear both music and audio captured by the microphone.\n      \n  "
            },
            {
                "cycle": "The number of times the music file plays.\n          ≥ 0: The number of playback times. For example, 0 means that the SDK does not play the music file while 1 means that the SDK plays once.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiomixing2",
        "name": "startAudioMixing",
        "description": "Starts playing and mixing the music file.This method mixes the specified local or online audio file with the audio from the microphone, or replaces the microphone's audio with the specified local or remote audio file. A successful method call triggers the AUDIO_MIXING_STATE_CHANGED(PLAY) callback. When the audio mixing file playback finishes, the SDK triggers the AUDIO_MIXING_STATE_CHANGED(STOPPED) callback on the local client.",
        "parameters": [
            {
                "cycle": "The number of times the music file plays.\n          ≥ 0: The number of playback times. For example, 0 means that the SDK does not play the music file while 1 means that the SDK plays once.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            },
            {
                "replace": "Whether to replace the audio captured by the microphone with a music file:\n          true: Replace the audio captured by the microphone with a music file. Users can only hear the music.\n          false: Do not replace the audio captured by the microphone with a music file. Users can hear both music and audio captured by the microphone.\n      \n  "
            },
            {
                "loopback": "Whether to only play music files on the local client:\n          true: Only play music files on the local client so that only the local user can hear the music.\n          false: Publish music files to remote clients so that both the local user and remote users can hear the music.\n      \n  "
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the\n                            audio effect file. For example: C:\\music\\audio.mp4. Supported audio formats include MP3, AAC, M4A, MP4,\n                            WAV, and 3GP. See Supported Media Formats\n                                in Media Foundation.\n               "
            },
            {
                "startPos": "The playback position (ms) of the music file."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startaudiorecording2",
        "name": "startAudioRecording",
        "description": "Starts audio recording on the client.Deprecated:\n                    This method is deprecated as of v3.4.0. Please use startAudioRecordingWithConfig instead.\n                \n            \n            \n                \n                    Since\n                    v2.9.1\n                \n                        \n   The Agora SDK allows recording during a call. After successfully calling this method, you can record the audio of all the users in the channel and get an audio recording file. Supported formats of the recording file are as follows:\n      .wav: Large file size with high fidelity.\n      .aac: Small file size with low fidelity.\n  \n       \n   \n       \n  Ensure that the directory you use to save the recording file exists and is writable.\n  This method should be called after the joinChannel method. The recording automatically stops when you call the leaveChannel method.\n  For better recording effects, set quality to AUDIO_RECORDING_QUALITY_MEDIUM or AUDIO_RECORDING_QUALITY_HIGH when sampleRate is 44.1 kHz or 48 kHz.",
        "parameters": [
            {
                "filePath": "\n                        The absolute path (including the filename extensions) of the recording file. For example:C:\\music\\audio.aac.\n                        Ensure that the directory for the log files exists and is writable.\n                    "
            },
            {
                "sampleRate": "\n      The sample rate (kHz) of the recording file. Supported values are as follows:\n     16000\n     32000 (Default)\n     44100\n     48000\n \n      \n  "
            },
            {
                "quality": "Recording quality. See AUDIO_RECORDING_QUALITY_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiorecording3",
        "name": "startAudioRecordingWithConfig",
        "description": "Starts audio recording on the client.The Agora SDK allows recording during a call. After successfully calling this method, you can record the audio of users in the channel and get an audio recording file. Supported formats of the recording file are as follows:\n                WAV: Large file size with high fidelity. For example, if the sample rate is 32,000 Hz, the file size for a recording duration of 10 minutes is around 73 M.\n                AAC: Small file size with low fidelity. For example, if the sample rate is 32,000 Hz and the recording quality is AUDIO_RECORDING_QUALITY_MEDIUM, the file size for a recording duration of 10 minutes is around 2 M.\n            \n            Once the user leaves the channel, the recording automatically stops.\n            Call this method after joining a channel.",
        "parameters": [
            {
                "config": "Recording configuration. See AudioRecordingConfiguration."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE and CHANNEL_MEDIA_RELAY_EVENT callbacks, and these callbacks return the state and events of the media stream relay.\n  If the CHANNEL_MEDIA_RELAY_STATE callback returns RELAY_STATE_RUNNING(2) and RELAY_OK(0), and the CHANNEL_MEDIA_RELAY_EVENT callback returns RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL(4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the CHANNEL_MEDIA_RELAY_STATE callback returns RELAY_STATE_FAILURE(3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a live streaming channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startdevicetest",
        "name": "startVideoDeviceTest",
        "description": "Starts the video capture device test.This method tests whether the video-capture device is working properly. Before calling this method, ensure that you have already called the enableVideo method, and the window handle (hwnd) parameter is valid.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startechotest1",
        "name": "startEchoTest",
        "description": "Starts an audio call test.Deprecated:\n                    This method is deprecated as of v2.4.0. Use startEchoTestWithInterval instead.\n                \n            \n            This method starts an audio call test to determine whether the audio devices (for example, headset and speaker) and the network connection are working properly. To conduct the test, the user speaks, and the recording is played back within 10 seconds. If the user can hear the recording within the interval, the audio devices and network connection are working properly.\n            \n                \n                    Call this method before joining a channel.\n                    After calling startEchoTest, you must call stopEchoTest to end the test. Otherwise, the app cannot perform the next echo test, and you cannot join the channel.\n                    In the live streaming channels, only a host can call this method.",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startechotest2",
        "name": "startEchoTestWithInterval",
        "description": "Starts an audio call test.This method starts an audio call test to determine whether the audio devices (for example, headset and speaker) and the network connection are working properly. To conduct the test, let the user speak for a while, and the recording is played back within the set interval. If the user can hear the recording within the interval, the audio devices and network connection are working properly.\n            \n                \n                    Call this method before joining a channel.\n                    After calling startEchoTestWithInterval, you must call stopEchoTest to end the test. Otherwise, the app cannot perform the next echo test, and you cannot join the channel.\n                    In the live streaming channels, only a host can call this method.",
        "parameters": [
            {
                "intervalInSeconds": "The time interval (s) between when you speak and when the recording plays back."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startlastmileprobetest",
        "name": "startLastmileProbeTest",
        "description": "Starts the last mile network probe test.Since\n                    v2.4.0\n                \n            \n            This method starts the last-mile network probe test before joining a channel to get the uplink and downlink last mile network statistics, including the bandwidth, packet loss, jitter, and round-trip time (RTT).\n            Once this method is enabled, the SDK returns the following callbacks:\n                    LASTMILE_QUALITY: The SDK triggers this callback within two seconds depending on the network conditions. This callback rates the network conditions and is more closely linked to the user experience.\n                    LASTMILE_PROBE_RESULT: The SDK triggers this callback within 30 seconds depending on the network conditions. This callback returns the real-time statistics of the network conditions and is more objective.\n                \n            \n            This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    In a live streaming channel, call this method to check the uplink network quality before an audience member switches to a host.\n                \n            \n            \n                \n                    This method consumes extra network traffic and may affect communication quality. We do not recommend calling this method and enableLastmileTest at the same time.\n                    Do not call other methods before receiving the LASTMILE_QUALITY and LASTMILE_PROBE_RESULT callbacks. Otherwise, the callbacks may be interrupted.\n                    A host should not call this method after joining a channel (when in a call).",
        "parameters": [
            {
                "config": "The configurations of the last-mile network probe test: LastmileProbeConfig."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startplaybackdevicetest",
        "name": "startAudioPlaybackDeviceTest",
        "description": "Starts the audio playback device test.This method tests if the audio playback device works properly. Once a user starts the test, the SDK plays an audio file specified by the user. If the user can hear the audio, the playback device works properly.\n   After calling this method, the SDK triggers the AUDIO_VOLUME_INDICATION callback every 100 ms, reporting uid = 1 and the volume information of the playback device.\n   Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "testAudioFilePath": "The path of the audio file for the audio playback device test in UTF-8.\n      Supported file formats: wav, mp3, m4a, and aac.\n      Supported file sample rates: 8000, 16000, 32000, 44100, and 48000 Hz.\n  "
            }
        ],
        "returns": "0: Success, and you can hear the sound of the specified audio file.\n       < 0: Failure."
    },
    {
        "id": "api_startpreview",
        "name": "startPreview",
        "description": "Enables the local video preview.This method starts the local video preview before joining the channel. Before calling this method, ensure that you do the following:\n   \n       Call setView to set the local preview window.\n       Call enableVideo to enable the video.\n   \n   \n       \n           The local preview enables the mirror mode by default.\n       After the local video preview is enabled, if you call leaveChannel to exit the channel, the local preview remains until you call stopPreview to disable it.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startrecordingdevicetest",
        "name": "startAudioRecordingDeviceTest",
        "description": "Starts the audio capture device test.This method tests whether the audio sampling device works properly. After calling this method, the SDK triggers the AUDIO_VOLUME_INDICATION callback at the time interval set in this method, which reports uid = 0 and the volume information of the capturing device.\n   Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "indicationInterval": "The time interval(ms) at which the SDK triggers the AUDIO_VOLUME_INDICATION callback. We recommend a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the AUDIO_VOLUME_INDICATION callback."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapturebyscreenrect",
        "name": "startScreenCaptureByScreen",
        "description": "Shares the whole or part of a screen by specifying the screen rect.Since\n  v2.4.0\n       \n   \n   This method shares a screen or part of the screen. You need to specify the area of the screen to be shared.\n   Call this method after joining a channel.",
        "parameters": [
            {
                "screenSymbol": "The display ID (macOS) or ScreenRect that identifies the screen. See ScreenSymbol. You can get the data stream ID by calling getScreensInfo."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. See Rectangle. If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapturebywindowid",
        "name": "startScreenCaptureByWindow",
        "description": "Shares the whole or part of a window by specifying the window ID.Since\n  v2.4.0\n       \n   \n   This method shares a window or part of the window. You need to specify the ID of the window to be shared.\n   \n       \n  Call this method after joining a channel.\n  \n   \n   \n       \n  \n      \n      \n      \n      \n      \n          \n              System version\n              Software\n              Compatible versions\n              Support\n          \n      \n      \n \n     win10\n     Chrome\n     76.0.3809.100\n     No\n \n \n     Office Word\n     18.1903.1152.0\n     Yes\n \n \n     Office Excel\n     No\n \n \n     Office PPT\n     Yes\n \n \n     WPS Word\n     11.1.0.9145\n     Yes\n \n \n     WPS Excel\n \n \n     WPS PPT\n \n \n     Media Player (come with the system)\n     All\n     Yes\n \n \n     win8\n     Chrome\n     All\n     Yes\n \n \n     Office Word\n     All\n     Yes\n \n \n     Office Excel\n \n \n     Office PPT\n \n \n     WPS Word\n     11.1.0.9098\n     Yes\n \n \n     WPS Excel\n \n \n     WPS PPT\n \n \n     Media Player (come with the system)\n     All\n     Yes\n \n \n     win7\n     Chrome\n     73.0.3683.103\n     No\n \n \n     Office Word\n     All\n     Yes\n \n \n     Office Excel\n \n \n     Office PPT\n \n \n     WPS Word\n     11.1.0.9098\n     No\n \n \n     WPS Excel\n \n \n     WPS PPT\n     11.1.0.9098\n     Yes\n \n \n     Media Player (come with the system)\n     All\n     No",
        "parameters": [
            {
                "windowId": "The ID of the window to be shared."
            },
            {
                "rectangle": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n  If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            },
            {
                "captureParams": "Screen sharing configurations. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopalleffects",
        "name": "stopAllEffects",
        "description": "Stops playing all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiodeviceloopbacktest",
        "name": "stopAudioDeviceLoopbackTest",
        "description": "Stops the audio device loopback test.Ensure that you call this method to stop the loopback test after calling the startAudioDeviceLoopbackTest method.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiomixing",
        "name": "stopAudioMixing",
        "description": "Stops playing and mixing the music file.This method stops the audio mixing. Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiorecording",
        "name": "stopAudioRecording",
        "description": "Stops the audio recording on the client.If you call startAudioRecordingWithConfig to start recording, you can call this method to stop the recording.\n            Once the user leaves the channel, the recording automatically stops.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.Since\n                    v2.9.0\n                \n            \n            \n   After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE callback. If the callback reports RELAY_STATE_IDLE(0) and RELAY_OK(0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the CHANNEL_MEDIA_RELAY_STATE callback with the RELAY_ERROR_SERVER_NO_RESPONSE(2) or RELAY_ERROR_SERVER_CONNECTION_LOST(8) status code. You can call the leaveChannel method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopdevicetest",
        "name": "stopVideoDeviceTest",
        "description": "Stops the video capture device test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopechotest",
        "name": "stopEchoTest",
        "description": "Stops the audio call test.",
        "parameters": [],
        "returns": "0: Success.\n                \n                    < 0: Failure.\n                        -5(ERR_REFUSED): Failed to stop the echo test. The echo test may not be running."
    },
    {
        "id": "api_stopeffect",
        "name": "stopEffect",
        "description": "Stops playing a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoplastmileprobetest",
        "name": "stopLastmileProbeTest",
        "description": "Stops the last mile network probe test.Since\n                    v2.4.0",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_stopplaybackdevicetest",
        "name": "stopAudioPlaybackDeviceTest",
        "description": "Stops the audio playback device test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoppreview",
        "name": "stopPreview",
        "description": "Stops the local video preview.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoprecordingdevicetest",
        "name": "stopAudioRecordingDeviceTest",
        "description": "Stops the audio capture device test.This method stops the audio capturing device test. You must call this method to stop the test after calling the startAudioRecordingDeviceTest method.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopscreencapture",
        "name": "stopScreenCapture",
        "description": "Stops screen sharing.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_switchchannel2",
        "name": "switchChannel",
        "description": "Switches to a different channel, and configures whether to automatically subscribe to audio or video streams in the target channel.Since\n  v3.3.0\n       \n   \n   This method allows the audience of a LIVE_BROADCASTING channel to switch to a different channel.\n   After the user successfully switches to another channel, the LEAVE_CHANNEL and JOINED_CHANNEL callbacks are triggered to indicate that the user has left the original channel and joined a new one.\n   Once the user switches to another channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.",
        "parameters": [
            {
                "token": "The token generated at your server.\n      In scenarios with low security requirements, token is optional and can be set as null.\n      In scenarios with high security requirements, set the value to the token generated from your server. If you enable the App Certificate, you must use a token to join the channel.\n  \n      Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n  "
            },
            {
                "channelId": "\n      The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n All lowercase English letters: a to z.\n All uppercase English letters: A to Z.\n All numeric characters: 0 to 9.\n Space\n \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n      \n  "
            },
            {
                "options": "The channel media options. See ChannelMediaOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -5(ERR_REFUSED): The request is rejected. The role of the remote user is not AUDIENCE.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -102(ERR_INVALID CHANNEL_NAME): The channel name is invalid. Please use a valid channel name.\n  -113(ERR_NOT_IN_CHANNEL): The user is not in the channel."
    },
    {
        "id": "api_unloadeffect",
        "name": "unloadEffect",
        "description": "Releases a specified preloaded audio effect from the memory.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_unregistermediametadataobserver",
        "name": "unregisterMediaMetadataObserver",
        "description": "Unregisters the media metadata\n        observer.",
        "parameters": [
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA. For details, see METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_unregisterplugin",
        "name": "unregisterPlugin",
        "description": "Unregisters a specified plugin.After calling registerPlugin to register the plugin, you can call this method to unregister the plugin.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin. You can get it from PluginInfo."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.After the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the CHANNEL_MEDIA_RELAY_EVENT callback with the RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL(7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_updatescreencaptureparameters",
        "name": "updateScreenCaptureParameters",
        "description": "Updates the screen sharing parameters.Since\n  v2.4.0",
        "parameters": [
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_updatescreencaptureregion1",
        "name": "updateScreenCaptureRegion",
        "description": "Updates the screen sharing region.Since\n  v2.4.0",
        "parameters": [
            {
                "rect": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n      If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_videosourceapicallexecuted",
        "name": "VIDEO_SOURCE_API_CALL_EXECUTED",
        "description": "Occurs when a method is executed by the SDK.The callback for the second instance.",
        "parameters": [
            {
                "err": "The error code returned by the SDK when the method call fails. For detailed error information and troubleshooting methods, see Error Code and Warning Code. If the SDK returns 0, then the method call is successful."
            },
            {
                "api": "The method executed by the SDK."
            },
            {
                "result": "The result of the method call."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceapierror",
        "name": "VIDEO_SOURCE_API_ERROR",
        "description": "Occurs when an error occurs in Electron.During the SDK runtime, the SDK triggers this callback when an error occurs in Electron.\n            The callback for the second instance.\n            This callback repots only errors in Electron. If you want to receive errors on the native layer, use VIDEO_SOURCE_ERROR.",
        "parameters": [
            {
                "apiType": "The internal engine. You can ignore this parameter."
            },
            {
                "msg": "The error message. A typical reason is incorrect parameter setting in the API call, for example invalid value or incorrect number of parameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceaudiodevicestatechanged",
        "name": "VIDEO_SOURCE_AUDIO_DEVICE_STATE_CHANGED",
        "description": "Occurs when the audio device state changes.This callback notifies the application that the system's audio device state is changed. For example, a headset is unplugged from the device.\n        The callback for the second instance.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "The device type. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "The device state. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceaudiopublishstatechanged",
        "name": "VIDEO_SOURCE_AUDIO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the audio publishing state changes.The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceaudiosubscribestatechanged",
        "name": "VIDEO_SOURCE_AUDIO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the audio subscribing state changes.The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcecameraready",
        "name": "VIDEO_SOURCE_CAMERA_READY",
        "description": "Occurs when the camera turns on and is ready to capture the video.This callback indicates that the camera has been successfully turned on and you can start to capture video.\n        \n                \n                    Deprecated:\n                    \n                        Please use LOCAL_VIDEO_STREAM_STATE_CAPTURING(1) in VIDEO_SOURCE_LOCAL_VIDEO_STATE_CHANGED instead.\n                    \n                \n            \n            The callback for the second instance.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourceconnectionbanned",
        "name": "VIDEO_SOURCE_CONNECTION_BANNED",
        "description": "Occurs when the connection is banned by the Agora server.Deprecated:\n                    Please use VIDEO_SOURCE_CONNECTION_STATE_CHANGED instead.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourceconnectioninterrupted",
        "name": "VIDEO_SOURCE_CONNECTION_INTERRUPTED",
        "description": "Occurs when the connection between the SDK and the server is interrupted.The callback for the second instance.\n            \n                \n                    Deprecated:\n                    Please use VIDEO_SOURCE_CONNECTION_STATE_CHANGED instead.\n                \n            \n            The SDK triggers this callback when it loses connection with the server for more than four seconds after the connection is established. After triggering this callback, the SDK tries to reconnect to the server. You can use this callback to implement pop-up reminders. The difference between this callback and VIDEO_SOURCE_CONNECTION_LOST is:\n                    The SDK triggers the VIDEO_SOURCE_CONNECTION_INTERRUPTED callback when it loses connection with the server for more than four seconds after it successfully joins the channel.\n                    The SDK triggers the VIDEO_SOURCE_CONNECTION_LOST callback when it loses connection with the server for more than 10 seconds, whether or not it joins the channel.\n                If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourceconnectionlost",
        "name": "VIDEO_SOURCE_CONNECTION_LOST",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.The callback for the second instance.\n            The SDK triggers this callback when it cannot connect to the server 10 seconds after calling the videoSourceJoinChannel method, regardless of whether it is in the channel. If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourceconnectionstatechanged",
        "name": "VIDEO_SOURCE_CONNECTION_STATE_CHANGED",
        "description": "Occurs when the network connection state changes.When the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.\n        The callback for the second instance.",
        "parameters": [
            {
                "state": "The current connection state. See CONNECTION_STATE_TYPE."
            },
            {
                "reason": "The reason for a connection state change. See CONNECTION_CHANGED_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcedisableaudio",
        "name": "videoSourceDisableAudio",
        "description": "Disables the audio module.A method for the second instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcedisablevideo",
        "name": "videoSourceDisableVideo",
        "description": "Disables the video module.A method for the second instance.\n            This method disables video. You can call this method either before or after joining a channel. If you call it before joining a channel, an audio call starts when you join the channel. If you call it after joining a channel, a video call switches to an audio call. Call the videoSourceEnableVideo method to enable video.\n            A successful call of this method triggers the VIDEO_SOURCE_USER_ENABLE_VIDEO(false) callback on the remote client.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceenableaudio",
        "name": "videoSourceEnableAudio",
        "description": "Enables the audio module.A method for the second instance.\n            This method enables audio (disabled by default) for the screen-sharing instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceenabledualstreammode",
        "name": "videoSourceEnableDualStreamMode",
        "description": "Enables the dual-stream mode for a videoSource stream.A method for the second instance.",
        "parameters": [
            {
                "enabled": "\n      \n true: Enables dual-stream mode.\n false: Disables dual-stream mode.\n      \n  "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourceenableencryption",
        "name": "videoSourceEnableEncryption",
        "description": "Enables/Disables the built-in encryption.All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               A method for the second instance.",
        "parameters": [
            {
                "enabled": "\n                              Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption. See EncryptionConfig."
            }
        ],
        "returns": "0: Success.\n                    \n                         < 0: Failure.\n                              -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the\n                                   parameter with a valid value.\n                              -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK\n                                   fails to load the external encryption library. Check the\n                                   enumeration or reload the external encryption library.\n                              -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize\n                                   the AgoraRtcEngine instance before calling this\n                                   method."
    },
    {
        "id": "api_videosourceenablelocalaudio",
        "name": "videoSourceEnableLocalAudio",
        "description": "Disables/Re-enables the local audio function.A method for the second instance.\n            This method disables or re-enables the local audio function to stop or restart local audio capturing.\n            This method does not affect receiving or playing the remote audio streams, and videoSourceEnableLocalAudio(false) applies to scenarios where the user wants to receive remote audio streams without sending any audio stream to other users in the channel.",
        "parameters": [
            {
                "enabled": "\n      true: (Default) Re-enable the local audio function, that is, to start the local audio capturing device (for example, the microphone).\n      false: Disable the local audio function, that is, to stop local audio capturing.\n       \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceenablelocalvideo",
        "name": "videoSourceEnableLocalVideo",
        "description": "Enables/Disables the local video capture.This method disables or re-enables the local video capturer, and does not affect receiving the remote video stream.\n   A method for the second instance.\n            After calling videoSourceEnableVideo, the local video capturer is\n                enabled by default. You can call videoSourceEnableLocalVideo(false) to disable the local video\n                capturer. If you want to re-enable the local video, call videoSourceEnableLocalVideo(true).\n            After the local video capturer is successfully disabled or re-enabled, the SDK triggers the VIDEO_SOURCE_USER_ENABLE_LOCAL_VIDEO callback on the remote client.",
        "parameters": [
            {
                "enabled": "\n      Whether to enable the local video capture:\n      \n true: (Default) Enables the local video capture.\n false: Disables the local video capture. Once the local video is disabled, the remote users can no longer receive the video stream of this user, while this user can still receive the video streams of the other remote users. When set to false, this method does not require a local camera.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceenableloopbackrecording",
        "name": "videoSourceEnableLoopbackRecording",
        "description": "Enables loopback audio capture.Applies to the macOS and Windows platforms only.\n      macOS does not support loopback capturing of the default sound card. If you need to use this method, please use a virtual sound card and pass its name to the deviceName parameter. Agora has tested and recommends using soundflower.\n      You can call this method either before or after joining a channel.\n  \n       \n        If you enable loopback audio capturing, the output of the sound card is mixed into the audio stream sent to the other end.\n       A method for the second instance.",
        "parameters": [
            {
                "enabled": "Whether to enableloopback capture:\n true: Enable loopback audio capture.\n false: (Default) Disable loopback capture.\n      "
            },
            {
                "deviceName": "The device name of the sound card. The default value is null (the default sound card). If the user uses a virtual sound card, such as \"Soundflower\", the virtual sound card name \"Soundflower\" can be passed to this parameter, and the SDK finds the corresponding virtual sound card device and starts collecting."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourceenableplugin",
        "name": "videoSourceEnablePlugin",
        "description": "Enable or disable the specified plug-in.A method for the second instance.",
        "parameters": [
            {
                "null": ""
            },
            {
                "enabled": "Whether to enable the plug-in:\n                            true: Enable the plug-in.\n                            false: Disable the plug-in.\n                        "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourceenablevideo",
        "name": "videoSourceEnableVideo",
        "description": "Enables the video module.A method for the second instance.\n            Call this method either before joining a channel or during a call. If this method is called before joining a channel, the call starts in the video mode. Call the videoSourceDisableVideo method to disable the video mode.\n            A successful call of this method triggers the VIDEO_SOURCE_REMOTE_VIDEO_STATE_CHANGED callback on the remote client.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceenablewebsdkinteroperability",
        "name": "videoSourceEnableWebSdkInteroperability",
        "description": "Enables the interoperability between the videoSource object with the Web SDK.Deprecated:\n  As of v3.0.0, the Native SDK automatically enables interoperability with the Web SDK, so you no longer need to call this method.\n       \n   \n   This method enables or disables interoperability with the Agora Web SDK. If the channel has Web SDK users, ensure that you call this method, or the video of the Native user will be a black screen for the Web user.\n   This method is only applicable in live streaming scenarios, and interoperability is enabled by default in communication scenarios.",
        "parameters": [
            {
                "enabled": "Whether to enable interoperability with the Agora Web SDK:\n                            true: Enable interoperability.\n                            false: (Default) Disable\n                                interoperability.\n                        "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourceerror",
        "name": "VIDEO_SOURCE_ERROR",
        "description": "Reports an error (in the C++ layer).This callback indicates that an error occurs during SDK runtime. In most cases, the SDK cannot fix the issue and resume running. The SDK requires the application to take action or informs the user about the issue. For example, the SDK reports an ERR_START_CALL error when failing to initialize a call. The app informs the user that the call initialization failed and invokes the leaveChannel method to leave the channel.\n    The callback for the second instance.\n            The callback only reports errors in the C++ layer. If you want to receive errors from the Electron layer, use VIDEO_SOURCE_API_ERROR.",
        "parameters": [
            {
                "err": "The error code. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcefirstlocalvideoframe",
        "name": "VIDEO_SOURCE_FIRST_LOCAL_VIDEO_FRAME",
        "description": "Occurs when the first local video frame is rendered.The SDK triggers this callback when the first local video frame is displayed/rendered on the local video view.\n          The callback for the second instance.",
        "parameters": [
            {
                "width": "The width (px) of the first local video frame."
            },
            {
                "height": "The height (px) of the first local video frame."
            },
            {
                "elapsed": "Time elapsed(ms) from the local user calling videoSourceJoinChannel until the SDK triggers this callback. If you call videoSourceStartPreview before calling videoSourceJoinChannel, then this parameter is the time elapsed from calling the videoSourceStartPreview method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcefirstremoteaudioframe",
        "name": "VIDEO_SOURCE_FIRST_REMOTE_AUDIO_FRAME",
        "description": "Occurs when the SDK receives the first audio frame from a specific remote user.Deprecated:\n                    Please use VIDEO_SOURCE_REMOTE_AUDIO_STATE_CHANGED instead.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling videoSourceJoinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcegetpluginparameter",
        "name": "videoSourceGetPluginParameter",
        "description": "Gets the parameter of a specified plugin.A method for the second instance.\n            If you want to pass the JSON string to the C++ layer when using the plugin, you need to call videoSourceGetPluginParameter and videoSourceSetPluginParameter to get and set the plugin parameters.",
        "parameters": [
            {
                "null": ""
            },
            {
                "key": "The key."
            }
        ],
        "returns": "The value corresponding to the key."
    },
    {
        "id": "api_videosourcegetplugins",
        "name": "videoSourceGetPlugins",
        "description": "Gets the plugins.A method for the second instance.\n            After the method call of videoSourceRegisterPlugin, you can call this method to get registered plugins.",
        "parameters": [],
        "returns": "An array of the Plugin objects."
    },
    {
        "id": "api_videosourceinitialize",
        "name": "videoSourceInitializeWithContext",
        "description": "Creates and initializes the videoSource object.A method for the second instance.\n            Ensure that you call this method to initialize the videoSource object before calling any other method in videoSource.",
        "parameters": [
            {
                "context": "The configuration for video source: RtcEngineContext."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2(ERR_INVALID_ARGUMENT): An invalid parameter is used.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -22(ERR_RESOURCE_LIMITED): The resource is limited. The SDK fails to allocate resources because your app uses too many system resources or system resources are insufficient.\n  -101(ERR_INVALID_APP_ID): The App ID is invalid."
    },
    {
        "id": "api_videosourcejoinchannel",
        "name": "videoSourceJoinChannel",
        "description": "Allows the videoSource object to join a channel.A method for the second instance.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "channelId": "\n      The name of the channel. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channel name enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. See Authenticate Your Users with Token.\n    Ensure that the App ID used for creating the token is the same App ID used by the initializeWithContext method for initializing the RTC engine.\n      "
            },
            {
                "uid": "The user ID of the videoSource object. Each user ID is unique in the channel. Ensure that the user ID of the videoSource is different from the uid used when calling the joinChannel method."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourcejoinchannelsuccess",
        "name": "VIDEO_SOURCE_JOIN_CHANNEL_SUCCESS",
        "description": "Occurs when a user joins a channel.This callback notifies the application that a user joins a specified channel.\n        The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the user who joins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the videoSourceJoinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceleavechannel",
        "name": "videoSourceLeaveChannel",
        "description": "Allows the videoSource object to leave a channel.A method for the second instance.",
        "parameters": [],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_videosourcelocalaudiostatechanged",
        "name": "VIDEO_SOURCE_LOCAL_AUDIO_STATE_CHANGED",
        "description": "Occurs when the local audio stream state changes.When the state is LOCAL_AUDIO_STREAM_STATE_FAILED(3), you can view the error information in the error parameter.\n        When the state of the local audio stream changes (including the state of the audio capture and encoding), the SDK triggers this callback to report the current state. This callback allows you to troubleshoot issues when audio exceptions occur.\n            The callback for the second instance.",
        "parameters": [
            {
                "state": "The state of the local audio. See LOCAL_AUDIO_STREAM_STATE."
            },
            {
                "error": "Local audio state error codes. See LOCAL_AUDIO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcelocalaudiostats",
        "name": "VIDEO_SOURCE_LOCAL_AUDIO_STATS",
        "description": "Reports the statistics of the local audio stream.The SDK triggers this callback once every two seconds.\n        The callback for the second instance.",
        "parameters": [
            {
                "stats": "Local audio statistics. See LocalAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcelocalvideostatechanged",
        "name": "VIDEO_SOURCE_LOCAL_VIDEO_STATE_CHANGED",
        "description": "Occurs when the local video stream state changes.For some device models, the SDK does not trigger this callback when the state of the local video changes while the local video capturing device is in use, so you have to make your own timeout judgment.\n        When the state of the local video stream changes (including the state of the video capture and encoding), the SDK triggers this callback to report the current state. This callback indicates the state of the local video stream, including camera capturing and video encoding, and allows you to troubleshoot issues when exceptions occur.\n            The callback for the second instance.\n            The SDK triggers the VIDEO_SOURCE_LOCAL_VIDEO_STATE_CHANGED callback with the state code LOCAL_VIDEO_STREAM_STATE_FAILED and error code LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE in the following situations:\n                        The app switches to the background, and the system gets the camera resource.\n                        The camera starts normally, but does not output video for four consecutive seconds.\n                    \n            \n            When the camera outputs the captured video frames, if the video frames are the same for 15 consecutive frames, the SDK triggers the VIDEO_SOURCE_LOCAL_VIDEO_STATE_CHANGED callback with the state code LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE and error code LOCAL_VIDEO_STREAM_STATE_CAPTURING. Note that the video frame duplication detection is only available for video frames with a resolution greater than 200 × 200, a frame rate greater than or equal to 10 fps, and a bitrate less than 20 Kbps.",
        "parameters": [
            {
                "localVideoState": "The state of the local video, see LOCAL_VIDEO_STREAM_STATE."
            },
            {
                "error": "The detailed error information, see LOCAL_VIDEO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcelocalvideostats",
        "name": "VIDEO_SOURCE_LOCAL_VIDEO_STATS",
        "description": "Reports the statistics of the local video stream.The SDK triggers this callback once every two seconds to report the statistics of the local video stream.The callback for the second instance.",
        "parameters": [
            {
                "stats": "The statistics of the local video stream. See LocalVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcemediaenginestartcallsuccess",
        "name": "VIDEO_SOURCE_MEDIA_ENGINE_START_CALL_SUCCESS",
        "description": "Occurs when the media engine call starts.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourcemuteallremoteaudiostreams",
        "name": "videoSourceMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.\n       \n   \n        As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   A method for the second instance.",
        "parameters": [
            {
                "mute": "Whether to subscribe to the audio streams of all remote users:\n                                true: Do not subscribe to the\n                                    audio streams of all remote users.\n                                false: (Default) Subscribe to\n                                    the audio streams of all remote users by default.\n                            \n                        \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_videosourcemuteallremotevideostreams",
        "name": "videoSourceMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing\n                            State.\n       \n   \n        As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   A method for the second instance.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the video streams of all remote users.\n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_videosourcenetworkquality",
        "name": "VIDEO_SOURCE_NETWORK_QUALITY",
        "description": "Reports the last mile network quality of each user in the channel.The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.\n        This callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The callback for the second instance.",
        "parameters": [
            {
                "uid": "User ID. The network quality of the user with this user ID is reported. If the uid is 0, the local network quality is reported."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the uplink network. This parameter is a quality rating helping you understand how well the current uplink network conditions can support the selected video encoder configuration. For example, a 1000 Kbps uplink network may be adequate for video frames with a resolution of 640 × 480 and a frame rate of 15 fps in the LIVE_BROADCASTING profile, but might be inadequate for resolutions higher than 1280 × 720. See QUALITY_TYPE."
            },
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate, average RTT, and jitter of the downlink network. See QUALITY_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcenetworktypechanged",
        "name": "VIDEO_SOURCE_NETWORK_TYPE_CHANGED",
        "description": "Occurs when the local network type changes.This callback occurs when the connection state of the local user changes. You can get the connection state and reason for the state change in this callback. When the network connection is interrupted, this callback indicates whether the interruption is caused by a network type change or poor network conditions.\n        The callback for the second instance.",
        "parameters": [
            {
                "type": "The type of the local network connection. See NETWORK_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceonleavechannel",
        "name": "VIDEO_SOURCE_LEAVE_CHANNEL",
        "description": "Occurs when a user leaves a channel.The callback for the second instance.\n            This callback notifies the app that the user leaves the channel by calling videoSourceLeaveChannel. From this callback, the app can get information such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceregisterplugin",
        "name": "videoSourceRegisterPlugin",
        "description": "Registers a plugin.After registering the plugin, you can use the functionality of the plugin in the SDK. For example, if you want to use a FaceUnity plugin, you can integrate the plugin file into the SDK's project project file first, and then call this method to register the plugin.\n            A method for the second instance.\n            Agora provides the following approaches for using the plugin:\n                    Call videoSourceGetPlugins and use the enable, disable, setParameter, and getParameter methods in Plugin to enable or disable the plugin, set plugin parameters, and get plugin parameters.\n                    Call videoSourceEnablePlugin, videoSourceSetPluginParameter, and videoSourceGetPluginParameter to enable or disable the plugin, set plugin parameters, and get plugin parameters.",
        "parameters": [
            {
                "pluginInfo": "Plugin information. See PluginInfo."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourcerejoinchannelsuccess",
        "name": "VIDEO_SOURCE_REJOIN_CHANNEL_SUCCESS",
        "description": "Occurs when a user rejoins the channel.When a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.\n        The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcerelease",
        "name": "videoSourceRelease",
        "description": "Releases the videoSource object.A method for the second instance.",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourceremoteaudiostatechanged",
        "name": "VIDEO_SOURCE_REMOTE_AUDIO_STATE_CHANGED",
        "description": "Occurs when the remote audio state changes.This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.\n          When the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "state": "The state of the remote audio, see REMOTE_AUDIO_STATE."
            },
            {
                "reason": "The reason of the remote audio state change, see REMOTE_AUDIO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the videoSourceJoinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceremoteaudiostats",
        "name": "VIDEO_SOURCE_REMOTE_AUDIO_STATS",
        "description": "Audio statistics of the remote user.The SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.\n        The callback for the second instance.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceremoteaudiotransportstats",
        "name": "VIDEO_SOURCE_REMOTE_AUDIO_TRANSPORT_STATS",
        "description": "Reports the transport-layer statistics of each remote audio stream.This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives an audio packet from a remote user. During a call, when the user receives the audio packet sent by the remote user/host, the callback is triggered every 2 seconds.\n        \n                \n                    \n                        Deprecated:\n                        Please use VIDEO_SOURCE_REMOTE_AUDIO_STATS instead.\n                    \n                \n            \n            The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the audio streams."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the receiver."
            },
            {
                "rxKBitrate": "Bitrate of the received audio (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceremotevideostatechanged",
        "name": "VIDEO_SOURCE_REMOTE_VIDEO_STATE_CHANGED",
        "description": "Occurs when the remote video state changes.This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.\n          The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "state": "The state of the remote video, see REMOTE_VIDEO_STATE."
            },
            {
                "reason": "The reason for the remote video state change, see REMOTE_VIDEO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the videoSourceJoinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceremotevideostats",
        "name": "VIDEO_SOURCE_REMOTE_VIDEO_STATS",
        "description": "Reports the transport-layer statistics of each remote video stream.Reports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.\n        The callback for the second instance.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. See RemoteVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceremotevideotransportstats",
        "name": "VIDEO_SOURCE_REMOTE_VIDEO_TRANSPORT_STATS",
        "description": "Reports the transport-layer statistics of each remote video stream.During a call, when the user receives the video packet sent by the remote user/host, the callback is triggered every 2 seconds.\n        This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives a video packet from a remote user.\n   \n                \n                    Deprecated:\n                    Please use VIDEO_SOURCE_REMOTE_VIDEO_STATS instead.\n                \n            \n            The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the video packets."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "The packet loss rate (%) of the video packet sent from the remote user."
            },
            {
                "rxKBitRate": "The bitrate of the received video (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcerenewtoken",
        "name": "videoSourceRenewToken",
        "description": "Renews the token for videoSource.A method for the second instance.",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2(ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_videosourcerequesttoken",
        "name": "VIDEO_SOURCE_REQUEST_TOKEN",
        "description": "Occurs when the token expires.When the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n   The callback for the second instance.\n            Once you receive this callback, generate a new token on your app server, and call videoSourceJoinChannel to rejoin the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourcertcstats",
        "name": "VIDEO_SOURCE_RTC_STATS",
        "description": "Reports the statistics of the current call.The SDK triggers this callback once every two seconds after the user joins the channel.\n        The callback for the second instance.",
        "parameters": [
            {
                "stats": "\n      Statistics of the RTC engine, see RtcStats for details.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcesetaddonlogfile",
        "name": "videoSourceSetAddonLogFile",
        "description": "Sets the log file for the videoSource instance in the Electron layer.A method for the second instance.",
        "parameters": [
            {
                "filePath": "The full path to the log file for the Electron layer of the SDK. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourcesetchannelprofile",
        "name": "videoSourceSetChannelProfile",
        "description": "Sets the channel profile for videoSource.A method for the second instance.",
        "parameters": [
            {
                "profile": "\n      The channel profile. See CHANNEL_PROFILE_TYPE.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n      -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_videosourcesetencryptionmode",
        "name": "videoSourceSetEncryptionMode",
        "description": "Sets the built-in encryption mode.The Agora SDK supports built-in encryption. The default encryption is AES-128-XTS. Call this method to use other encryption modes. All users in the same channel must use the same encryption mode and secret. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   \n                \n                    Deprecated:\n                    This method is deprecated from v3.2.0. Please use the videoSourceEnableEncryption method instead.\n                \n            \n            A method for the second instance.\n            Before calling this method, please call videoSourceSetEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "\n      Encryption mode.\n     \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     \"\": When setting as an empty string, the encryption mode is set as\n                                        \"aes-128-xts\" by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcesetencryptionsecret",
        "name": "videoSourceSetEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If the secret is not set or secret is set as null, the built-in encryption is disabled.\n   \n                \n                    Deprecated:\n                    This method is deprecated from v3.2.0. Please use the videoSourceEnableEncryption method instead.\n                \n            \n            A method for the second instance.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcesetlogfile",
        "name": "videoSourceSetLogFile",
        "description": "Sets the log file for the videoSource instance in the Native layer.Deprecated:\n                    This method is deprecated. Please use videoSourceInitializeWithContext instead.\n                \n            \n            A method for the second instance.\n            \n                Ensure that you call this method immediately after initializing videoSource; otherwise, the output log may not be complete.\n                The default path for the log file of videoSource is the same with the main thread. Ensure that you change the log file path to avoid overwriting the log.",
        "parameters": [
            {
                "filePath": "\n                        The absolute path of the log files. The default file path is C: \\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files.\n                    "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcesetpluginparameter",
        "name": "videoSourceSetPluginParameter",
        "description": "Sets the parameter of a specified\n        plugin.A method for the second instance.\n            After getting the value using videoSourceGetPluginParameter, you can call this method to pass a JSON string containing a key and a value to the C++ layer.",
        "parameters": [
            {
                "null": ""
            },
            {
                "parameter": "A JSON string containing a key and a value."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourcesetscreencapturecontenthint",
        "name": "videoSourceSetScreenCaptureContentHint",
        "description": "Sets the content hint for screen sharing.You can call this method either before or after you start screen sharing.\n        A content hint suggests the type of the content being shared, so that the SDK applies different optimization algorithms to different types of content. If you don't call this method, the default content hint is CONTENT_HINT_NONE.\n   A method for the second instance.",
        "parameters": [
            {
                "contentHint": "The content hint for screen sharing. See VideoContentHint."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcesetvideoencoderconfiguration",
        "name": "videoSourceSetVideoEncoderConfiguration",
        "description": "Sets the video encoder configuration.Sets the encoder configuration for the local video.\n   A method for the second instance.",
        "parameters": [
            {
                "config": "Video profile. See VideoEncoderConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcesetvideoprofile",
        "name": "videoSourceSetVideoProfile",
        "description": "Sets the video profile for videoSource.Deprecated:\n                    Please use the videoSourceSetVideoEncoderConfiguration method instead.\n                \n            \n            A method for the second instance.\n            Call this method before calling videoSourceStartScreenCaptureByScreen or videoSourceStartScreenCaptureByWindow.",
        "parameters": [
            {
                "profile": "Video profile. See VIDEO_PROFILE_TYPE."
            },
            {
                "swapWidthAndHeight": "The SDK outputs video with a fixed width and height according to the video profile (profile) you selected. This parameter sets whether to swap width and height of the video:\n  \n      true: Swap the width and height.\n      false: (Default) Do not swap the width and height.\n  \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_videosourcestartpreview",
        "name": "videoSourceStartPreview",
        "description": "Enables the local video preview.A method for the second instance.\n            This method starts the local video preview before joining the channel. Before calling this method, ensure that you do the following:\n            \n                Call setView to set the local preview window.\n                Call videoSourceEnableVideo to enable the video.\n            \n            \n                \n                    The local preview enables the mirror mode by default.\n                    After the local video preview is enabled, if you call videoSourceLeaveChannel to exit the channel, the local preview remains until you call videoSourceStopPreview to disable it.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcestartscreencapturebyscreen",
        "name": "videoSourceStartScreenCaptureByScreen",
        "description": "Shares the whole or part of a screen by specifying the screen rect.Call this method after joining a channel.\n        This method shares a screen or part of the screen. You need to specify the area of the screen to be shared.\n   A method for the second instance.",
        "parameters": [
            {
                "screenRect": "Sets the relative location of the screen to the virtual screen."
            },
            {
                "screenSymbol": "The display ID (macOS) or ScreenRect that identifies the screen. See ScreenSymbol. You can get the data stream ID by calling getScreensInfo."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. See Rectangle. If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcestartscreencapturebywindow",
        "name": "videoSourceStartScreenCaptureByWindow",
        "description": "Shares the whole or part of a window by specifying the window ID.Call this method after joining a channel.\n  Applies to the macOS and Windows platforms only.\n       \n   \n   This method shares a window or part of the window. You need to specify the ID of the window to be shared.\n   A method for the second instance.",
        "parameters": [
            {
                "windowId": "The ID of the window to be shared.You can get the data stream ID by calling getWindowsInfo."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. See Rectangle. If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window."
            },
            {
                "rectangle": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n  If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            },
            {
                "captureParams": "Screen sharing configurations. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcestoppreview",
        "name": "videoSourceStopPreview",
        "description": "Stops the local video preview.A method for the second instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcestopscreencapture",
        "name": "videoSourceStopScreenCapture",
        "description": "Stops screen sharing.A method for the second instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_videosourcetokenprivilegewillexpire",
        "name": "VIDEO_SOURCE_TOKEN_PRIVILEGE_WILL_EXPIRE",
        "description": "Occurs when the token expires in 30 seconds.When the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token.\n   The callback for the second instance.\n            Upon receiving this callback, generate a new token on your server, and call videoSourceRenewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceunregisterplugin",
        "name": "videoSourceUnregisterPlugin",
        "description": "Unregisters a specified plugin.A method for the second instance.\n            After calling videoSourceRegisterPlugin to register the plugin, you can call this method to unregister the plugin.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin. You can get it from PluginInfo."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_videosourceupdatescreencaptureparameters",
        "name": "videoSourceUpdateScreenCaptureParameters",
        "description": "Updates the screen sharing parameters.A method for the second instance.",
        "parameters": [
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_videosourceupdatescreencaptureregion",
        "name": "videoSourceUpdateScreenCaptureRegion",
        "description": "Updates the screen sharing region.A method for the second instance.",
        "parameters": [
            {
                "regionRect": "The relative location of the screen-shared area to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. See Rectangle. If the specified region overruns the screen or window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen or window."
            },
            {
                "rect": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n      If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_videosourceuserenablelocalvideo",
        "name": "VIDEO_SOURCE_USER_ENABLE_LOCAL_VIDEO",
        "description": "Occurs when a specific remote user enables/disables the local video capturing function.The SDK triggers this callback when the remote user resumes or stops capturing the video stream by calling the enableLocalVideo method.\n        The callback for the second instance.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "Whether the specified remote user enables/disables the local video capturing function:\n true: Enable. Other users in the channel can see the video of this remote user.\n false: Disable. Other users in the channel can no longer receive the video stream from this remote user, while this remote user can still receive the video streams from other users.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceuserenablevideo",
        "name": "VIDEO_SOURCE_USER_ENABLE_VIDEO",
        "description": "Occurs when a remote user enables/disables the video module.Once the video module is disabled, the user can only use a voice call. The user cannot send or receive any video.\n   The callback for the second instance.\n            The SDK triggers this callback when a remote user enables or disables the video module by calling the videoSourceEnableVideo or videoSourceDisableVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "\n      \n true: Enable.\n false: Disable.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourceuseroffline",
        "name": "VIDEO_SOURCE_USER_OFFLINE",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.There are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections. It's recommended to use the Agora RTM SDK for reliable offline detection.\n                \n            \n        The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "reason": "Reason why the user goes offline: USER_OFFLINE_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcevideodevicestatechanged",
        "name": "VIDEO_SOURCE_VIDEO_DEVICE_STATE_CHANGED",
        "description": "Occurs when the video device state changes.This callback reports the change of system video devices, such as being unplugged or removed. On a Windows device with an external camera for video capturing, the video disables once the external camera is unplugged.\n        The callback for the second instance.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "Media device types. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "Media device states. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcevideopublishstatechanged",
        "name": "VIDEO_SOURCE_VIDEO_PUBLISH_STATE_CHANGED",
        "description": "Occurs when the video publishing state changes.The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "oldState": "The previous publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "newState": "The current publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcevideosizechanged",
        "name": "VIDEO_SOURCE_VIDEO_SIZE_CHANGED",
        "description": "Occurs when the video size or rotation of a specified user changes.The callback for the second instance.",
        "parameters": [
            {
                "uid": "The ID of the user whose video size or rotation changes. uid is 0 for the local user."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "rotation": "The rotation information. The value range is [0,360)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcevideostopped",
        "name": "VIDEO_SOURCE_VIDEO_STOPPED",
        "description": "Occurs when the video stops playing.The application can use this callback to change the configuration of the view (for example, displaying other pictures in the view) after the video stops playing.\n        \n                \n                    Deprecated:\n                    Please use VIDEO_SOURCE_LOCAL_VIDEO_STATE_CHANGED(0) in the LOCAL_VIDEO_STREAM_STATE_STOPPED callback instead.\n                \n            \n            The callback for the second instance.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_videosourcevideosubscribestatechanged",
        "name": "VIDEO_SOURCE_VIDEO_SUBSCRIBE_STATE_CHANGED",
        "description": "Occurs when the video subscribing state changes.The callback for the second instance.",
        "parameters": [
            {
                "channel": "The name of the channel."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_videosourcewarning",
        "name": "VIDEO_SOURCE_WARNING",
        "description": "Reports a warning during SDK runtime.Occurs when a warning occurs during SDK runtime. In most cases, the app can ignore the warnings reported by the SDK because the SDK can usually fix the issue and resume running. For example, when losing connection with the server, the SDK may report WARN_LOOKUP_CHANNEL_TIMEOUT and automatically try to reconnect.\n        The callback for the second instance.",
        "parameters": [
            {
                "warn": "Warning codes. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "Warning description."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiorecordingconfiguration",
        "name": "AudioRecordingConfiguration",
        "description": "The configuration of audio recording on the app client.",
        "parameters": [
            {
                "filePath": "\n                        The absolute path (including the filename extensions) of the recording file. For example:C:\\music\\audio.aac.\n                        Ensure that the directory for the log files exists and is writable.\n                    "
            },
            {
                "recordingQuality": "Recording quality. See AUDIO_RECORDING_QUALITY_TYPE.\n                    This parameter applies to AAC files only."
            },
            {
                "recordingPosition": "The recording content. See AUDIO_RECORDING_POSITION."
            },
            {
                "recordingSampleRate": "Recording sample rate (Hz).\n                        16000\n                        (Default) 32000\n                        44100\n                        48000\n                    \n                        If you set this parameter as 44100 or 48000, Agora recommends recording WAV files or AAV files whose recordingQuality is AUDIO_RECORDING_QUALITY_MEDIUM or AUDIO_RECORDING_QUALITY_HIGH for better recording quality."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiovolumeinfo",
        "name": "AudioVolumeInfo",
        "description": "The volume information of users.",
        "parameters": [
            {
                "uid": "\n      User ID.\n     In the local user's callback, uid = 0.\n     In the remote users' callback, uid is the ID of a remote user whose instantaneous volume is one of the three highest.\n \n      \n  "
            },
            {
                "volume": "The volume of the user. The value ranges between 0 (lowest volume) and 255 (highest volume). If the user calls startAudioMixing, the value of volume is the volume after audio mixing."
            },
            {
                "vad": "\n      Voice activity status of the local user.\n     0: The local user is not speaking.\n     1: The local user is speaking.\n \n      \n      \n \n     The vad parameter does not report the voice activity status of remote users. In the remote users' callback, the value of vad is always 0.\n     To use this parameter, you must set report_vad to true when calling enableAudioVolumeIndication.\n \n      \n  "
            },
            {
                "channelId": "The name of the channel where the user is in."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_beautyoptions",
        "name": "BeautyOptions",
        "description": "Image enhancement options.",
        "parameters": [
            {
                "lighteningContrastLevel": "The contrast level. See LIGHTENING_CONTRAST_LEVEL."
            },
            {
                "lighteningLevel": "The brightness level. The value ranges from 0.0 (original) to 1.0. This parameter adjusts the red saturation level."
            },
            {
                "smoothnessLevel": "The sharpness level. The value ranges between 0 (original) and 1. This parameter is usually used to remove blemishes."
            },
            {
                "rednessLevel": "The redness level. The value ranges between 0 (original) and 1. This parameter adjusts the red saturation level."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_cameracapturerconfiguration",
        "name": "CameraCapturerConfiguration",
        "description": "The camera capturer preference.",
        "parameters": [
            {
                "preference": "The camera capture preference. See CAPTURER_OUTPUT_PREFERENCE."
            },
            {
                "captureWidth": "\n                        \n                            \n                                Since\n                                v3.3.1\n                            \n                        \n                        The width (px) of the video image captured by the local camera. To customize the width of the video image, set preference as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3) first, and then use captureWidth to set the video width.\n                    "
            },
            {
                "captureHeight": "\n                        \n                            \n                                Since\n                                v3.3.1\n                            \n                        \n                        The height (px) of the video image captured by the local camera. To customize the height of the video image, set preference as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3) first, and then use captureHeight to set the video height.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channel",
        "name": "Channel",
        "description": "The channel information.The channel information. You can set it as one of the following values:\n                \"\".\n                A string.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_channelmediainfo",
        "name": "ChannelMediaInfo",
        "description": "The definition of ChannelMediaInfo.",
        "parameters": [
            {
                "channelName": "The name of the channel."
            },
            {
                "token": "The token that enables the user to join the channel."
            },
            {
                "uid": "User ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediaoptions",
        "name": "ChannelMediaOptions",
        "description": "The channel media options.",
        "parameters": [
            {
                "autoSubscribeAudio": "Whether to automatically subscribe to all remote audio streams when the user joins a channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteAudioStreams method. After joining the channel, you can call the muteAllRemoteAudioStreams method to set whether to subscribe to audio streams in the channel."
            },
            {
                "audioSubscribeVideo": "Whether to subscribe to video streams when the user joins the channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteVideoStreams method. After joining the channel, you can call the muteAllRemoteVideoStreams method to set whether to subscribe to video streams in the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediarelayconfiguration",
        "name": "ChannelMediaRelayConfiguration",
        "description": "The definition of ChannelMediaRelayConfiguration.",
        "parameters": [
            {
                "srcInfo": "\n                        Pointer to the information of the source channel ChannelMediaInfo. It contains the following members:\n                                channelName: The name of the source channel. The default value is null, which means the SDK applies the name of the current channel.\n                                uid: The unique ID to identify the relay stream in the source channel. The default value is 0, which means the SDK generates a random UID. You must set it as 0.\n                                token: The token for joining the source channel. It is generated with the channelName and uid you set in srcInfo.\n                                        If you have not enabled the App Certificate, set this parameter as the default value null, which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid, and the uid must be set as 0.\n                                    \n                                \n                            \n                        \n                    "
            },
            {
                "destInfos": "\n                        Pointer to the information of the destination channelChannelMediaInfo. It contains the following members:\n                                channelName: The name of the destination channel.\n                                uid: The unique ID to identify the relay stream in the destination channel. The value ranges from 0 to (232-1). To avoid UID conflicts, this uid must be different from any other uid in the destination channel. The default value is 0, which means the SDK generates a random user ID. Do not set this parameter as the user ID of the host in the destination channel, and ensure that this uid is different from any other use ID in the channel.\n                                token: The token for joining the destination channel. It is generated with the channelName and uid you set in destInfos.\n                                        If you have not enabled the App Certificate, set this parameter as the default value null, which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid.\n                                    \n                                \n                            \n                        \n                    "
            },
            {
                "destCount": "The number of destination channels. The default value is 0, and the value range is from 0 to 4. Ensure that the value of this parameter corresponds to the number of ChannelMediaInfo structs you define in destInfos."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_clientroleoptions",
        "name": "ClientRoleOptions",
        "description": "The detailed options of a user.",
        "parameters": [
            {
                "audienceLatencyLevel": "The latency level of an audience member in interactive live streaming. See AUDIENCE_LATENCY_LEVEL_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_datastreamconfig",
        "name": "DataStreamConfig",
        "description": "The configurations for the data stream.The following table shows the SDK behaviors under different parameter settings:\n   \n       \n  \n  \n  \n           \n               \n                   syncWithAudio\n                   ordered\n                   SDK behaviors\n               \n           \n           \n      \n false\n false\n The SDK triggers the STREAM_MESSAGE callback immediately after the receiver receives a data packet.\n      \n      \n true\n false\n If the data packet delay is within the audio delay, the SDK triggers the STREAM_MESSAGE callback when the synchronized audio packet is played out. If the data packet delay exceeds the audio delay, the SDK triggers the STREAM_MESSAGE callback as soon as the data packet is received.\n      \n      \n false\n true\n In this case, the data packet is not synchronized with the audio packet. If the delay of a data packet is within five seconds, the SDK corrects the order of the data packet.\n      \n      \n true\n true\n If the delay of a data packet exceeds five seconds, the SDK discards the data packet. If the delay of a data packet exceeds the audio delay, the SDK discards this data packet.",
        "parameters": [
            {
                "syncWithAudio": "\n                        Whether to synchronize the data packet with the published audio packet.\n                                true: Synchronize the data packet with the audio\n                                    packet.\n                                false: Do not synchronize the data packet with\n                                    the audio packet.\n                            When you set the data packet to synchronize with the audio, then if\n                            the data packet delay is within the audio delay, the SDK triggers the\n                                STREAM_MESSAGE callback when the synchronized\n                            audio packet is played out. Do not set this parameter as true if you need the receiver to receive the data packet\n                            immediately. Agora recommends that you set this parameter to true only when you need to implement specific functions,\n                            for example lyric synchronization.\n                    "
            },
            {
                "ordered": "\n                        Whether the SDK guarantees that the receiver receives the data in the sent order.\n                                true: Guarantee that the receiver receives the data in the sent order.\n                                false: Do not guarantee that the receiver receives the data in the sent order.\n                            Do not set this parameter as true if you need the receiver to receive the data packet immediately.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_device",
        "name": "Device",
        "description": "The device information.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceName": "The name of the device."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_encryptionconfig",
        "name": "EncryptionConfig",
        "description": "Configurations of built-in encryption.",
        "parameters": [
            {
                "encryptionMode": "Encryption mode. The default encryption mode is AES_128_XTS. For details, see ENCRYPTION_MODE."
            },
            {
                "encryptionKey": "\n      Encryption key in string type.\n      If you do not set an encryption key or set it as null, you cannot use the built-in\n                            encryption, and the SDK returns ERR_INVALID_ARGUMENT\n                            (-2).\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_ichannel",
        "name": "AgoraRtcChannel",
        "description": "Provides methods that enable real-time communications in an AgoraRtcChannel channel.Call createChannel to create an AgoraRtcChannel object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_injectstreamconfig",
        "name": "InjectStreamConfig",
        "description": "Configurations of injecting an external audio or video stream.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see Service Sunset Plans.",
        "parameters": [
            {
                "width": "The width of the external video stream after injecting. The default value is 0, which represents the same width as the original."
            },
            {
                "height": "The height of the external video stream after injecting. The default value is 0, which represents the same height as the original."
            },
            {
                "videoGop": "The GOP (in frames) of injecting the external video stream. The default value is 30 frames."
            },
            {
                "videoFramerate": "The frame rate (fps) of injecting the external video stream. The default rate is 15 fps."
            },
            {
                "videoBitrate": "\n                        The bitrate (Kbps) of injecting the external video stream. The default value is 400 Kbps.\n                        The bitrate setting is closely linked to the video resolution. If the bitrate you set is beyond a reasonable range, the SDK sets it within a reasonable range.\n                    "
            },
            {
                "audioSampleRate": "The sampling rate (Hz) of injecting the external audio stream. The default value is 48000 Hz. See AUDIO_SAMPLE_RATE_TYPE.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioBitrate": "\n                        The bitrate (Kbps) of injecting the external audio stream. The default value is 48 Kbps.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioChannels": "\n                        The number of channels of the external audio stream after injecting.\n                                1:  (Default) Mono.\n                                2: Stereo.\n                            \n                        \n                        Agora recommends using the default value.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcengine",
        "name": "AgoraRtcEngine",
        "description": "The basic interface of the Agora Native SDK that implements the core functions of real-time communication.AgoraRtcEngine This interface provides the main methods that your app can call.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeconfig",
        "name": "LastmileProbeConfig",
        "description": "Configurations of the last-mile network test.",
        "parameters": [
            {
                "probeUplink": "Sets whether to test the uplink network. Some users, for example, the audience members in a LIVE_BROADCASTING channel, do not need such a test.\n true: Test.\n false: Not test.\n      \n      \n  "
            },
            {
                "probeDownlink": "\n      Sets whether to test the downlink network:\n     true: Test.\n     false: Not test.\n \n      \n  "
            },
            {
                "expectedUplinkBitrate": "The expected maximum uplink bitrate (bps) of the local user. The value range is [100000, 5000000]. Agora recommends referring to setVideoEncoderConfiguration to set the value."
            },
            {
                "expectedDownlinkBitrate": "The expected maximum downlink bitrate (bps) of the local user. The value range is [100000,5000000]."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeonewayresult",
        "name": "LastmileProbeOneWayResult",
        "description": "Results of the uplink or downlink last-mile network test.",
        "parameters": [
            {
                "packetLossRate": "The packet loss rate (%)."
            },
            {
                "jitter": "The network jitter (ms)."
            },
            {
                "availableBandwidth": "The estimated available bandwidth (bps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileproberesult",
        "name": "LastmileProbeResult",
        "description": "Results of the uplink and downlink last-mile network tests.",
        "parameters": [
            {
                "state": "The status of the last-mile network tests. See LASTMILE_PROBE_RESULT_STATE."
            },
            {
                "uplinkReport": "Results of the uplink last-mile network test. See LastmileProbeOneWayResult."
            },
            {
                "downlinkReport": "Results of the downlink last-mile network test. See LastmileProbeOneWayResult."
            },
            {
                "rtt": "The round-trip time (ms)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_livetranscoding",
        "name": "LiveTranscoding",
        "description": "Transcoding configurations for CDN live streaming.",
        "parameters": [
            {
                "width": "\n                        The width of the output media stream in pixels. The default value is 360.\n                        \n                            When the output media stream is video, ensure that width is set to 64 or higher. Otherwise, the Agora server adjusts the value to 64.\n                            When the output media stream is audio, set width to 0.\n                        \n                    "
            },
            {
                "height": "\n      The height of the output media stream in pixels. The default value is 640.\n      \n When the output media stream is video, ensure that height is set to 64 or higher. Otherwise, the Agora server adjusts the value to 64.\n When the output media stream is audio, set height to 0.\n      \n  "
            },
            {
                "videoBitrate": "The video bitrate (Kbps) of the output media stream. The default value is 400. You can refer\n                        to Pushing Streams to CDN to set\n                        this paramter."
            },
            {
                "videoFrameRate": "The video frame rate (fps) of the output media stream. The default value is 15, and the value range is [1,30].The Agora server adjusts any value over 30 fps to 30 fps."
            },
            {
                "lowLatency": "\n      \n \n     Deprecated\n     This attribute is deprecated since v2.8.0, and Agora does not recommend it.\n \n      \n      \n true: Low latency with unassured quality.\n false: (Default) High latency with assured quality.\n      \n  "
            },
            {
                "videoGop": "The video GOP (Group of Pictures) of the output media stream. The default value is 30."
            },
            {
                "videoCodecProfile": "\n  The video encoding specifications of the output media stream. See VIDEO_CODEC_PROFILE_TYPE.\n  If you set this parameter to other values, Agora adjusts it to the default value.\n       "
            },
            {
                "videoCodecType": "The codec type of the output video. See VIDEO_CODEC_TYPE_FOR_STREAM."
            },
            {
                "backgroundColor": "The video background color of the output media stream. The format is a hexadecimal integer defined by RGB without the # symbol. For example, 0xFFB6C1 represents light pink. The default value is 0x000000 (black)."
            },
            {
                "userCount": "The number of hosts involved in transcoding. The default value is 0."
            },
            {
                "transcodingUsers": "\n      Transcoding configurations of each host. One live streaming channel supports up to 17 hosts. See TranscodingUser.\n  "
            },
            {
                "transcodingExtraInfo": "The user SEI information embedded in the output media stream. This parameter is used to send SEI information to the CDN. The maximum length is 4096 bytes. See How to solve SEI-related issues?"
            },
            {
                "metadata": "\n      \n \n     Deprecated:\n     This attribute is deprecated.\n \n      The metadata sent to the CDN client."
            },
            {
                "watermark": "The video watermark of the output media stream. Ensure that the format of the watermark image is PNG. See RtcImage."
            },
            {
                "backgroundImage": "The video background image of the output media stream. See RtcImage."
            },
            {
                "audioSampleRate": "The audio sampling rate (Hz) of the output media stream. See AUDIO_SAMPLE_RATE_TYPE."
            },
            {
                "audioBitrate": "The audio bitrate (Kbps) of the output media stream. The default value is 48, and the maximum is 128."
            },
            {
                "audioChannels": "The number of audio channels of the output media stream. The default value is 1. Agora recommends setting it to 1 or 2.\n      1: (Default) Mono.\n      2: Stereo.\n      3: Three audio channels.\n      4: Four audio channels.\n      5: Five audio channels.\n      \n  "
            },
            {
                "audioCodecProfile": "The audio codec of the media stream. See AUDIO_CODEC_PROFILE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localaudiostats",
        "name": "LocalAudioStats",
        "description": "Local audio statistics.",
        "parameters": [
            {
                "numChannels": "The number of audio channels."
            },
            {
                "sentSampleRate": "The sampling rate (Hz) of sending the local user's audio stream."
            },
            {
                "sentBitrate": "The average bitrate (Kbps) of sending the local user's audio stream."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the local client to the Agora edge server before applying the anti-packet loss strategies."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localvideostats",
        "name": "LocalVideoStats",
        "description": "The statistics of the local video stream.",
        "parameters": [
            {
                "sentBitrate": "\n      The actual bitrate (Kbps) while sending the local video stream.This value does not include the bitrate while resending the video after packet loss.\n  "
            },
            {
                "sentFrameRate": "The actual frame rate (Kbps) while sending the local video stream.This value does not include the frame rate while resending the video after packet loss."
            },
            {
                "encoderOutputFrameRate": "The output frame rate (fps) of the local video encoder."
            },
            {
                "rendererOutputFrameRate": "The output frame rate (fps) of the local video renderer."
            },
            {
                "targetBitrate": "The target bitrate (Kbps) of the current encoder. This is an estimate made by the SDK based on the current network conditions."
            },
            {
                "targetFrameRate": "The target frame rate (fps) of the current encoder."
            },
            {
                "qualityAdaptIndication": "Quality adaption of the local video stream in the reported interval (in terms of the target frame rate and target bitrate). See QUALITY_ADAPT_INDICATION."
            },
            {
                "encodedBitrate": "\n      The bitrate (Kbps) while encoding the local video stream.This value does not include the bitrate while resending the video after packet loss.\n  "
            },
            {
                "encodedFrameWidth": "The width of the encoded video (px)."
            },
            {
                "encodedFrameHeight": "The height of the encoded video (px)."
            },
            {
                "encodedFrameCount": "The number of sent video frames, represented by an aggregate value."
            },
            {
                "CodecType: Encoding type of the sent audio.": "The codec type of the local video stream. See VIDEO_CODEC_TYPE."
            },
            {
                "txPacketLossRate": "The video packet loss rate (%) from the local client to the Agora edge server before applying the anti-packet loss strategies."
            },
            {
                "captureFrameRate": "The capture frame rate (fps) of the local video stream."
            },
            {
                "captureBrightnessLevel": "\n      \n \n     Since\n     v3.3.0\n \n      \n      The brightness level of the video image captured by the local camera. See CAPTURE_BRIGHTNESS_LEVEL_TYPE.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_logconfig",
        "name": "LogConfig",
        "description": "The configuration of the SDK log files.Since\n  v3.3.0",
        "parameters": [
            {
                "filePath": "\n                        The absolute path of the log files. Ensure that the directory for the log\n                            files exists and is writable. You can use this parameter to rename the\n                            log files. \n                        The default file path is /storage/emulated/0/Android/data/<package\n                                        name>/files/agorasdk.log\n                        The default file path is:\n                                        If Sandbox is enabled: App\n                                                Sandbox/Library/Logs/agorasdk.log, for\n                                                example,\n                                                /Users/<username>/Library/Containers/<App\n                                                Bundle\n                                                Identifier>/Data/Library/Logs/agorasdk.log.\n                                        If Sandbox is disabled:\n                                                ~/Library/Logs/agorasdk.log\n                                    \n                    "
            },
            {
                "fileSize": "The size (KB) of a log file. The default value is 2014 KB. If you set\n                            fileSize to 1024 KB, the maximum aggregate size of\n                        the log files output by the SDK is 5 MB. If you set\n                            fileSize to less than 1024 KB, the setting is\n                        invalid, and the maximum size of a log file is still 1024 KB."
            },
            {
                "level": "The output level of the SDK log file. See LOG_LEVEL."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_metadata",
        "name": "Metadata",
        "description": "Media metadata",
        "parameters": [
            {
                "uid": "\n      User ID.\n For the receiver: The user ID of the user who sent the Metadata.\n     For the sender: Ignore this value.\n \n  "
            },
            {
                "size": "The buffer size of the sent or received Metadata."
            },
            {
                "buffer": "The buffer address of the sent or received Metadata."
            },
            {
                "timeStampMs": "The timestamp (ms) of the Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_plugin",
        "name": "Plugin",
        "description": "Interface for configuring and managing plug-ins.After calling registerPlugin to register a plugin, you can get the Plugin interface through getPlugins.",
        "parameters": [
            {
                "id": "The ID of the plugin."
            },
            {
                "enable": "Enable the plugin."
            },
            {
                "disable": "Disable the plugin."
            },
            {
                "setParameter": "Set the plugin parameters. After calling getParameter to get the value, you can call this method to pass a JSON string containing a key and a value to the C++ layer."
            },
            {
                "getParameter": "Get the plugin parameters. If you want to pass the JSON string to the C++ layer when using the plugin, you need to call this method to get the plugin parameters and then call setParameter to the parameters."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_plugininfo",
        "name": "PluginInfo",
        "description": "Information of the plugin.",
        "parameters": [
            {
                "pluginId": "The ID that identifies the plugin."
            },
            {
                "pluginPath": "The absolute path of the plugin file."
            },
            {
                "order": "The priority of the plugin. If multiple plugins are enabled, the SDK uses\n                        them in the descending order of priority. Set this parameter as a\n                        non-negative integer. The greater the value, the lower the priority. 0\n                        represents the highest priority."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rect",
        "name": "Rect",
        "description": "The screen sharing region.Deprecated:\n  This class is deprecated. Please use the updateScreenCaptureRegion method to update the shared area.",
        "parameters": [
            {
                "top": "The coordinate of the top side of the shared area on the vertical axis."
            },
            {
                "left": "The coordinate of the left side of the shared area on the horizontal axis."
            },
            {
                "bottom": "The coordinate of the bottom side of the shared area on the vertical axis."
            },
            {
                "right": "The coordinate of the right side of the shared area on the horizontal axis."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rectangle",
        "name": "Rectangle",
        "description": "The relative location of the screen-shared area to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window.",
        "parameters": [
            {
                "x": "The horizontal offset from the top-left corner."
            },
            {
                "y": "The vertical offset from the top-left corner."
            },
            {
                "width": "The width of the shared area."
            },
            {
                "height": "The height of the shared area."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remoteaudiostats",
        "name": "RemoteAudioStats",
        "description": "Audio statistics of the remote user.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "quality": "The quality of the audio stream sent by the user. See QUALITY_TYPE."
            },
            {
                "networkTransportDelay": "The network delay (ms) from the audio sender to the receiver."
            },
            {
                "jitterBufferDelay": "\n      The network delay (ms) from the audio receiver to the jitter buffer.This parameter does not take effect if the receiver is an audience member and AUDIENCE_LATENCY_LEVEL_TYPE is 1.\n  "
            },
            {
                "audioLossRate": "The frame loss rate (%) of the remote audio stream in the reported interval."
            },
            {
                "numChannels": "The number of audio channels."
            },
            {
                "receivedSampleRate": "The sampling rate of the received remote audio stream in the reported interval."
            },
            {
                "receivedBitrate": "The average bitrate (Kbps) of the received audio stream in the reported interval."
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote audio stream after the remote user joins the channel. In a session, audio freeze occurs when the audio frame loss rate reaches 4%."
            },
            {
                "frozenRate": "The total audio freeze time as a percentage (%) of the total time when the audio is available. The audio is available means that the remote user neither stops sending the audio stream nor disables the audio module after joining the channel."
            },
            {
                "totalActiveTime": "The total time (ms) when the remote user in the COMMUNICATION profile or the remote host in the LIVE_BROADCASTING profile neither stops sending the audio stream nor disables the audio module after joining the channel."
            },
            {
                "publishDuration": "The total duration (ms) of the published remote audio stream."
            },
            {
                "qoeQuality": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Quality of experience (QoE) of the local user when receiving the remote audio stream. See EXPERIENCE_QUALITY_TYPE.\n  "
            },
            {
                "qualityChangedReason": "\n      The reason for poor QoE of the local user when receiving the remote audio stream. See EXPERIENCE_POOR_REASON.\n  "
            },
            {
                "mosValue": "\n               The quality of the remote audio stream in the reported interval. The quality is determined by the Agora real-time audio MOS (Mean Opinion Score) measurement method. The return value range is [0, 500]. Dividing the return value by 100 gets the MOS score, which ranges from 0 to 5. The higher the score, the better the audio quality.\n               \n               The subjective perception of audio quality corresponding to the Agora real-time audio MOS scores is as follows:\n                                \n                                    MOS score\n                                    Perception of audio quality\n                                \n                                \n                                    Greater than 4\n                                    Excellent. The audio sounds clear and smooth.\n                                \n                                \n                                    From 3.5 to 4\n                                    Good. The audio has some perceptible impairment but still sounds clear.\n                                \n                                \n                                    From 3 to 3.5\n                                    Fair. The audio freezes occasionally and requires attentive listening.\n                                \n                                \n                                    From 2.5 to 3\n                                    Poor. The audio sounds choppy and requires considerable effort to understand.\n                                \n                                \n                                    From 2 to 2.5\n                                    Bad. The audio has occasional noise. Consecutive audio dropouts occur, resulting in some information loss. The users can communicate only with difficulty.\n                                \n                                \n                                    Less than 2\n                                    Very bad. The audio has persistent noise. Consecutive audio dropouts are frequent, resulting in severe information loss. Communication is nearly impossible.\n                                \n                            \n           "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remotevideostats",
        "name": "RemoteVideoStats",
        "description": "Statistics of the remote video stream.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "delay": "\n      \n \n     Deprecated:\n     In scenarios where audio and video are synchronized, you can get the video delay data from networkTransportDelay and jitterBufferDelay in RemoteAudioStats.\n \n      \n      The video delay (ms).\n  "
            },
            {
                "width": "The width (pixels) of the video."
            },
            {
                "height": "The height (pixels) of the video."
            },
            {
                "receivedBitrate": "The bitrate (Kbps) of receiving the remote video since the last count."
            },
            {
                "decoderOutputFrameRate": "The frame rate (fps) of decoding the remote video."
            },
            {
                "rendererOutputFrameRate": "The frame rate (fps) of rendering the remote video."
            },
            {
                "packetLossRate": "The packet loss rate (%) of the remote video after using the anti-packet-loss technology."
            },
            {
                "rxStreamType": "The type of the video stream. See REMOTE_VIDEO_STREAM_TYPE."
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote video stream after the remote user joins the channel. In a video session where the frame rate is set to no less than 5 fps, video freeze occurs when the time interval between two adjacent renderable video frames is more than 500 ms."
            },
            {
                "frozenRate": "The total video freeze time as a percentage (%) of the total time when the video is available. The video is available means that the remote user neither stops sending the video stream nor disables the video module after joining the channel."
            },
            {
                "totalActiveTime": "The total time (ms) when the remote user in the COMMUNICATION profile or the remote host in the LIVE_BROADCASTING profile neither stops sending the video stream nor disables the video module after joining the channel."
            },
            {
                "publishDuration": "The total duration (ms) of the published remote video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_renderconfig",
        "name": "RendererConfig",
        "description": "The video renderer configuration.",
        "parameters": [
            {
                "user": "The user of the video. See User."
            },
            {
                "view": "Dom for rendering video. Leave this parameter empty to destroy the video renderer."
            },
            {
                "rendererOptions": "Video rendering options. See RendererOptions."
            },
            {
                "channelId": "The ID of the channel in which the video is rendered. For details, see Channel. You only need to set this parameter in multi-channel scenarios."
            },
            {
                "fps": "The capture frame rate (fps) of the local video. The parameter cannot exceed 30."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rendereroptions",
        "name": "RendererOptions",
        "description": "Video renderer options.",
        "parameters": [
            {
                "append": "When the new video is connected to the DOM, whether to use the native appendChild method to add a child DOM:\n                        true: Add a child DOM. The new video can be played together with the original video.\n                        false: (Default) Do not add a child DOM. Only play the new video.\n                    "
            },
            {
                "contentMode": "Video display modes. See CONTENT_MODE."
            },
            {
                "mirror": "Whether to enable mirror mode when rendering video:\n                            true: Enable mirror mode.\n                            false: (Default) Do not enable mirror mode.\n                        "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcengineconfig",
        "name": "RtcEngineContext",
        "description": "Configurations of initializing the SDK.",
        "parameters": [
            {
                "appId": "The App ID issued by Agora for your app development project. Only users who use the same App ID can join the same channel and communicate with each other.\n      An App ID can only be used to create one AgoraRtcEngineinstance. If you need to change the App ID, you must call release to destroy the current IRtcEngine, and then call  and initializeWithContext to recreate AgoraRtcEngine.\n      An App ID can only be used to create one AgoraRtcEngineinstance. If you need to change the App ID, you\n                            must call release destroy the current IRtcEngine, and\n                            then call initializeWithContext to recreate AgoraRtcEngine.\n  "
            },
            {
                "areaCode": "The region for connection. This advanced feature applies to scenarios that have regional restrictions. See AREA_CODE for details about supported regions.\n  After specifying the region, the SDK connects to the Agora servers within that region."
            },
            {
                "logConfig": "The configuration of the log files. See LogConfig.\n  By default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log.\n  Each log file has a default size of 512 KB and is encoded in UTF-8 format. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest  log."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcimage",
        "name": "RtcImage",
        "description": "Image properties.This class sets the properties of the watermark and background images in the live video.",
        "parameters": [
            {
                "url": "\n      The HTTP/HTTPS URL address of the image in the live video. The maximum length of this parameter is 1024 bytes.\n      "
            },
            {
                "x": "The x coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "y": "The y coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "width": "The width (pixel) of the image on the video frame."
            },
            {
                "height": "The height (pixel) of the image on the video frame."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcstats",
        "name": "RtcStats",
        "description": "Statistics of a call session.",
        "parameters": [
            {
                "duration": "\n      Call duration of the local user in seconds, represented by an aggregate value.\n      "
            },
            {
                "txBytes": "The number of bytes sent."
            },
            {
                "rxBytes": "The number of bytes received."
            },
            {
                "txAudioBytes": "The total number of audio bytes sent, represented by an aggregate value."
            },
            {
                "txVideoBytes": "The total number of video bytes sent, represented by an aggregate value."
            },
            {
                "rxAudioBytes": "The total number of audio bytes received, represented by an aggregate value."
            },
            {
                "rxVideoBytes": "The total number of video bytes received, represented by an aggregate value."
            },
            {
                "txKBitRate": "The bitrate (Kbps) of sending data."
            },
            {
                "rxKBitRate": "The receiving bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "rxAudioKBitRate": "Audio receive bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "txAudioKBitRate": "The bitrate (Kbps) of sending the audio packet."
            },
            {
                "rxVideoKBitRate": "Video receive bitrate (Kbps), represented by an instantaneous value."
            },
            {
                "txVideoKBitRate": "The bitrate (Kbps) of sending the video."
            },
            {
                "lastmileDelay": "The client-to-server delay (milliseconds)."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the client to the Agora server before using the anti-packet-loss method."
            },
            {
                "rxPacketLossRate": "The packet loss rate (%) from the Agora server to the client before using the anti-packet-loss method."
            },
            {
                "userCount": "The number of users in the channel.\n      For COMMUNICATION profile: The number of users in the channel.\n      For LIVE_BROADCASTING profile:\n If the local user is an audience member: The number of users in the channel = The number of hosts in the channel + 1.\n If the user is a host: The number of users in the channel = The number of hosts in the channel.\n      \n  \n  "
            },
            {
                "cpuAppUsage": "The CPU usage (%) of the application."
            },
            {
                "cpuTotalUsage": "\n      The system CPU usage (%).\n      In the multi-kernel environment, this member represents the average CPU usage. The value = 100 - System Idle Progress in Task Manager.\n  "
            },
            {
                "gatewayRtt": "The round-trip time delay from the client to the local router."
            },
            {
                "memoryAppUsageRatio": "\n      The memory occupied by the application (%).\n      This value is for reference only. Due to system limitations, you might\n                            not get this value.\n  "
            },
            {
                "memoryTotalUsageRatio": "\n      The memory occupied by the system (%).\n      This value is for reference only. Due to system limitations, you might\n                            not get this value.\n  "
            },
            {
                "memoryAppUsageInKbytes": "\n      The memory occupied by the application (KB).\n      This value is for reference only. Due to system limitations, you might\n                            not get this value.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_screencaptureparameters",
        "name": "ScreenCaptureParameters",
        "description": "Screen sharing configurations.",
        "parameters": [
            {
                "dimensions": "The maximum dimensions of encoding the shared region. See VideoDimensions. The default value is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges.\n                        If the screen dimensions are different from the value of this parameter, Agora applies the following strategies for encoding. Suppose dimensions are set to 1920 x 1080:\n                                If the value of the screen dimensions is lower than that of dimensions, for example, 1000 x 1000 pixels, the SDK uses 1000 x 1000 pixels for encoding.\n                                If the value of the screen dimensions is higher than that of dimensions, for example, 2000 x 1500, the SDK uses the maximum value next to 1920 x 1080 with the aspect ratio of the screen dimension (4:3) for encoding, that is, 1440 x 1080.\n                            \n                    "
            },
            {
                "frameRate": "The frame rate (fps) of the shared region. The default value is 5. Agora does not recommend setting it to a value greater than 15."
            },
            {
                "bitrate": "The bitrate (Kbps) of the shared region. The default value is 0, which represents that the SDK works out a bitrate according to the dimensions of the current screen."
            },
            {
                "captureMouseCursor": "\n                        \n                            \n                                Since\n                                v2.4.1\n                            \n                        \n                        Sets whether to capture the mouse in screen sharing:\n                                true: (Default) Capture the mouse.\n                                false: Do not capture the mouse.\n                            "
            },
            {
                "windowFocus": "\n                        \n                            Since\n                            v3.1.0\n                        \n                    Sets whether to bring the window to the front when calling the startScreenCaptureByWindow method to share it:\n                            true: Bring the window to the front.\n                            false: (Default) Do not bring the window to the front.\n                        "
            },
            {
                "excludeWindowList": "\n                        \n                            \n                                Since\n                                v3.1.0\n                            \n                        \n                        The ID list of the windows to be blocked. When calling  to start screen sharing, you can use this parameter to block a specified window. When calling updateScreenCaptureParameters to update screen sharing configurations, you can use this parameter to dynamically block a specified window."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_screensymbol",
        "name": "ScreenSymbol",
        "description": "The screen to be shared.The display ID (macOS) or ScreenRect that identifies the screen. You can set it as one of the following values:\n                Number: The display ID for macOS.\n                Rectangle: The Screen Rect for Windows.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_transcodinguser",
        "name": "TranscodingUser",
        "description": "Transcoding configurations of each host.",
        "parameters": [
            {
                "uid": "\n  The user ID of the host.\n       "
            },
            {
                "x": "\n  The x coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, width], where width is the width set in LiveTranscoding."
            },
            {
                "y": "The y coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, height], where height is the height set in LiveTranscoding."
            },
            {
                "width": "The width (pixel) of the host's video."
            },
            {
                "height": "\n                        The height (pixel) of the host's video.\n                    "
            },
            {
                "zOrder": "\n                        The layer number of the host's video. The value ranges from 0 to 100.\n                                0: (Default) The host's video is the bottom layer.\n                                100: The host's video is the top layer.\n                            \n                        \n                        \n                            \n                                If the value is beyond this range, the SDK reports the error code ERR_INVALID_ARGUMENT.\n                                As of v2.3, the SDK supports setting zOrder to 0.\n                            \n                        \n                    "
            },
            {
                "alpha": "\n                        The transparency of the host's video. The value ranges between 0.0 and 1.0.\n                                0.0: Completely transparent.\n                                1.0: (Default) Opaque.\n                            \n                        \n                    "
            },
            {
                "audioChannel": "\n                        The audio channel used by the host's audio in the output audio. The default value is 0, and the value range is [0, 5].\n                                0: (Recommended) The defaut setting, which supports dual channels at most and depends on the upstream of the host.\n                                1: The host's audio uses the FL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                2: The host's audio uses the FC audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                3: The host's audio uses the FR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                4: The host's audio uses the BL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                5: The host's audio uses the BR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                0xFF or a value greater than 5: The host's audio is muted, and the Agora server removes the host's audio.\n                            \n                            If the value is not 0, a special player is required.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_user",
        "name": "User",
        "description": "User information of the rendered video.This class specifies the user information to which the SDK renders the video. You can set it as one of the following values:\n                \"local\": Represents video rendering for the local user.\n                \"videoSource\": Represents video rendering for the video source object.\n                Integer: This value is consistent with the remote user's user ID, and represents the remote user's video rendering.\n                String: This string is consistent with the remote user's user account, and represents the video rendering of the remote user.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_userinfo",
        "name": "UserInfo",
        "description": "The user information.Since\n  v2.8.0",
        "parameters": [
            {
                "uid": "User ID."
            },
            {
                "userAccount": "The user account."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videodimensions",
        "name": "VideoDimensions",
        "description": "Video dimensions.",
        "parameters": [
            {
                "width": "\n      The width of the video in pixels.\n      "
            },
            {
                "height": "The height of the video in pixels."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videoencoderconfiguration",
        "name": "VideoEncoderConfiguration",
        "description": "Video encoder configurations.",
        "parameters": [
            {
                "dimensions": "\n      The dimensions of the encoded video (px). See VideoDimensions. This parameter is used to measure encoding quality and expressed in the form of length × width. The default value is 640 × 360. You can set a custom value."
            },
            {
                "frameRate": "\n      The frame rate (fps) of encoding the video. See FRAME_RATE. The default value is 15.\n  "
            },
            {
                "minFramerate": "The minimum frame rate of encoding the video. The default value is -1."
            },
            {
                "bitrate": "\n      The bitrate (Kbps) of encoding the video.\n      You can refer to the table below to set your bitrate according to your app scenario. If the bitrate you set is beyond a reasonable range, the SDK sets it within a reasonable range. You can also choose from the following options:\n      \n  : (Recommended) Standard bitrate mode In this mode, the video bitrate of the LIVE_BROADCASTING profile is twice that of the COMMUNICATION profile.\n : Adaptive bitrate mode In this mode, the bitrate differs between the LIVE_BROADCASTING and COMMUNICATION profiles. If you choose this mode in the LIVE_BROADCASTING profile, the video frame rate may be lower than the set value.\n      \n      Agora uses different video codecs for different profiles to optimize user experience. The COMMUNICATION profile prioritizes smoothness while the LIVE_BROADCASTING profile prioritizes video quality (a higher bitrate). Therefore, Agora recommends setting this parameter as . You can also set the bitrate value of the LIVE_BROADCASTING profile to twice the bitrate value of the COMMUNICATION profile.\n      \n \n     \n     \n     \n     \n     \n\n    Resolution\n    Frame rate (fps)\n    Bitrate (Kbps) for COMMUNICATION\n    Bitrate (Kbps) for LIVE_BROADCASTING\n\n     \n     \n\n    160 × 120\n    15\n    65\n    130\n\n\n    120 × 120\n    15\n    50\n    100\n\n\n    320 × 180\n    15\n    140\n    280\n\n\n    180 × 180\n    15\n    100\n    200\n\n\n    240 × 180\n    15\n    120\n    240\n\n\n    320 × 240\n    15\n    200\n    400\n\n\n    240 × 240\n    15\n    140\n    280\n\n\n    424 × 240\n    15\n    220\n    440\n\n\n    640 × 360\n    15\n    400\n    800\n\n\n    360 × 360\n    15\n    260\n    520\n\n\n    640 × 360\n    30\n    600\n    1200\n\n\n    360 × 360\n    30\n    400\n    800\n\n\n    480 × 360\n    15\n    320\n    640\n\n\n    480 × 360\n    30\n    490\n    980\n\n\n    640 × 480\n    15\n    500\n    1000\n\n\n    480 × 480\n    15\n    400\n    800\n\n\n    640 × 480\n    30\n    750\n    1500\n\n\n    480 × 480\n    30\n    600\n    1200\n\n\n    848 × 480\n    15\n    610\n    1220\n\n\n    848 × 480\n    30\n    930\n    1860\n\n\n    640 × 480\n    10\n    400\n    800\n\n\n    1280 × 720\n    15\n    1130\n    2260\n\n\n    1280 × 720\n    30\n    1710\n    3420\n\n\n    960 × 720\n    15\n    910\n    1820\n\n\n    960 × 720\n    30\n    1380\n    2760\n\n\n    1920 × 1080\n    15\n    2080\n    4160\n\n\n    1920 × 1080\n    30\n    3150\n    6300\n\n\n    1920 × 1080\n    60\n    4780\n    6500\n\n     \n \n      \n  "
            },
            {
                "minBitrate": "\n      The minimum bitrate (Kbps) of encoding the video.\n      The SDK automatically adjusts the encoding bitrate to adapt to the network conditions. Using a value greater than the default value forces the video encoder to output high-quality images but may cause more packet loss and hence sacrifice the smoothness of the video transmission. That said, unless you have special requirements for image quality, Agora does not recommend changing this value.\n      This parameter only applies to the LIVE_BROADCASTING profile.\n  "
            },
            {
                "orientationMode": "The orientation mode of the encoded video. See ORIENTATION_MODE."
            },
            {
                "degradationPreference": "Video degradation preferences when the bandwidth is a constraint. See DEGRADATION_PREFERENCE."
            },
            {
                "mirrorMode": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Sets the mirror mode of the published local video stream. It only affects the video that the remote user sees. See VIDEO_MIRROR_MODE_TYPE.\n      The mirror mode is disabled by default.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_watermarkoptions",
        "name": "WatermarkOptions",
        "description": "Configurations of the watermark image.",
        "parameters": [
            {
                "visibleInPreview": "\n      Whether the watermark image is visible in the local video preview:\n     true: (Default) The watermark image is visible in the preview.\n     false: The watermark image is not visible in the preview.\n \n      \n  "
            },
            {
                "positionInLandscapeMode": "\n      The area to display the watermark image in landscape mode. See Rectangle:\n                                x: The horizontal offset from the top-left\n                                    corner.\n                                y: The vertical offset from the top-left\n                                    corner.\n                                width: The width (pixels) of\n                                    the area.\n                                height: The height (pixels) of\n                                    the area.\n                            For details about the landscape mode, see Set the Video Profile.\n  "
            },
            {
                "positionInPortraitMode": "\n      The area to display the watermark image in portrait mode. See Rectangle :\n                                x: The horizontal offset from the top-left\n                                    corner.\n                                y: The vertical offset from the top-left\n                                    corner.\n                                width: The width (pixels) of\n                                    the area.\n                                height: The height (pixels) of\n                                    the area.\n                            For details about the portrait mode, see Set the Video Profile.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_windowinfo",
        "name": "WindowInfo",
        "description": "Information of the window to be\n        shared.",
        "parameters": [
            {
                "windowId": "The Window ID that identifies the window."
            },
            {
                "name": "The name of the window."
            },
            {
                "ownerName": "The corresponding process of the window."
            },
            {
                "isOnScreen": "Whether the window is shown on the screen."
            },
            {
                "width": "The width of the window thumbnail (px)."
            },
            {
                "height": "The height of the window thumbnail (px)."
            },
            {
                "originWidth": "The original width of the window (px)."
            },
            {
                "originHeight": "The original height of the window (px)."
            },
            {
                "image": "The window thumbnail. See Uint8Array (https://microsoft.github.io/PowerBI-JavaScript/interfaces/_node_modules_typedoc_node_modules_typescript_lib_lib_es5_d_.uint8array.html)."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_areacode",
        "name": "AREA_CODE",
        "description": "The region for connection, which is the region where\n            the server the SDK connects to is located.",
        "parameters": [
            {
                "AREA_CODE_CN": "Mainland China."
            },
            {
                "AREA_CODE_NA": "North America."
            },
            {
                "AREA_CODE_EU": "Europe."
            },
            {
                "AREA_CODE_AS": "Asia, excluding Mainland China."
            },
            {
                "AREA_CODE_JP": "Japan."
            },
            {
                "AREA_CODE_IN": "India."
            },
            {
                "AREA_CODE_GLOB": "(Default) Global."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiencelatencyleveltype",
        "name": "AUDIENCE_LATENCY_LEVEL_TYPE",
        "description": "The latency level of an audience member in interactive live streaming. This enum takes effect only when the user role is set to CLIENT_ROLE_AUDIENCE.",
        "parameters": [
            {
                "AUDIENCE_LATENCY_LEVEL_LOW_LATENCY": "1: Low latency."
            },
            {
                "AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY": "2: (Default) Ultra low latency."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiocodecprofiletype",
        "name": "AUDIO_CODEC_PROFILE_TYPE",
        "description": "The codec type of the output audio stream for CDN live\n            streaming. The default value is LC-ACC.",
        "parameters": [
            {
                "AUDIO_CODEC_PROFILE_LC_AAC": "0: (Default) LC-AAC, which is the low-complexity audio codec type."
            },
            {
                "AUDIO_CODEC_PROFILE_HE_AAC": "1: HE-AAC, which is the high-efficiency audio codec type."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioeffectpreset",
        "name": "AUDIO_EFFECT_PRESET",
        "description": "Voice effect presets.For better voice effects, Agora recommends setting the profile parameter of setAudioProfile to \n            \n                \n                    AUDIO_PROFILE_MUSIC_HIGH_QUALITY\n                \n            \n         or \n            \n                \n                    AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO\n                \n            \n         before using the following presets:\n   \n       ROOM_ACOUSTICS_KTV\n       ROOM_ACOUSTICS_VOCAL_CONCERT\n       ROOM_ACOUSTICS_STUDIO\n       ROOM_ACOUSTICS_PHONOGRAPH\n       ROOM_ACOUSTICS_SPACIAL\n       ROOM_ACOUSTICS_ETHEREAL\n       VOICE_CHANGER_EFFECT_UNCLE\n       VOICE_CHANGER_EFFECT_OLDMAN\n       VOICE_CHANGER_EFFECT_BOY\n       VOICE_CHANGER_EFFECT_SISTER\n       VOICE_CHANGER_EFFECT_GIRL\n       VOICE_CHANGER_EFFECT_PIGKING\n       VOICE_CHANGER_EFFECT_HULK\n       PITCH_CORRECTION",
        "parameters": [
            {
                "AUDIO_EFFECT_OFF": "Turn off voice effects, that is, use the original voice."
            },
            {
                "ROOM_ACOUSTICS_KTV": "The voice effect typical of a KTV venue."
            },
            {
                "ROOM_ACOUSTICS_VOCAL_CONCERT": "The voice effect typical of a concert hall."
            },
            {
                "ROOM_ACOUSTICS_STUDIO": "The voice effect typical of a recording studio."
            },
            {
                "ROOM_ACOUSTICS_PHONOGRAPH": "The voice effect typical of a vintage phonograph."
            },
            {
                "ROOM_ACOUSTICS_VIRTUAL_STEREO": "\n      The virtual stereo effect, which renders monophonic audio as stereo audio.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "ROOM_ACOUSTICS_SPACIAL": "A more spatial voice effect."
            },
            {
                "ROOM_ACOUSTICS_ETHEREAL": "A more ethereal voice effect."
            },
            {
                "ROOM_ACOUSTICS_3D_VOICE": "\n      A 3D voice effect that makes the voice appear to be moving around the user. The default movement cycle is 10 seconds. After setting this effect, you can call setAudioEffectParameters to modify the movement period.\n      \n      \n Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_STANDARD_STEREO or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n If the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n      \n      \n  "
            },
            {
                "VOICE_CHANGER_EFFECT_UNCLE": "\n      A middle-aged man's voice.\n      Agora recommends using this preset to process a male-sounding voice;\n                            otherwise, you might not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_OLDMAN": "A senior man's voice.\n      Agora recommends using this preset to process a male-sounding voice;\n                            otherwise, you might not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_BOY": "\n      A boy's voice.\n      Agora recommends using this preset to process a male-sounding voice;\n                            otherwise, you might not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_SISTER": "\n      A young woman's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_GIRL": "\n      A girl's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_PIGKING": "The voice of Pig King, a character in Journey to the West who has a voice like a growling bear."
            },
            {
                "VOICE_CHANGER_EFFECT_HULK": "The Hulk's voice."
            },
            {
                "STYLE_TRANSFORMATION_RNB": "\n      The voice effect typical of R&B music.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "STYLE_TRANSFORMATION_POPULAR": "\n      The voice effect typical of popular music.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "PITCH_CORRECTION": "A pitch correction effect that corrects the user's pitch based on the pitch of the natural C major scale. After setting this voice effect, you can call setAudioEffectParameters to adjust the basic mode of tuning and the pitch of the main tone."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioequalizationbandfrequency",
        "name": "AUDIO_EQUALIZATION_BAND_FREQUENCY",
        "description": "The midrange frequency for audio equalization.",
        "parameters": [
            {
                "AUDIO_EQUALIZATION_BAND_31": "0: 31 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_62": "1: 62 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_125": "2: 125 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_250": "3: 250 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_500": "4: 500 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_1K": "5: 1 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_2K": "6: 2 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_4K": "7: 4 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_8K": "8: 8 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_16K": "9: 16 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingerrortype",
        "name": "AUDIO_MIXING_ERROR_TYPE",
        "description": "Errors that might occur when playing a music\n        file.",
        "parameters": [
            {
                "AUDIO_MIXING_ERROR_CAN_NOT_OPEN": "The SDK cannot open the music file."
            },
            {
                "AUDIO_MIXING_ERROR_TOO_FREQUENT_CALL": "The SDK opens the music file too frequently."
            },
            {
                "AUDIO_MIXING_ERROR_INTERRUPTED_EOF": "The playback of the music file is interrupted."
            },
            {
                "AUDIO_MIXING_ERROR_OK": "The music file is playing."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingreasontype",
        "name": "AUDIO_MIXING_REASON_TYPE",
        "description": "The reason why the playback state of the music file changes. Reported in the AUDIO_MIXING_STATE_CHANGED callback.",
        "parameters": [
            {
                "AUDIO_MIXING_REASON_CAN_NOT_OPEN": "701: The SDK cannot open the music file. For example, the local music file\n                        does not exist, the SDK does not support the file format, or  the SDK cannot\n                        access the music file URL."
            },
            {
                "AUDIO_MIXING_REASON_TOO_FREQUENT_CALL": "702: The SDK opens the music file too frequently. If you need to call startAudioMixing multiple times, ensure that the call interval is more than 500 ms."
            },
            {
                "AAUDIO_MIXING_REASON_INTERRUPTED_EOF": "703: The music file playback is interrupted."
            },
            {
                "AUDIO_MIXING_REASON_STARTED_BY_USER": "720: The method call of startAudioMixing to play music\n                        files succeeds."
            },
            {
                "AUDIO_MIXING_REASON_ONE_LOOP_COMPLETED": "721: The music file completes a loop playback."
            },
            {
                "AUDIO_MIXING_REASON_START_NEW_LOOP": "722: The music file starts a new loop playback."
            },
            {
                "AUDIO_MIXING_REASON_ALL_LOOPS_COMPLETED": "723: The music file completes all loop playbacks."
            },
            {
                "AUDIO_MIXING_REASON_STOPPED_BY_USER": "724: The method call of stopAudioMixing to stop playing the\n                        music file succeeds."
            },
            {
                "AUDIO_MIXING_REASON_PAUSED_BY_USER": "725: The method call of pauseAudioMixing to pause playing\n                        the music file succeeds."
            },
            {
                "AUDIO_MIXING_REASON_RESUMED_BY_USER": "726: The method call of resumeAudioMixing to resume playing\n                        the music file succeeds."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingstatetype",
        "name": "AUDIO_MIXING_STATE_TYPE",
        "description": "The playback state of the music file.",
        "parameters": [
            {
                "AUDIO_MIXING_STATE_PLAYING": "\n      710: The music file is playing.\n      The possible reasons include:\n          AUDIO_MIXING_REASON_STARTED_BY_USER(710)\n          AUDIO_MIXING_REASON_ONE_LOOP_COMPLETED(720)\n          AUDIO_MIXING_REASON_START_NEW_LOOP(722)\n          AUDIO_MIXING_REASON_RESUMED_BY_USER(726)\n      \n      \n  "
            },
            {
                "AUDIO_MIXING_STATE_PAUSED": "\n      711: The music file pauses playing.\n      This state is due to AUDIO_MIXING_REASON_PAUSED_BY_USER(725).\n  "
            },
            {
                "AUDIO_MIXING_STATE_STOPPED": "\n      713: The music file stops playing.\n      The possible reasons include:\n          AUDIO_MIXING_REASON_ALL_LOOPS_COMPLETED(723)\n          AUDIO_MIXING_REASON_STOPPED_BY_USER(724)\n      \n  "
            },
            {
                "AUDIO_MIXING_STATE_FAILED": "\n      714: An error occurs during the playback of the audio mixing file.\n      The possible reasons include:\n          AUDIO_MIXING_REASON_CAN_NOT_OPEN(701)\n          AUDIO_MIXING_REASON_TOO_FREQUENT_CALL(702)\n          AAUDIO_MIXING_REASON_INTERRUPTED_EOF(703)\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioprofiletype",
        "name": "AUDIO_PROFILE_TYPE",
        "description": "The audio profile, including the sampling rate, bitrate, encoding mode, and the number of channels.",
        "parameters": [
            {
                "AUDIO_PROFILE_DEFAULT": "\n      0: The default audio profile.\n For the LIVE_BROADCASTING profile: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps.\n For the COMMUNICATION profile: A sampling rate of 32 kHz, music encoding, mono, and a bitrate of up to 18 Kbps.\n      \n  "
            },
            {
                "AUDIO_PROFILE_SPEECH_STANDARD": "1: A sampling rate of 32 kHz, audio encoding, mono, and a bitrate of up to 18 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_STANDARD": "2: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_STANDARD_STEREO": "3: A sampling rate of 48 kHz, music encoding, stereo, and a bitrate of up to 80 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_HIGH_QUALITY": "4: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 96 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO": "5: A sampling rate of 48 kHz, music encoding, stereo, and a bitrate of up to 128 Kbps."
            },
            {
                "AUDIO_PROFILE_NUM": "Enumerator boundary."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiorecordingposition",
        "name": "AUDIO_RECORDING_POSITION",
        "description": "Recording content. Set in startAudioRecordingWithConfig.",
        "parameters": [
            {
                "AUDIO_RECORDING_POSITION_MIXED_RECORDING_AND_PLAYBACK": "0: (Default) Records the mixed audio of the local and all remote users."
            },
            {
                "AUDIO_RECORDING_POSITION_RECORDING": "1: Only records the audio of the local user."
            },
            {
                "AUDIO_RECORDING_POSITION_MIXED_PLAYBACK": "2: Only records the audio of all remote users."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiorecordingqualitytype",
        "name": "AUDIO_RECORDING_QUALITY_TYPE",
        "description": "Recording quality.",
        "parameters": [
            {
                "AUDIO_RECORDING_QUALITY_LOW": "0: Low quality. The sample rate is 32 kHz, and the file size is around 1.2 MB for 10 minutes\n                        of recording."
            },
            {
                "AUDIO_RECORDING_QUALITY_MEDIUM": "1: Medium quality. The sample rate is 32 kHz, and the file size is around 2 MB for 10 minutes\n                        of recording."
            },
            {
                "AUDIO_RECORDING_QUALITY_HIGH": "2: High quality. The sample rate is 32 kHz, and the file size is around 3.75 MB for 10 minutes\n                        of recording."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbpreset",
        "name": "AUDIO_REVERB_PRESET",
        "description": "Voice reverb presets.Deprecated:\n                        Deprecated as of v3.2.0.",
        "parameters": [
            {
                "AUDIO_REVERB_OFF": "Turn off voice reverb, that is, to use the original voice."
            },
            {
                "AUDIO_REVERB_FX_KTV": "The reverb style typical of a KTV venue (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_VOCAL_CONCERT": "The reverb style typical of a concert hall (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_UNCLE": "A middle-aged man's voice."
            },
            {
                "AUDIO_REVERB_FX_SISTER": "The reverb style typical of a young woman's voice."
            },
            {
                "AUDIO_REVERB_FX_STUDIO": "The reverb style typical of a recording studio (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_POPULAR": "The reverb style typical of popular music (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_RNB": "The reverb style typical of R&B music (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_PHONOGRAPH": "The voice effect typical of a vintage phonograph."
            },
            {
                "AUDIO_REVERB_POPULAR": "The voice effect typical of popular music."
            },
            {
                "AUDIO_REVERB_RNB": "The voice effect typical of R&B music."
            },
            {
                "AUDIO_REVERB_ROCK": "The reverb style typical of rock music."
            },
            {
                "AUDIO_REVERB_HIPHOP": "The reverb style typical of hip-hop music."
            },
            {
                "AUDIO_REVERB_VOCAL_CONCERT": "The voice effect typical of a concert hall."
            },
            {
                "AUDIO_REVERB_KTV": "The voice effect typical of a KTV venue."
            },
            {
                "AUDIO_REVERB_STUDIO": "The voice effect typical of a recording studio."
            },
            {
                "AUDIO_VIRTUAL_STEREO": "The reverberation of the virtual stereo. The virtual stereo is an effect that renders the monophonic audio as the stereo audio, so that all users in the channel can hear the stereo voice effect."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbtype",
        "name": "AUDIO_REVERB_TYPE",
        "description": "Audio reverberation types.",
        "parameters": [
            {
                "AUDIO_REVERB_DRY_LEVEL": "0: The level of the dry signal (dB). The value is between -20 and 10."
            },
            {
                "AUDIO_REVERB_WET_LEVEL": "1: The level of the early reflection signal (wet signal) (dB). The value is between -20 and 10."
            },
            {
                "AUDIO_REVERB_ROOM_SIZE": "2: The room size of the reflection. The value is between 0 and 100."
            },
            {
                "AUDIO_REVERB_WET_DELAY": "3: The length of the initial delay of the wet signal (ms). The value is between 0 and 200."
            },
            {
                "AUDIO_REVERB_STRENGTH": "4: The reverberation strength. The value is between 0 and 100."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioroutetype",
        "name": "AUDIO_ROUTE_TYPE",
        "description": "The type of the audio route.",
        "parameters": [
            {
                "AUDIO_ROUTE_DEFAULT": "The default audio route."
            },
            {
                "AUDIO_ROUTE_HEADSET": "The headset."
            },
            {
                "AUDIO_ROUTE_EARPIECE": "The earpiece."
            },
            {
                "AUDIO_ROUTE_HEADSET_NO_MIC": "The headset with no microphone."
            },
            {
                "AUDIO_ROUTE_SPEAKERPHONE": "The built-in speaker on a mobile device."
            },
            {
                "AUDIO_ROUTE_LOUDSPEAKER": "The external speaker."
            },
            {
                "AUDIO_ROUTE_BLUETOOTH": "The bluetooth headset."
            },
            {
                "AUDIO_ROUTE_USB": "The USB peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_HDMI": "The HDMI peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_DISPLAYPORT": "The DisplayPort peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_AIRPLAY": "Apple AirPlay (macOS only)."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiosampleratetype",
        "name": "AUDIO_SAMPLE_RATE_TYPE",
        "description": "The audio sampling rate of the stream to be pushed to the CDN.",
        "parameters": [
            {
                "AUDIO_SAMPLE_RATE_32000": "32000: 32 kHz"
            },
            {
                "AUDIO_SAMPLE_RATE_44100": "44100: 44.1 kHz"
            },
            {
                "AUDIO_SAMPLE_RATE_48000": "48000: (Default) 48 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioscenariotype",
        "name": "AUDIO_SCENARIO_TYPE",
        "description": "Audio application scenarios.",
        "parameters": [
            {
                "AUDIO_SCENARIO_DEFAULT": "0: The default audio scenario."
            },
            {
                "AUDIO_SCENARIO_CHATROOM_ENTERTAINMENT": "1: Entertainment scenario where users need to frequently switch the user role."
            },
            {
                "AUDIO_SCENARIO_EDUCATION": "2: Education scenario where users want smoothness and stability."
            },
            {
                "AUDIO_SCENARIO_GAME_STREAMING": "3: High-quality audio chatroom scenario where hosts mainly play music."
            },
            {
                "AUDIO_SCENARIO_SHOWROOM": "4: Showroom scenario where a single host wants high-quality audio."
            },
            {
                "AUDIO_SCENARIO_CHATROOM_GAMING": "5: Gaming scenario for group chat that only contains the human voice."
            },
            {
                "AUDIO_SCENARIO_IOT": "6: IoT (Internet of Things) scenario where users use IoT devices with low power consumption."
            },
            {
                "AUDIO_SCENARIO_MEETING": "\n      \n \n     Since\n     v3.2.0\n \n      \n      8: Meeting scenario that mainly contains the human voice.\n  "
            },
            {
                "AUDIO_SCENARIO_NUM": "The number of elements in the enumeration."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_capturebrightnessleveltype",
        "name": "CAPTURE_BRIGHTNESS_LEVEL_TYPE",
        "description": "The brightness level of the video image captured by the local camera.Since\n                    v3.3.0",
        "parameters": [
            {
                "CAPTURE_BRIGHTNESS_LEVEL_INVALID": "-1: The SDK does not detect the brightness level of the video image. Wait a few seconds to get the brightness level from captureBrightnessLevel in the next callback."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_NORMAL": "0: The brightness level of the video image is normal."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_BRIGHT": "1: The brightness level of the video image is too bright."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_DARK": "2: The brightness level of the video image is too dark."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_captureroutputpreference",
        "name": "CAPTURER_OUTPUT_PREFERENCE",
        "description": "Camera capture preference.",
        "parameters": [
            {
                "CAPTURER_OUTPUT_PREFERENCE_AUTO": "0: (Default) Automatically adjust the camera capture preference. The SDK adjusts the camera output parameters according to the system performance and network conditions to balance CPU consumption and video preview quality."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE": "1: Prioritizes the system performance. The SDK chooses the dimension and frame rate of the local camera capture closest to those set by setVideoEncoderConfiguration. In this case, the local preview quality depends on the encoder."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_PREVIEW": "2: Prioritizes the local preview quality. The SDK chooses higher camera output parameters to improve the local video preview quality. This option requires extra CPU and RAM usage for video pre-processing."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_MANUAL": "\n                        \n                            \n                                Since\n                                v3.3.0\n                            \n                        \n                        3: Allows you to customize the width and height of the video image captured by the local camera.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayerror",
        "name": "CHANNEL_MEDIA_RELAY_ERROR",
        "description": "The error code of the channel media replay.",
        "parameters": [
            {
                "RELAY_OK": "0: No error."
            },
            {
                "RELAY_ERROR_SERVER_ERROR_RESPONSE": "1: An error occurs in the server response."
            },
            {
                "RELAY_ERROR_SERVER_NO_RESPONSE": "\n      2: No server response.\n      You can call leaveChannel to leave the channel.\n      This error can also occur if your project has not enabled co-host token authentication. Contact support@agora.io to enable the co-host token authentication service before starting a channel media relay.\n  "
            },
            {
                "RELAY_ERROR_NO_RESOURCE_AVAILABLE": "3: The SDK fails to access the service, probably due to limited resources of the server."
            },
            {
                "RELAY_ERROR_FAILED_JOIN_SRC": "4: Fails to send the relay request."
            },
            {
                "RELAY_ERROR_FAILED_JOIN_DEST": "5: Fails to accept the relay request."
            },
            {
                "RELAY_ERROR_FAILED_PACKET_RECEIVED_FROM_SRC": "6: The server fails to receive the media stream."
            },
            {
                "RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST": "7: The server fails to send the media stream."
            },
            {
                "RELAY_ERROR_SERVER_CONNECTION_LOST": "8: The SDK disconnects from the server due to poor network connections. You can call the leaveChannel method to leave the channel."
            },
            {
                "RELAY_ERROR_INTERNAL_ERROR": "9: An internal error occurs in the server."
            },
            {
                "RELAY_ERROR_SRC_TOKEN_EXPIRED": "10: The token of the source channel has expired."
            },
            {
                "RELAY_ERROR_DEST_TOKEN_EXPIRED": "11: The token of the destination channel has expired."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayevent",
        "name": "CHANNEL_MEDIA_RELAY_EVENT",
        "description": "The event code of channel media relay.",
        "parameters": [
            {
                "RELAY_EVENT_NETWORK_DISCONNECTED": "0: The user disconnects from the server due to a poor network connection."
            },
            {
                "RELAY_EVENT_NETWORK_CONNECTED": "1: The user is connected to the server."
            },
            {
                "RELAY_EVENT_PACKET_JOINED_SRC_CHANNEL": "2: The user joins the source channel."
            },
            {
                "RELAY_EVENT_PACKET_JOINED_DEST_CHANNEL": "3: The user joins the destination channel."
            },
            {
                "RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL": "4: The SDK starts relaying the media stream to the destination channel."
            },
            {
                "RELAY_EVENT_PACKET_RECEIVED_VIDEO_FROM_SRC": "5: The server receives the audio stream from the source channel."
            },
            {
                "RELAY_EVENT_PACKET_RECEIVED_AUDIO_FROM_SRC": "6: The server receives the audio stream from the source channel."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL": "7: The destination channel is updated."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED": "8: The destination channel update fails due to internal reasons."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_NOT_CHANGE": "9: The destination channel does not change, which means that the destination channel fails to be updated."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_IS_NULL": "10: The destination channel name is null."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelaystate",
        "name": "CHANNEL_MEDIA_RELAY_STATE",
        "description": "The state code of the channel media relay.",
        "parameters": [
            {
                "RELAY_STATE_IDLE": "0: The initial state. After you successfully stop the channel media relay by calling stopChannelMediaRelay, the CHANNEL_MEDIA_RELAY_STATE callback returns this state."
            },
            {
                "RELAY_STATE_CONNECTING": "1: The SDK tries to relay the media stream to the destination channel."
            },
            {
                "RELAY_STATE_RUNNING": "2: The SDK successfully relays the media stream to the destination channel."
            },
            {
                "RELAY_STATE_FAILURE": "3: An error occurs. See code in CHANNEL_MEDIA_RELAY_STATE for the error code."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelprofiletype",
        "name": "CHANNEL_PROFILE_TYPE",
        "description": "The channel profile.",
        "parameters": [
            {
                "CHANNEL_PROFILE_COMMUNICATION": "0: (Default) The communication profile. This profile applies to scenarios such as an audio call or video call, where all users can publish and subscribe to streams."
            },
            {
                "CHANNEL_PROFILE_LIVE_BROADCASTING": "1: Live streaming. In this profile, you can set the role of users as the host or audience by calling setClientRole. A host both publishes and subscribes to streams, while an audience subscribes to streams only. This profile applies to scenarios such as a chat room or interactive video streaming."
            },
            {
                "CHANNEL_PROFILE_GAME": "2: Gaming. Agora does not recommend using this setting."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_clientroletype",
        "name": "CLIENT_ROLE_TYPE",
        "description": "The user role in the interactive live streaming.",
        "parameters": [
            {
                "CLIENT_ROLE_BROADCASTER": "1: Host. A host can both send and receive streams."
            },
            {
                "CLIENT_ROLE_AUDIENCE": "2: (Default) Audience. An audience member can only receive streams."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_cloudproxytype",
        "name": "CLOUD_PROXY_TYPE",
        "description": "The cloud proxy type.",
        "parameters": [
            {
                "NONE_PROXY": "0: Do not use cloud proxy."
            },
            {
                "UDP_PROXY": "1: Use cloud proxy with the UDP protocol."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionchangedreasontype",
        "name": "CONNECTION_CHANGED_REASON_TYPE",
        "description": "Reasons causing the change of the connection state.",
        "parameters": [
            {
                "CONNECTION_CHANGED_CONNECTING": "0: The SDK is connecting to the Agora edge server."
            },
            {
                "CONNECTION_CHANGED_JOIN_SUCCESS": "1: The SDK has joined the channel successfully."
            },
            {
                "CONNECTION_CHANGED_INTERRUPTED": "2: The connection between the SDK and the Agora edge server is interrupted."
            },
            {
                "CONNECTION_CHANGED_BANNED_BY_SERVER": "3: The connection between the SDK and the Agora edge server is banned by the Agora edge server. This error occurs when the user is kicked out of the channel by the server."
            },
            {
                "CONNECTION_CHANGED_JOIN_FAILED": "4: The SDK fails to join the channel. When the SDK fails to join the channel for more than 20 minutes, this error occurs and the SDK stops reconnecting to the channel."
            },
            {
                "CONNECTION_CHANGED_LEAVE_CHANNEL": "5: The SDK has left the channel."
            },
            {
                "CONNECTION_CHANGED_INVALID_APP_ID": "6: The connection failed because the App ID is not valid. Please rejoin the channel with a valid App ID."
            },
            {
                "CONNECTION_CHANGED_INVALID_CHANNEL_NAME": "7: The connection failed since channel name is not valid. Please rejoin the channel with a valid channel name."
            },
            {
                "CONNECTION_CHANGED_INVALID_TOKEN": "8: The connection failed because the token is not valid. Typical reasons include:\n      The App Certificate for the project is enabled in Agora Console, but you do not use a token when joining the channel. If you enable the App Certificate, you must use a token to join the channel.\n      The uid specified when calling joinChannel to join the channel is inconsistent with the uid passed in when generating the token.\n  "
            },
            {
                "CONNECTION_CHANGED_TOKEN_EXPIRED": "9: The connection failed since token is expired."
            },
            {
                "CONNECTION_CHANGED_REJECTED_BY_SERVER": "10: The connection is rejected by server. Typical reasons include:\n      The user is already in the channel and still calls a method, for example, joinChannel, to join the channel. Stop calling this method to clear this error.\n      The user tries to join the channel when calling startEchoTest for a call test. The user needs to call the channel after the call test ends.\n  \n  "
            },
            {
                "CONNECTION_CHANGED_SETTING_PROXY_SERVER": "11: The connection state changed to reconnecting because the SDK has set a proxy server."
            },
            {
                "CONNECTION_CHANGED_RENEW_TOKEN": "12: The connection state changed because the token is renewed."
            },
            {
                "CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED": "13: The IP address of the client has changed, possibly because the network type, IP address, or port has been changed."
            },
            {
                "CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT": "14: Timeout for the keep-alive of the connection between the SDK and the Agora edge server. The connection state changes to CONNECTION_STATE_RECONNECTING."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionstatetype",
        "name": "CONNECTION_STATE_TYPE",
        "description": "Connection states.",
        "parameters": [
            {
                "CONNECTION_STATE_DISCONNECTED": "1: The SDK is disconnected from the Agora edge server. The state indicates the SDK is in one of the following phases:\n      The initial state before calling the joinChannel method.\n      The app calls the leaveChannel method.\n  \n  "
            },
            {
                "CONNECTION_STATE_CONNECTING": "2: The SDK is connecting to the Agora edge server. This state indicates that the SDK is establishing a connection with the specified channel after the app calls joinChannel.\n      If the SDK successfully joins the channel, it triggers the CONNECTION_STATE_CHANGED callback and the connection state switches to CONNECTION_STATE_CONNECTED.\n      After the connection is established, the SDK also initializes the media and triggers JOINED_CHANNEL when everything is ready.\n  \n  "
            },
            {
                "CONNECTION_STATE_CONNECTED": "3: The SDK is connected to the Agora edge server. This state also indicates that the user has joined a channel and can now publish or subscribe to a media stream in the channel. If the connection to the Agora edge server is lost because, for example, the network is down or switched, the SDK automatically tries to reconnect and triggers CONNECTION_STATE_CHANGED that indicates the connection state switches to CONNECTION_STATE_RECONNECTING."
            },
            {
                "CONNECTION_STATE_RECONNECTING": "4: The SDK keeps reconnecting to the Agora edge server. The SDK keeps rejoining the channel after being disconnected from a joined channel because of network issues.\n      If the SDK cannot rejoin the channel within 10 seconds, it triggers CONNECTION_LOST, stays in the CONNECTION_STATE_RECONNECTING state, and keeps rejoining the channel.\n      If the SDK fails to rejoin the channel 20 minutes after being disconnected from the Agora edge server, the SDK triggers the CONNECTION_STATE_CHANGED callback, switches to the CONNECTION_STATE_FAILED state, and stops rejoining the channel.\n  "
            },
            {
                "CONNECTION_STATE_FAILED": "5: The SDK fails to connect to the Agora edge server or join the channel. This state indicates that the SDK stops trying to rejoin the channel. You must call leaveChannel to leave the channel.\n      You can call joinChannel to rejoin the channel.\n      If the SDK is banned from joining the channel by the Agora edge server through the RESTful API, the SDK triggers the CONNECTION_STATE_CHANGED callback.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_contentmode",
        "name": "CONTENT_MODE",
        "description": "Video display mode.",
        "parameters": [
            {
                "CROPPED": "Uniformly scale the video until it fills the visible boundaries (cropped). One dimension of the video might have clipped contents."
            },
            {
                "FIT": "Uniformly scale the video until one of its dimensions fits the boundary (zoomed to fit). Areas that are not filled due to disparity in the aspect ratio are filled with black."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_degradationpreference",
        "name": "DEGRADATION_PREFERENCE",
        "description": "Video degradation preferences when the bandwidth is a constraint.",
        "parameters": [
            {
                "MAINTAIN_QUALITY": "0: (Default) Prefers to reduce the video frame rate while maintaining video quality during video encoding under limited bandwidth. This degradation preference is suitable for scenarios where video quality is prioritized.\n  In the COMMUNICATION channel profile, the resolution of the video sent may change, so remote users need to handle this issue. See VIDEO_SIZE_CHANGED."
            },
            {
                "MAINTAIN_FRAMERATE": "1: Prefers to reduce the video quality while maintaining the video frame rate during video encoding under limited bandwidth. This degradation preference is suitable for scenarios where smoothness is prioritized and video quality is allowed to be reduced."
            },
            {
                "MAINTAIN_BALANCED": "\n                        2: Reduces the video frame rate and video quality simultaneously during video encoding under limited bandwidth. MAINTAIN_BALANCED has a lower reduction than MAINTAIN_QUALITY and MAINTAIN_FRAMERATE, and this preference is suitable for scenarios where both smoothness and video quality are a priority.\n                        The resolution of the video sent may change, so remote users need to handle this issue. See VIDEO_SIZE_CHANGED.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_encryptionmode",
        "name": "ENCRYPTION_MODE",
        "description": "The built-in encryption mode.",
        "parameters": [
            {
                "AES_128_XTS": "1: (Default) 128-bit AES encryption, XTS mode."
            },
            {
                "AES_128_ECB": "2: 128-bit AES encryption, ECB mode."
            },
            {
                "AES_256_XTS": "3: 256-bit AES encryption, XTS mode."
            },
            {
                "AES_128_GCM": "\n               \n                   \n                       Since\n                       v3.3.1\n                   \n               \n               5: 128-bit AES encryption, GCM mode."
            },
            {
                "AES_256_GCM": "\n               \n                   \n                       Since\n                       v3.3.1\n                   \n               \n               6: 256-bit AES encryption, GCM mode."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencepoorreason",
        "name": "EXPERIENCE_POOR_REASON",
        "description": "Reasons why the QoE of the local user when receiving a remote audio stream is poor.Since\n                v3.3.0",
        "parameters": [
            {
                "EXPERIENCE_REASON_NONE": "0: No reason, indicating a good QoE of the local user."
            },
            {
                "REMOTE_NETWORK_QUALITY_POOR": "1: The remote user's network quality is poor."
            },
            {
                "LOCAL_NETWORK_QUALITY_POOR": "2: The local user's network quality is poor."
            },
            {
                "WIRELESS_SIGNAL_POOR": "4: The local user's Wi-Fi or mobile network signal is weak."
            },
            {
                "WIFI_BLUETOOTH_COEXIST": "8: The local user enables both Wi-Fi and bluetooth, and their signals interfere with each other. As a result, audio transmission quality is undermined."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencequalitytype",
        "name": "EXPERIENCE_QUALITY_TYPE",
        "description": "The Quality of Experience (QoE) of the local user when receiving a remote audio stream.Since\n                v3.3.0",
        "parameters": [
            {
                "EXPERIENCE_QUALITY_GOOD": "0: The QoE of the local user is good."
            },
            {
                "EXPERIENCE_QUALITY_BAD": "1: The QoE of the local user is poor."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_framerate",
        "name": "FRAME_RATE",
        "description": "Video frame rate.",
        "parameters": [
            {
                "FRAME_RATE_FPS_1": "1: 1 fps"
            },
            {
                "FRAME_RATE_FPS_7": "7: 7 fps"
            },
            {
                "FRAME_RATE_FPS_10": "10: 10 fps"
            },
            {
                "FRAME_RATE_FPS_15": "15: 15 fps"
            },
            {
                "FRAME_RATE_FPS_24": "24: 24 fps"
            },
            {
                "FRAME_RATE_FPS_30": "30: 30 fps"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_injectstreamstatus",
        "name": "INJECT_STREAM_STATUS",
        "description": "States of importing an external video stream in the interactive live streaming.",
        "parameters": [
            {
                "INJECT_STREAM_STATUS_START_SUCCESS": "0: The external video stream is imported successfully."
            },
            {
                "INJECT_STREAM_STATUS_START_ALREADY_EXISTS": "1: The external video stream already exists."
            },
            {
                "INJECT_STREAM_STATUS_START_UNAUTHORIZED": "2: The external video stream to be imported is unauthorized."
            },
            {
                "INJECT_STREAM_STATUS_START_TIMEDOUT": "3: A timeout occurs when importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_START_FAILED": "4: The SDK fails to import the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_SUCCESS": "5: The SDK successfully stops importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_NOT_FOUND": "6: The external video stream to be stopped importing is not found."
            },
            {
                "INJECT_STREAM_STATUS_STOP_UNAUTHORIZED": "7: The external video stream to be stopped importing is unauthorized."
            },
            {
                "INJECT_STREAM_STATUS_STOP_TIMEDOUT": "8: A timeout occurs when stopping importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_FAILED": "9: The SDK fails to stop importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_BROKEN": "10: The external video stream is corrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lastmileproberesultstate",
        "name": "LASTMILE_PROBE_RESULT_STATE",
        "description": "The status of the last-mile network tests.",
        "parameters": [
            {
                "LASTMILE_PROBE_RESULT_COMPLETE": "1: The last-mile network probe test is complete."
            },
            {
                "LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE": "2: The last-mile network probe test is incomplete because the bandwidth estimation is not available due to limited test resources."
            },
            {
                "LASTMILE_PROBE_RESULT_UNAVAILABLE": "3: The last-mile network probe test is not carried out, probably due to poor network conditions."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lighteningcontrastlevel",
        "name": "LIGHTENING_CONTRAST_LEVEL",
        "description": "The contrast level.",
        "parameters": [
            {
                "LIGHTENING_CONTRAST_LOW": "Low contrast level."
            },
            {
                "LIGHTENING_CONTRAST_NORMAL": "(Default) Normal contrast level."
            },
            {
                "LIGHTENING_CONTRAST_HIGH": "High contrast level."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamerror",
        "name": "LOCAL_AUDIO_STREAM_ERROR",
        "description": "Local audio state error codes.",
        "parameters": [
            {
                "LOCAL_AUDIO_STREAM_ERROR_OK": "0: The local audio is normal."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_FAILURE": "1: No specified reason for the local audio failure."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION": "2: No permission to use the local audio device."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY": "3: The microphone is in use."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE": "4: The local audio capturing fails. Check whether the capturing device is working properly."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE": "5: The local audio encoding fails."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamstate",
        "name": "LOCAL_AUDIO_STREAM_STATE",
        "description": "Local audio states.",
        "parameters": [
            {
                "LOCAL_AUDIO_STREAM_STATE_STOPPED": "0: The local audio is in the initial state."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_RECORDING": "1: The capturing device starts successfully."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_ENCODING": "2: The first audio frame encodes successfully."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_FAILED": "3: The local audio fails to start."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamerror",
        "name": "LOCAL_VIDEO_STREAM_ERROR",
        "description": "Local video state error codes.",
        "parameters": [
            {
                "LOCAL_VIDEO_STREAM_ERROR_OK": "0: The local video is normal."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_FAILURE": "1: No specified reason for the local video failure."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION": "2: No permission to use the local video capturing device."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY": "3: The local video capturing device is in use."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE": "5: The local video encoding fails."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_DEVICE_NOT_FOUND": "\n                        8: Fails to find a local video capture device.\n                    "
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED": "11: When calling startScreenCaptureByWindow to share the window, the shared window is in a minimized state."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_CLOSED": "\n      \n          \n              Since\n              v3.2.0\n          \n      \n      12: The error code indicates that a window shared by the window ID has been closed, or a full-screen window shared by the window ID has exited full-screen mode. After exiting full-screen mode, remote users cannot see the shared window. To prevent remote users from seeing a black screen, Agora recommends that you immediately stop screen sharing.\n      Common scenarios for reporting this error code:\n When the local user closes the shared window, the SDK reports this error code.\n     The local user shows some slides in full-screen mode first, and then shares the windows of the slides. After the user exits full-screen mode, the SDK reports this error code.\n     The local user watches web video or reads web document in full-screen mode first, and then shares the window of the web video or document. After the user exits full-screen mode, the SDK reports this error code.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamstate",
        "name": "LOCAL_VIDEO_STREAM_STATE",
        "description": "Local video states.",
        "parameters": [
            {
                "LOCAL_VIDEO_STREAM_STATE_STOPPED": "0: The local video is in the initial state."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_CAPTURING": "1: The local video capturing device starts successfully. The SDK also reports this state when you call startScreenCaptureByWindow to share a maximized window."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_ENCODING": "2: The first video frame is successfully encoded."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_FAILED": "3: Fails to start the local video."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_logfiltertype",
        "name": "LOG_FILTER_TYPE",
        "description": "The output log level of the SDK.",
        "parameters": [
            {
                "LOG_FILTER_OFF": "0: Do not output any log information."
            },
            {
                "LOG_FILTER_DEBUG": "0x080f: Output all log information. Set your log filter as DEBUG if you want to get the most complete log file."
            },
            {
                "LOG_FILTER_INFO": "0x000f: Output CRITICAL, ERROR, WARNING, and INFO level log information. We recommend setting your log filter as this level."
            },
            {
                "LOG_FILTER_WARN": "0x000e: Output CRITICAL, ERROR, and WARNING level log information."
            },
            {
                "LOG_FILTER_ERROR": "0x000c: Output CRITICAL and ERROR level log information."
            },
            {
                "LOG_FILTER_CRITICAL": "0x0008: Output CRITICAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_loglevel",
        "name": "LOG_LEVEL",
        "description": "The output log level of the SDK.Since\n  v3.3.0",
        "parameters": [
            {
                "LOG_LEVEL_NONE": "0: Do not output any log information."
            },
            {
                "LOG_LEVEL_INFO": "0x0001: (Default) Output FATAL, ERROR,\n                        WARN, and INFO level log information. We\n                        recommend setting your log filter as this level."
            },
            {
                "LOG_LEVEL_WARN": "0x0002: Output FATAL, ERROR, and WARN level\n                        log information."
            },
            {
                "LOG_LEVEL_ERROR": "0x0004: Output FATAL and ERROR level log information."
            },
            {
                "LOG_LEVEL_FATAL": "0x0008: Output FATAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicestatetype",
        "name": "MEDIA_DEVICE_STATE_TYPE",
        "description": "Media device states.",
        "parameters": [
            {
                "MEDIA_DEVICE_STATE_ACTIVE": "1: The device is in use."
            },
            {
                "MEDIA_DEVICE_STATE_DISABLED": "2: The device is disabled."
            },
            {
                "MEDIA_DEVICE_STATE_NOT_PRESENT": "4: The device is not found."
            },
            {
                "MEDIA_DEVICE_STATE_UNPLUGGED": "8: The device is unplugged."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicetype",
        "name": "MEDIA_DEVICE_TYPE",
        "description": "Media device types.",
        "parameters": [
            {
                "UNKNOWN_AUDIO_DEVICE": "-1: Unknown device type."
            },
            {
                "AUDIO_PLAYOUT_DEVICE": "0: Audio playback device."
            },
            {
                "AUDIO_RECORDING_DEVICE": "1: Audio capturing device."
            },
            {
                "VIDEO_RENDER_DEVICE": "2: Video renderer."
            },
            {
                "VIDEO_CAPTURE_DEVICE": "3: Video capturer."
            },
            {
                "AUDIO_APPLICATION_PLAYOUT_DEVICE": "4: Application audio playback device."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_metadatatype",
        "name": "METADATA_TYPE",
        "description": "Metadata type of the  observer. We only support video metadata for now.",
        "parameters": [
            {
                "UNKNOWN_METADATA": "The type of Metadata is unknown."
            },
            {
                "VIDEO_METADATA": "The type of Metadata is video."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_networktype",
        "name": "NETWORK_TYPE",
        "description": "Network type.",
        "parameters": [
            {
                "NETWORK_TYPE_UNKNOWN": "-1: The network type is unknown."
            },
            {
                "NETWORK_TYPE_DISCONNECTED": "0: The SDK disconnects from the network."
            },
            {
                "NETWORK_TYPE_LAN": "1: The network type is LAN."
            },
            {
                "NETWORK_TYPE_WIFI": "2: The network type is Wi-Fi (including hotspots)."
            },
            {
                "NETWORK_TYPE_MOBILE_2G": "3: The network type is mobile 2G."
            },
            {
                "NETWORK_TYPE_MOBILE_3G": "4: The network type is mobile 3G."
            },
            {
                "NETWORK_TYPE_MOBILE_4G": "5: The network type is mobile 4G."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_orientationmode",
        "name": "ORIENTATION_MODE",
        "description": "Video output orientation modes.",
        "parameters": [
            {
                "ORIENTATION_MODE_ADAPTIVE": "\n      0: (Default) The output video always follows the orientation of the captured video. The receiver takes the rotational information passed on from the video encoder. This mode applies to scenarios where video orientation can be adjusted on the receiver.\n      \n If the captured video is in landscape mode, the output video is in landscape mode.\n If the captured video is in portrait mode, the output video is in portrait mode.\n      \n  "
            },
            {
                "ORIENTATION_FIXED_LANDSCAPE": "1: In this mode, the SDK always outputs videos in landscape (horizontal) mode. If the captured video is in portrait mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            },
            {
                "ORIENTATION_FIXED_PORTRAIT": "2: In this mode, the SDK always outputs video in portrait (portrait) mode. If the captured video is in landscape mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_prioritytype",
        "name": "PRIORITY_TYPE",
        "description": "The priority of the remote user.",
        "parameters": [
            {
                "PRIORITY_HIGH": "The user's priority is high."
            },
            {
                "PRIORITY_NORMAL": "(Default) The user's priority is normal."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualityadaptindication",
        "name": "QUALITY_ADAPT_INDICATION",
        "description": "Quality change of the local video in terms of target frame rate and target bit rate since last count.",
        "parameters": [
            {
                "ADAPT_NONE": "The quality stays the same."
            },
            {
                "ADAPT_UP_BANDWIDTH": "The quality improves because the network bandwidth increases."
            },
            {
                "ADAPT_DOWN_BANDWIDTH": "The quality worsens because the network bandwidth decreases."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualitytype",
        "name": "QUALITY_TYPE",
        "description": "Network quality types.",
        "parameters": [
            {
                "QUALITY_UNKNOWN": "0: The network quality is unknown."
            },
            {
                "QUALITY_EXCELLENT": "1: The network quality is excellent."
            },
            {
                "QUALITY_GOOD": "2: The network quality is quite good, but the bitrate may be slightly lower than excellent."
            },
            {
                "QUALITY_POOR": "3: Users can feel the communication slightly impaired."
            },
            {
                "QUALITY_BAD": "4: Users cannot communicate smoothly."
            },
            {
                "QUALITY_VBAD": "5: The quality is so bad that users can barely communicate."
            },
            {
                "QUALITY_DOWN": "6: The network is down and users cannot communicate at all."
            },
            {
                "QUALITY_UNSUPPORTED": "7: Users cannot detect the network quality. (Not in use.)"
            },
            {
                "QUALITY_DETECTING": "8: Detecting the network quality."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rawaudioframeopmodetype",
        "name": "RAW_AUDIO_FRAME_OP_MODE_TYPE",
        "description": "The use mode of the audio data.",
        "parameters": [
            {
                "RAW_AUDIO_FRAME_OP_MODE_READ_ONLY": "0: Read-only mode: Users only read the data without modifying anything. For example, when users acquire the data with the Agora SDK, then push the RTMP or RTMPS streams."
            },
            {
                "RAW_AUDIO_FRAME_OP_MODE_WRITE_ONLY": "1: Write-only mode: Users replace the returned data with their own data and pass the data to the SDK for encoding. For example, when users acquire the data."
            },
            {
                "RAW_AUDIO_FRAME_OP_MODE_READ_WRITE": "2: Read and write mode: Users read the returned data, modify it, and then play it. For example, when users have their own sound-effect processing module and perform some voice pre-processing, such as a voice change."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostate",
        "name": "REMOTE_AUDIO_STATE",
        "description": "Remote audio states.",
        "parameters": [
            {
                "REMOTE_AUDIO_STATE_STOPPED": "0: The local audio is in the initial state. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_LOCAL_MUTED, REMOTE_AUDIO_STATE_REASON_REMOTE_MUTED or REMOTE_AUDIO_STATE_REASON_REMOTE_OFFLINE."
            },
            {
                "REMOTE_AUDIO_STATE_STARTING": "1: The first remote audio packet is received."
            },
            {
                "REMOTE_AUDIO_STATE_DECODING": "2: The remote audio stream is decoded and plays normally. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_NETWORK_RECOVERY, REMOTE_AUDIO_STATE_REASON_LOCAL_UNMUTED or REMOTE_AUDIO_STATE_REASON_REMOTE_UNMUTED."
            },
            {
                "REMOTE_AUDIO_STATE_FROZEN": "3: The remote audio is frozen. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_NETWORK_CONGESTION."
            },
            {
                "REMOTE_AUDIO_STATE_FAILED": "4: The remote audio fails to start. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_INTERNAL."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostatereason",
        "name": "REMOTE_AUDIO_STATE_REASON",
        "description": "The reason for the remote audio state change.",
        "parameters": [
            {
                "REMOTE_AUDIO_STATE_REASON_INTERNAL": "0: The SDK reports this reason when the audio state changes."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_NETWORK_CONGESTION": "1: Network congestion."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_NETWORK_RECOVERY": "2: Network recovery."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_LOCAL_MUTED": "3: The local user stops receiving the remote audio stream or disables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote audio stream or enables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_MUTED": "5: The remote user stops sending the audio stream or disables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the audio stream or enables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostate",
        "name": "REMOTE_VIDEO_STATE",
        "description": "The state of the remote video.",
        "parameters": [
            {
                "REMOTE_VIDEO_STATE_STOPPED": "0: The remote video is in the initial state. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED, REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED or REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE."
            },
            {
                "REMOTE_VIDEO_STATE_STARTING": "1: The first remote video packet is received."
            },
            {
                "REMOTE_VIDEO_STATE_DECODING": "2: The remote video stream is decoded and plays normally. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY, REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED,REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED, or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY."
            },
            {
                "REMOTE_VIDEO_STATE_FROZEN": "3: The remote video is frozen. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK."
            },
            {
                "REMOTE_VIDEO_STATE_FAILED": "4: The remote video fails to start. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_INTERNAL."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostatereason",
        "name": "REMOTE_VIDEO_STATE_REASON",
        "description": "The reason for the remote video state change.",
        "parameters": [
            {
                "REMOTE_VIDEO_STATE_REASON_INTERNAL": "0: The SDK reports this reason when the video state changes."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION": "1: Network congestion."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY": "2: Network recovery."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED": "3: The local user stops receiving the remote video stream or disables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote video stream or enables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED": "5: The remote user stops sending the video stream or disables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the video stream or enables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK": "8: The remote audio-and-video stream falls back to the audio-only stream due to poor network conditions."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY": "9: The remote audio-only stream switches back to the audio-and-video stream after the network conditions improve."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostreamtype",
        "name": "REMOTE_VIDEO_STREAM_TYPE",
        "description": "The type of video streams.",
        "parameters": [
            {
                "REMOTE_VIDEO_STREAM_HIGH": "0: High-quality video stream."
            },
            {
                "REMOTE_VIDEO_STREAM_LOW": "1: Low-quality video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rendermodeelectron",
        "name": "RENDER_MODE",
        "description": "Video rendering mode.",
        "parameters": [
            {
                "WEBGL": "WebGL rendering."
            },
            {
                "SOFTWARE": "Software rendering."
            },
            {
                "CUSTOM": "Customized rendering."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreamingevent",
        "name": "RTMP_STREAMING_EVENT",
        "description": "Events during the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE": "An error occurs when you add a background image or a watermark image to the RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublisherror",
        "name": "RTMP_STREAM_PUBLISH_ERROR",
        "description": "Error codes of the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAM_PUBLISH_ERROR_OK": "The RTMP or RTMPS streaming publishes successfully."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT": "Invalid argument used. Please check the parameter setting. For example, if you do not call setLiveTranscoding to set the transcoding parameters before calling addPublishStreamUrl, the SDK returns this error."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED": "Check whether you set the parameters in the setLiveTranscoding method properly."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT": "The RTMP or RTMPS streaming is encrypted and cannot be published. Call addPublishStreamUrl to re-publish the stream."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR": "An error occurs in Agora's streaming server. Call the addPublishStreamUrl method to publish the streaming again."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR": "An error occurs in the CDN server."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN": "The RTMP or RTMPS streaming publishes too frequently."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT": "The host has published more than 10 URLs. Delete the unnecessary URLs before adding new ones."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED": "The host manipulates other hosts' streams. For example, the host updates or stops other hosts' streams. Check your app logic."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND": "Agora's server fails to find the RTMP or RTMPS streaming."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED": "The URL format is incorrect. Check whether the URL format is correct."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublishstate",
        "name": "RTMP_STREAM_PUBLISH_STATE",
        "description": "States of the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAM_PUBLISH_STATE_IDLE": "The RTMP or RTMPS streaming has not started or has ended. This state is also triggered after you remove an RTMP or RTMPS stream from the CDN by calling removePublishStreamUrl."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_CONNECTING": "The SDK is connecting to Agora's streaming server and the CDN server. This state is triggered after you call the addPublishStreamUrl method."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_RUNNING": "The RTMP or RTMPS streaming publishes. The SDK successfully publishes the RTMP or RTMPS streaming and returns this state."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_RECOVERING": "\n      The RTMP or RTMPS streaming is recovering. When exceptions occur to the CDN, or the streaming is interrupted, the SDK tries to resume RTMP or RTMPS streaming and returns this state.\n      \n If the SDK successfully resumes the streaming, RTMP_STREAM_PUBLISH_STATE_RUNNING(2) returns.\n If the streaming does not resume within 60 seconds or server errors occur, RTMP_STREAM_PUBLISH_STATE_FAILURE(4) returns. You can also reconnect to the server by calling the removePublishStreamUrl and addPublishStreamUrl methods.\n      \n  "
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_FAILURE": "The RTMP or RTMPS streaming fails. See the error code for the detailed error information. You can also call the addPublishStreamUrl method to publish the RTMP or RTMPS stream again."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamfallbackoptions",
        "name": "STREAM_FALLBACK_OPTIONS",
        "description": "Stream fallback options.",
        "parameters": [
            {
                "STREAM_FALLBACK_OPTION_DISABLED": "0: No fallback behavior for the local/remote video stream when the uplink/downlink network conditions are poor. The quality of the stream is not guaranteed."
            },
            {
                "STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW": "1: Under poor downlink network conditions, the remote video stream, to which you subscribe, falls back to the low-quality (low resolution and low bitrate) video stream. This option is only valid for setRemoteSubscribeFallbackOption and is invalid for setLocalPublishFallbackOption."
            },
            {
                "STREAM_FALLBACK_OPTION_AUDIO_ONLY": "2: Under poor uplink network conditions, the published video stream falls back to audio only. Under poor downlink network conditions, the remote video stream, to which you subscribe, first falls back to the low-quality (low resolution and low bitrate) video stream; and then to an audio-only stream if the network conditions worsen."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streampublishstate",
        "name": "STREAM_PUBLISH_STATE",
        "description": "The publishing state.",
        "parameters": [
            {
                "PUB_STATE_IDLE": "0: The initial publishing state after joining the channel."
            },
            {
                "PUB_STATE_NO_PUBLISHED": "\n      1: Fails to publish the local stream. Possible reasons:\n The local user calls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending the local media stream.\n The local user calls disableAudio or disableVideo to disable the local audio or video module.\n The local user calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n     The role of the local user is audience.\n \n  "
            },
            {
                "PUB_STATE_PUBLISHING": "2: Publishing."
            },
            {
                "PUB_STATE_PUBLISHED": "3: Publishes successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamsubscribestate",
        "name": "STREAM_SUBSCRIBE_STATE",
        "description": "The subscribing state.",
        "parameters": [
            {
                "SUB_STATE_IDLE": "0: The initial subscribing state after joining the channel."
            },
            {
                "SUB_STATE_NO_SUBSCRIBED": "\n      1: Fails to subscribe to the remote stream. Possible reasons:\n     The remote user:\nCalls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending local media stream.\nCalls disableAudio or disableVideo to disable the local audio or video module.\n    Calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n    The role of the remote user is audience.\n\n     The local user calls the following methods to stop receiving remote streams:\n    Calls muteRemoteAudioStream(true), muteAllRemoteAudioStreams(true) or setDefaultMuteAllRemoteAudioStreams(true) to stop receiving the remote audio streams.\n    Calls muteRemoteVideoStream(true), muteAllRemoteVideoStreams(true) or setDefaultMuteAllRemoteVideoStreams(true) to stop receiving the remote video streams.\n\n \n  "
            },
            {
                "SUB_STATE_SUBSCRIBING": "2: Subscribing."
            },
            {
                "SUB_STATE_SUBSCRIBED": "3: Subscribes to and receives the remote stream successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_userofflinereasontype",
        "name": "USER_OFFLINE_REASON_TYPE",
        "description": "Reasons for a user being offline.",
        "parameters": [
            {
                "USER_OFFLINE_QUIT": "0: The user quits the call."
            },
            {
                "USER_OFFLINE_DROPPED": "1: The SDK times out and the user drops offline because no data packet is received within a certain period of time.\n      If the user quits the call and the message is not passed to the SDK (due to an unreliable channel), the SDK assumes the user dropped offline."
            },
            {
                "USER_OFFLINE_BECOME_AUDIENCE": "2: The user switches the client role from the host to the audience."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodecprofiletype",
        "name": "VIDEO_CODEC_PROFILE_TYPE",
        "description": "Video codec profile types.",
        "parameters": [
            {
                "VIDEO_CODEC_PROFILE_BASELINE": "66: Baseline video codec profile. Generally used for video calls on mobile phones."
            },
            {
                "VIDEO_CODEC_PROFILE_MAIN": "77: Main video codec profile. Generally used in mainstream electronics such as MP4 players, portable video players, PSP, and iPads."
            },
            {
                "VIDEO_CODEC_PROFILE_HIGH": "100: (Default) High video codec profile. Generally used in high-resolution live streaming or television."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodectype",
        "name": "VIDEO_CODEC_TYPE",
        "description": "Video codec types.",
        "parameters": [
            {
                "VIDEO_CODEC_VP8": "Standard VP8."
            },
            {
                "VIDEO_CODEC_H264": "Standard H.264."
            },
            {
                "VIDEO_CODEC_EVP": "Enhanced VP8."
            },
            {
                "VIDEO_CODEC_E264": "Enhanced H.264."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodectypeforstream",
        "name": "VIDEO_CODEC_TYPE_FOR_STREAM",
        "description": "The codec type of the output video.",
        "parameters": [
            {
                "null": "2: H.265."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocontenthint",
        "name": "VideoContentHint",
        "description": "The content hint for screen sharing.",
        "parameters": [
            {
                "CONTENT_HINT_NONE": "(Default) No content hint."
            },
            {
                "CONTENT_HINT_MOTION": "Motion-intensive content. Choose this option if you prefer smoothness or when you are sharing a video clip, movie, or video game."
            },
            {
                "CONTENT_HINT_DETAILS": "Motionless content. Choose this option if you prefer sharpness or when you are sharing a\n                        picture, PowerPoint slides, or texts."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videomirrormodetype",
        "name": "VIDEO_MIRROR_MODE_TYPE",
        "description": "Video mirror mode.",
        "parameters": [
            {
                "VIDEO_MIRROR_MODE_AUTO": "0: (Default) The SDK determines the mirror mode."
            },
            {
                "VIDEO_MIRROR_MODE_ENABLED": "1: Enable mirror mode."
            },
            {
                "VIDEO_MIRROR_MODE_DISABLED": "2: Disable mirror mode."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videoprofiletype",
        "name": "VIDEO_PROFILE_TYPE",
        "description": "Video profile",
        "parameters": [
            {
                "VIDEO_PROFILE_LANDSCAPE_120P": "0: 160 × 120, frame rate 15 fps, bitrate 65 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_120P_3": "2: 120 × 120, frame rate 15 fps, bitrate 50 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P": "10: 320 × 180, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P_3": "12: 180 × 180, frame rate 15 fps, bitrate 100 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P_4": "13: 240 × 180, frame rate 15 fps, bitrate 120 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P": "20: 320 × 240, frame rate 15 fps, bitrate 200 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P_3": "22: 240 × 240, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P_4": "23: 424 × 240, frame rate 15 fps, bitrate 220 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P": "30: 640 × 360, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_3": "32: 360 × 360, frame rate 15 fps, bitrate 260 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_4": "33: 640 × 360, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_6": "35: 360 × 360, frame rate 30 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_7": "36: 480 × 360, frame rate 15 fps, bitrate 320 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_8": "37: 480 × 360, frame rate 30 fps, bitrate 490 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_9": "\n      38: 640 × 360, frame rate 15 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_10": "39: 640 × 360, frame rate 24 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_11": "100: 640 × 360, frame rate 24 fps, bitrate 1000 Kbps.\n      This profile applies only to the live streaming channel profile."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P": "40: 640 × 480, frame rate 15 fps, bitrate 500 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_3": "42: 480 × 480, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_4": "43: 640 × 480, frame rate 30 fps, bitrate 750 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_6": "45: 480 × 480, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_8": "47: 848 × 480, frame rate 15 fps, bitrate 610 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_9": "48: 848 × 480, frame rate 30 fps, bitrate 930 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_10": "49: 640 × 480, frame rate 10 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P": "50: 1280 × 720, frame rate 15 fps, bitrate 1130 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_3": "52: 1280 × 720, frame rate 30 fps, bitrate 1710 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_5": "54: 960 × 720, frame rate 15 fps, bitrate 910 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_6": "55: 960 × 720, frame rate 30 fps, bitrate 1380 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P": "60: 1920 × 1080, frame rate 15 fps, bitrate 2080 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P_3": "60: 1920 × 1080, frame rate 30 fps, bitrate 3150 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P_5": "64: 1920 × 1080, frame rate 60 fps, bitrate 4780 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_120P": "1000: 120 × 160, frame rate 15 fps, bitrate 65 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_120P_3": "1002: 120 × 120, frame rate 15 fps, bitrate 50 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P": "1010: 180 × 320, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P_3": "1012: 180 × 180, frame rate 15 fps, bitrate 100 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P_4": "1013: 180 × 240, frame rate 15 fps, bitrate 120 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P": "1020: 240 × 320, frame rate 15 fps, bitrate 200 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P_3": "1022: 240 × 240, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P_4": "1023: 240 × 424, frame rate 15 fps, bitrate 220 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P": "1030: 360 × 640, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_3": "1032: 360 × 360, frame rate 15 fps, bitrate 260 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_4": "1033: 360 × 640, frame rate 15 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_6": "1035: 360 × 360, frame rate 30 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_7": "1036: 360 × 480, frame rate 15 fps, bitrate 320 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_8": "1037: 360 × 480, frame rate 30 fps, bitrate 490 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_9": "\n      1038: 360 × 640, frame rate 15 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_10": "\n      1039: 360 × 640, frame rate 24 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_11": "\n      1100: 360 × 640, frame rate 24 fps, bitrate 1000 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P": "1040: 480 × 640, frame rate 15 fps, bitrate 500 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_3": "1042: 480 × 480, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_4": "1043: 480 × 640, frame rate 30 fps, bitrate 750 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_6": "1045: 480 × 480, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_8": "1047: 480 × 848, frame rate 15 fps, bitrate 610 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_9": "1048: 480 × 848, frame rate 30 fps, bitrate 930 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_10": "1049: 480 × 640, frame rate 10 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P": "1050: 720 × 1280, frame rate 15 fps, bitrate 1130 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_3": "1052: 720 × 1280, frame rate 30 fps, bitrate 1710 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_5": "1054: 720 × 960, frame rate 15 fps, bitrate 910 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_6": "1055: 720 × 960, frame rate 30 fps, bitrate 1380 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P": "1060: 1080 × 1920, frame rate 15 fps, bitrate 2080 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P_3": "1062: 1080 × 1920, frame rate 30 fps, bitrate 3150 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P_5": "1064: 1080 × 1920, frame rate 60 fps, bitrate 4780 Kbps."
            },
            {
                "VIDEO_PROFILE_DEFAULT": "(Default) 640 × 360, frame rate 15 fps, bitrate 400 Kbps."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicebeautifierpreset",
        "name": "VOICE_BEAUTIFIER_PRESET",
        "description": "The options for SDK preset voice beautifier effects.",
        "parameters": [
            {
                "VOICE_BEAUTIFIER_OFF": "Turn off voice beautifier effects and use the original voice."
            },
            {
                "CHAT_BEAUTIFIER_MAGNETIC": "A more magnetic voice.\n      Agora recommends using this enumerator to process a male-sounding\n                            voice; otherwise, you might experience vocal distortion."
            },
            {
                "CHAT_BEAUTIFIER_FRESH": "\n      A fresher voice.\n      Agora recommends using this enumerator to process a female-sounding\n                            voice; otherwise, you might experience vocal distortion.\n  "
            },
            {
                "CHAT_BEAUTIFIER_VITALITY": "\n      A more vital voice.\n      Agora recommends using this enumerator to process a female-sounding\n                            voice; otherwise, you might experience vocal distortion.\n  "
            },
            {
                "SINGING_BEAUTIFIER": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Singing beautifier effect.\n      \n If you call setVoiceBeautifierPreset(SINGING_BEAUTIFIER), you can beautify a male-sounding voice and add a reverberation effect that sounds like singing in a small room. Agora recommends using this enumerator to process a male-sounding voice; otherwise, you might experience vocal distortion.\n If you call setVoiceBeautifierParameters(SINGING_BEAUTIFIER, param1, param2), you can beautify a male- or female-sounding voice and add a reverberation effect.\n      \n  "
            },
            {
                "TIMBRE_TRANSFORMATION_VIGOROUS": "A more vigorous voice."
            },
            {
                "TIMBRE_TRANSFORMATION_DEEP": "A deep voice."
            },
            {
                "TIMBRE_TRANSFORMATION_MELLOW": "A mellower voice."
            },
            {
                "TIMBRE_TRANSFORMATION_FALSETTO": "Falsetto."
            },
            {
                "TIMBRE_TRANSFORMATION_FULL": "A fuller voice."
            },
            {
                "TIMBRE_TRANSFORMATION_CLEAR": "A clearer voice."
            },
            {
                "TIMBRE_TRANSFORMATION_RESOUNDING": "A more resounding voice."
            },
            {
                "TIMBRE_TRANSFORMATION_RINGING": "A more ringing voice."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicechangerpreset",
        "name": "VOICE_CHANGER_PRESET",
        "description": "Local voice changer options.",
        "parameters": [
            {
                "VOICE_CHANGER_OFF": "The original voice (no local voice change)."
            },
            {
                "VOICE_CHANGER_OLDMAN": "The voice of an old man."
            },
            {
                "VOICE_CHANGER_BABYBOY": "The voice of a little boy."
            },
            {
                "VOICE_CHANGER_BABYGIRL": "The voice of a little girl."
            },
            {
                "VOICE_CHANGER_ZHUBAJIE": "The voice of Zhu Bajie, a character in Journey to the West who has a voice like that of a growling bear."
            },
            {
                "VOICE_CHANGER_ETHEREAL": "The ethereal voice."
            },
            {
                "VOICE_CHANGER_HULK": "The voice of Hulk."
            },
            {
                "VOICE_BEAUTY_VIGOROUS": "A more vigorous voice."
            },
            {
                "VOICE_BEAUTY_DEEP": "A deeper voice."
            },
            {
                "VOICE_BEAUTY_MELLOW": "A mellower voice."
            },
            {
                "VOICE_BEAUTY_FALSETTO": "Falsetto."
            },
            {
                "VOICE_BEAUTY_FULL": "A fuller voice."
            },
            {
                "VOICE_BEAUTY_CLEAR": "A clearer voice."
            },
            {
                "VOICE_BEAUTY_RESOUNDING": "A more resounding voice."
            },
            {
                "VOICE_BEAUTY_RINGING": "A more ringing voice."
            },
            {
                "VOICE_BEAUTY_SPACIAL": "A more spatially resonant voice."
            },
            {
                "GENERAL_BEAUTY_VOICE_MALE_MAGNETIC": "(For male only) A more magnetic voice. Do not use it when the speaker is a female; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_FRESH": "(For female only) A fresher voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_VITALITY": "(For female only) A more vital voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voice_conversion_preset",
        "name": "VOICE_CONVERSION_PRESET",
        "description": "The options for SDK preset voice conversion effects.Since\n                    v3.3.1",
        "parameters": [
            {
                "VOICE_CONVERSION_OFF": "Turn off voice conversion effects and use the original voice."
            },
            {
                "VOICE_CHANGER_NEUTRAL": "A gender-neutral voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "VOICE_CHANGER_SWEET": "A sweet voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "VOICE_CHANGER_SOLID": "A steady voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            },
            {
                "VOICE_CHANGER_BASS": "A deep voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            }
        ],
        "returns": ""
    }
]