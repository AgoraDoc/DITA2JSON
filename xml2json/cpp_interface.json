[
    {
        "id": "api_addhandler",
        "name": "addHandler",
        "description": "Adds event handlersThe SDK uses the IRtcEngineEventHandler class to send callbacks to the app. The app inherits the methods of this class to receive these callbacks. All methods in this class have default (empty) implementations. Therefore, apps only need to register callbacks according to the scenario. In the callbacks, avoid time-consuming tasks or calling APIs that can block the thread, such as the sendStreamMessage method. Otherwise, the SDK may not work properly.",
        "parameters": [
            {
                "handler": "Callback events to be added. For details, see IRtcEngineEventHandler."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n      This method applies to the Native SDK v2.4.1 and later.\n      This method takes effect only when you are a host in a LIVE_BROADCASTING channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the ongoing live broadcast. This applies to scenarios where all users in the channel can watch a live show and interact with each other. After calling this method, the SDK triggers the onStreamInjectedStatus callback on the local client to report the state of injecting the online media stream; after successfully injecting the media stream, the stream joins the channel, and all users in the channel receive the onUserJoined callback, where uid is 666.",
        "parameters": [
            {
                "url": "\n      The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: InjectStreamConfig."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n      ERR_INVALID_ARGUMENT (-2): The injected URL does not exist. Call this method again to inject the stream and ensure that the URL is valid.\n      ERR_NOT_READY (-3): The user is not in the channel.\n      #ERR_NOT_SUPPORTED (-4): The channel profile is not LIVE_BROADCASTING. Call setChannelProfile and set the channel profile live broadcasting before calling this method.\n      ERR_NOT_INITIALIZED (-7): The SDK is not initialized. Ensure that the IRtcEngine object is Initialized before using this method."
    },
    {
        "id": "api_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.After calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the onRtmpStreamingStateChanged callback on the local client to report the state of adding a local stream to the CDN.\n   \n       \n  Call this method after joining a channel.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "\n      Whether to enable transcoding.  in a CDN live streaming converts the audio and video streams before pushing them to the CDN server. It applies to scenarios where a channel has multiple broadcasters and composite layout is needed\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true, ensure that you call the setLiveTranscoding method before this method.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n                        ERR_INVALID_ARGUMENT(-2): Invalid argument, usually because the URL address is null or the string length is 0.\n                        ERR_NOT_INITIALIZED(-7): You have not initialized the RTC engine when publishing the stream."
    },
    {
        "id": "api_addvideowatermark1",
        "name": "addVideoWatermark[1/2]",
        "description": "Adds a watermark image to the local video.Deprecated:\n  This method is deprecated. Use addVideoWatermark instead.\n       \n   \n   This method adds a PNG watermark image to the local video stream in a live streaming. Once the watermark image is added, all the users in the channel (CDN audience included) and the video capturing device can see and capture it. If you only want to add a watermark to the CDN live streaming, see descriptions in setLiveTranscoding.\n   \n       \n  The URL descriptions are different for the local video and CDN live streaming: In a local video stream, URL refers to the absolute path of the added watermark image file in the local video stream. In a CDN live stream, URL refers to the URL address of the added watermark image in the CDN live streaming.\n  The source file of the watermark image must be in the PNG file format. If the width and height of the PNG file differ from your settings in this method, the PNG file will be cropped to conform to your settings.\n  The Agora SDK supports adding only one watermark image onto a local video or CDN live stream. The newly added watermark image replaces the previous one.",
        "parameters": [
            {
                "watermark": "The watermark image to be added to the local live streaming: RtcImage."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_addvideowatermark2",
        "name": "addVideoWatermark[2/2]",
        "description": "Adds a watermark image to the local video.This method adds a PNG watermark image to the local video in the live streaming. Once the watermark image is added, all the audience in the channel (CDN audience included), and the capturing device can see and capture it. Agora supports adding only one watermark image onto the local video, and the newly watermark image replaces the previous one.\n   The watermark coordinates are dependent on the settings in the setVideoEncoderConfigurationmethod:\n  If the orientation mode of the encoding video (ORIENTATION_MODE) is FIXED_LANDSCAPE, or the landscape mode in ADAPTIVE, the watermark uses the landscape orientation.\n  If the orientation mode of the encoding video (ORIENTATION_MODE) is FIXED_PORTRAIT, or the portrait mode in ADAPTIVE, the watermark uses the portrait orientation.\n  When setting the watermark position, the region must be less than the dimensions set in the setVideoEncoderConfiguration method. Otherwise, the watermark image will be cropped.\n       \n   \n   \n       \n  Ensure that you have called enableVideo before calling this method.\n  If you only want to add a watermark to the CDN live streaming, you can call this method or the setLiveTranscoding method.\n  This method supports adding a watermark image in the PNG file format only. Supported pixel formats of the PNG image are RGBA, RGB, Palette, Gray, and Alpha_gray.\n  If the dimensions of the PNG image differ from your settings in this method, the image will be cropped or zoomed to conform to your settings.\n  If you have enabled the local video preview by calling the startPreview method, you can use the visibleInPreview member to set whether or not the watermark is visible in the preview.\n  If you have enabled the mirror mode for the local video, the watermark on the local video is also mirrored. To avoid mirroring the watermark, Agora recommends that you do not use the mirror and watermark functions for the local video at the same time. You can implement the watermark function in your application layer.",
        "parameters": [
            {
                "watermarkUrl": "The local file path of the watermark image to be added. This method supports adding a watermark image from the local absolute or relative file path."
            },
            {
                "options": "The options of the watermark image to be added. For details, see WatermarkOptions."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingplayoutvolume",
        "name": "adjustAudioMixingPlayoutVolume",
        "description": "Adjusts the volume of audio mixing for local playback.You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume for local playback. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingpublishvolume",
        "name": "adjustAudioMixingPublishVolume",
        "description": "Adjusts the volume of audio mixing for publishing.This method adjusts the volume of audio mixing for publishing (sending to other users).\n   You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value range is [0,100]. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustaudiomixingvolume",
        "name": "adjustAudioMixingVolume",
        "description": "Adjusts the volume during audio mixing.This method adjusts the audio mixing volume on both the local client and remote clients.\n   \n       \n  Call this method after startAudioMixing.\n  Calling this method does not affect the volume of audio effect file playback invoked by the playEffect method.",
        "parameters": [
            {
                "volume": "Audio mixing volume. The value ranges between 0 and 100. The default value is 100, the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustplaybacksignalvolume",
        "name": "adjustPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of all remote users.This method adjusts the playback volume that is the mixed volume of all remote users.\n  Starting from v2.3.2, to mute the local audio, you need to call the adjustPlaybackSignalVolume and adjustAudioMixingPlayoutVolume methods at the same time, and set volume to 0.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_adjustrecordingsignalvolume",
        "name": "adjustRecordingSignalVolume",
        "description": "Adjusts the capturing signal volume.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "\n      The volume of the signal captured by the microphone. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.Since\n  v3.0.0\n       \n   \n   You can call this method as many times as necessary to adjust the playback volume of different remote users, or to repeatedly adjust the playback volume of the same remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "volume": "\n      The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_clearvideowatermarks",
        "name": "clearVideoWatermarks",
        "description": "Removes the watermark image from the video stream.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_complain",
        "name": "complain",
        "description": "Allows a user to complain about the call quality after a call ends.This method allows users to complain about the quality of the call. Call this method after the user leaves the channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT).\n  -3 (ERR_NOT_READY)。"
    },
    {
        "id": "api_consumerawvideoframe",
        "name": "consumeRawVideoFrame",
        "description": "Receives the raw video frame.Ensure that the video frame type specified in this method is the same as that in the getBufferType callback.",
        "parameters": [
            {
                "buffer": "The video buffer."
            },
            {
                "frameType": "The video frame type. See VIDEO_PIXEL_FORMAT."
            },
            {
                "width": "The width (px) of the video frame."
            },
            {
                "height": "The height (px) of the video frame."
            },
            {
                "rotation": "The angle at which the video frame is rotated clockwise. If you set the rotation angle, the SDK rotates the video frame after receiving it. You can set the rotation angle as `0`, `90`, `180`, and `270`."
            },
            {
                "timestamp": "The Unix timestamp (ms) of the video frame. You must set a timestamp for each video frame."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_createagorartcengine",
        "name": "createAgoraRtcEngine",
        "description": "Create the IRtcEngine object and return the pointer.Currently, the Agora RTC Native SDK supports creating only one IRtcEngine object for an app.",
        "parameters": [],
        "returns": "IRtcEngine object."
    },
    {
        "id": "api_createChannel",
        "name": "createChannel",
        "description": "Creates and gets an IChannel object.You can call this method multiple times to create multiple IChannel objects, and then call the IChannel methods in of each joinChannel to join multiple channels at the same time.\n   After joining multiple channels, you can simultaneously subscribe to the the audio and video streams of all the channels, but publish a stream in only one channel at one time.",
        "parameters": [
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  \n \n     The parameter does not have a default value. You must set it.\n     Do not set this parameter as the empty string \"\". Otherwise, the SDK returns ERR_REFUSED(5).\n \n      \n  "
            }
        ],
        "returns": "A pointer to the IChannel instance, if the method call succeeds.\n       An empty pointer NULL, if the method call fails."
    },
    {
        "id": "api_createdatastream1",
        "name": "createDataStream[1/2]",
        "description": "Creates a data stream.Deprecated:\n  This method is deprecated as of v2.4.0. Please use createDataStream[2/2] instead.\n       \n   \n   Each user can create up to five data streams during the lifecycle of RtcEngine.\n   \n       \n  Call this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as false.",
        "parameters": [
            {
                "reliable": "Whether or not the data stream is reliable:\n      true: The recipients receive the data from the sender within five seconds. If the recipient does not receive the data within five seconds, the SDK triggers the onStreamMessageError callback and returns an error code.\n      false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is reported for any delay or missing data stream.\n  "
            },
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            }
        ],
        "returns": "0: The data stream is successfully created.\n       < 0: Fails to create the data stream. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_createdatastream2",
        "name": "createDataStream[2/2]",
        "description": "Creates a data stream.Since\n  v3.3.0. Used to replace createDataStream[1/2].\n       \n   \n   Creates a data stream. Each user can create up to five data streams in a single channel.\n   Compared with createDataStream[1/2], this method does not support data reliability. If a data packet is not received five seconds after it was sent, the SDK directly discards the data.",
        "parameters": [
            {
                "config": "The configurations for the data stream. See DataStreamConfig."
            }
        ],
        "returns": "ID of the created data stream, if the method call succeeds.\n       < 0: Failure. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_delegate",
        "name": "delegate",
        "description": "Sets and gets IRtcEngineEventHandler.The Agora Native SDK uses the specified delegates to notify the app of runtime events. All methods defined in the delegate are optional.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_disableaudio",
        "name": "disableAudio",
        "description": "Disables the audio module.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_disablelastmiletest",
        "name": "disableLastmileTest",
        "description": "Disables the network connection quality test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_disablevideo",
        "name": "disableVideo",
        "description": "Disables the video module.This method can be called before joining a channel or during a call to disable the video module. If this method is called before joining a channel, the call starts in audio mode. Call the enableVideo method to enable the video module.A successful call of this method triggers the onUserEnableVideo(false) callback on the remote client.\n   \n       This method affects the internal engine and can be called after leaveChannel.\n       This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableaudio",
        "name": "enableAudio",
        "description": "Enables the audio module.The audio mode is enabled by default.\n   \n       This method enables the internal engine and can be called anytime after initialization. It is still valid after leaveChannel.\n       This method enables the audio module and takes some time to take effect. Agora recommends using the following API methods to control the audio module separately:\n  enableLocalAudio: Whether to enable the microphone to create the local audio stream.\n  muteLocalAudioStream: Whether to publish the local audio stream.\n  muteRemoteAudioStream: Whether to subscribe and play the remote audio stream.\n  muteAllRemoteAudioStreams: Whether to subscribe to and play all remote audio streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableaudiovolumeindication",
        "name": "enableAudioVolumeIndication",
        "description": "Enables the reporting of users' volume indication.This method enables the SDK to regularly report the volume information of the local user who sends a stream and remote users (up to three) whose instantaneous volumes are the highest to the app. Once you call this method and users send streams in the channel, the SDK triggers the onAudioVolumeIndication callback at the time interval set in this method.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "interval": "Sets the time interval between two consecutive volume indications:\n ≤ 0: Disables the volume indication.\n > 0: Time interval (ms) between two consecutive volume indications. We recommend a setting greater than 200 ms. Do not set this parameter to less than 10 milliseconds, otherwise the onAudioVolumeIndication callback will not be triggered.\n      \n  "
            },
            {
                "smooth": "The smoothing factor sets the sensitivity of the audio volume indicator. The value ranges between 0 and 10. The recommended value is 3. The greater the value, the more sensitive the indicator."
            },
            {
                "report_vad": "\n      \n true: Enable the voice activity detection of the local user. Once it is enabled, the vad parameter of the onAudioVolumeIndication callback reports the voice activity status of the local user.\n false(Default) Disable the voice activity detection of the local user. Once it is disabled, the vad parameter of the onAudioVolumeIndication callback does not report the voice activity status of the local user, except for the scenario where the engine automatically detects the voice activity of the local user.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enabledeeplearningdenoise",
        "name": "enableDeepLearningDenoise",
        "description": "Enables or disables deep-learning noise reduction.Since\n  v3.3.0\n       \n   \n   The SDK enables traditional noise reduction mode by default to reduce most of the stationary background noise. If you need to reduce most of the non-stationary background noise, Agora recommends enabling deep-learning noise reduction as follows:\n       Integrate the dynamical library under the libs folder to your project: libagora_ai_denoise_extension.dll\n       2. Call enableDeepLearningDenoise(true).\n   \n   Deep-learning noise reduction requires high-performance devices. The deep-learning noise reduction is enabled only when the device supports this function. For example, the following devices and later models are known to support deep-learning noise reduction:\n       iPhone 6S\n       MacBook Pro 2015\n       iPad Pro (5nd generation)\n       iPad mini (5th generation)\n       iPad Air (3rd generation)\n   \n   After successfully enabling deep-learning noise reduction, if the SDK detects that the device performance is not sufficient, it automatically disables deep-learning noise reduction and enables traditional noise reduction.\n   If you call enableDeepLearningDenoise(true) or the SDK automatically disables deep-learning noise reduction in the channel, when you need to re-enable deep-learning noise reduction, you need to call leaveChannel first, and then call enableDeepLearningDenoise(true).\n   \n       This method dynamically loads the library, so Agora recommends calling this method before joining a channel.\n       This method works best with the human voice. Agora does not recommend using this method for audio containing music.",
        "parameters": [
            {
                "enabled": "Enables or disables deep-learning noise reduction.\n      truetrue: (Default) Enables deep-learning noise reduction.\n      false: Disables deep-learning noise reduction.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -157 (ERR_MODULE_NOT_FOUND): The dynamic library for enabling deep-learning noise reduction is not integrated."
    },
    {
        "id": "api_enabledualstreammode",
        "name": "enableDualStreamMode",
        "description": "Enables/Disables dual-stream mode.This method enables or disables dual streams. If a remote user enables dual-stream mode, use this method to subscribe to the high-quality or low-quality video stream. The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "\n      \n true: Enables dual-stream mode.\n false: Disables dual-stream mode.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.Since\n                         v3.1.0\n                    \n               \n               In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "\n                              Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption schemas. See EncryptionConfig."
            }
        ],
        "returns": "0: Success.\n                    \n                         < 0: Failure.\n                              -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the parameter with a valid value.\n                              -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK fails to load the external encryption library. Check the enumeration or reload the external encryption library.\n                              -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_enablefacedetection",
        "name": "enableFaceDetection",
        "description": "Enables/Disables face detection for the local user.Since\n  v3.0.1\n       \n   \n   You can call this method either before or after joining a channel.\n   Once face detection is enabled, the SDK triggers the onFacePositionChanged callback to report the face information of the local user:\n       The width and height of the local video.\n       The position of the human face in the local video.\n       The distance between the human face and the screen.\n   \n   \n   This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [
            {
                "enable": "Whether to enable face detection:\n      true: Enable face detection.\n      false: (Default) Disable face detection.\n  \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableInearmonitoring",
        "name": "enableInEarMonitoring",
        "description": "Enables in-ear monitoring.This method is for Android and iOS only.\n      Users must use wired earphones to hear their own voices.\n      You can call this method either before or after joining a channel.\n  \n       \n       This method enables or disables in-ear monitoring.",
        "parameters": [
            {
                "enabled": "Enables in-ear monitoring.\n true: Enables in-ear monitoring.\n false: (Default) Disables in-ear monitoring.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablelastmiletest",
        "name": "enableLastmileTest",
        "description": "Enables the network connection quality test.This method tests the quality of the users' network connections. By default, this function is disabled. This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    Before an audience switches to a host, call this method to check the uplink network quality.\n                \n            \n            Regardless of the scenario, enabling this method consumes extra network traffic and affects the call quality. After receiving the onLastmileQuality callback, call disableLastmileTest to stop the test, and then join the channel or switch to the host.\n            \n                \n                    Do not use this method together with startLastmileProbeTest.\n                    Do not call any other methods before receiving the onLastmileQuality callback. Otherwise, the callback may be interrupted by other methods, and hence may not be triggered.\n                    A host should not call this method after joining a channel (when in a call).\n                    If you call this method to test the last mile network quality, the SDK consumes the bandwidth of a video stream, whose bitrate corresponds to the bitrate you set in setVideoEncoderConfiguration. After joining a channel, whether you have called disableLastmileTest or not, the SDK automatically stops consuming the bandwidth.",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_enablelocalaudio",
        "name": "enableLocalAudio",
        "description": "Disables/Re-enables the local audio function.The audio function is enabled by default. This method disables or re-enables the local audio function, that is, to stop or restart local audio capturing.\n   This method does not affect receiving or playing the remote audio streams, and enableLocalAudio(false) is applicable to scenarios where the user wants to receive remote audio streams without sending any audio stream to other users in the channel.\n   Once the local audio function is disabled or re-enabled, the SDK triggers the onLocalAudioStateChanged callback, which reports LOCAL_AUDIO_STREAM_STATE_STOPPED(0) or LOCAL_AUDIO_STREAM_STATE_RECORDING(1).\n       This method is different from the muteLocalAudioStream method:\n                            enableLocalVideo: Disables/Re-enables the local audio capturing and processing. If you disable or re-enable local audio capturing using the enableLocalAudio method, the local user may hear a pause in the remote audio playback.\n                            muteLocalAudioStream: Sends/Stops sending the local audio streams.\n                        \n                           \n       You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "\n      true: (Default) Re-enable the local audio function, that is, to start the local audio capturing device (for example, the microphone).\n      false: Disable the local audio function, that is, to stop local audio capturing.\n       \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablelocalvideo",
        "name": "enableLocalVideo",
        "description": "Enables/Disables the local video capture.This method disables or re-enables the local video capturer, and does not affect receiving the remote video stream.\n   After callingenableVideo , the local video capturer is enabled by default. You can call enableLocalVideo(false) to disable the local video capturer. If you want to re-enable it, call enableLocalVideo(true).\n   After the local video capturer is successfully disabled or re-enabled, the SDK triggers the onUserEnableLocalVideo callback on the remote client.\n   \n       \n  You can call this method either before or after joining a channel.\n  This method enables the internal engine and is valid after leaveChannel.",
        "parameters": [
            {
                "enabled": "\n      Whether to enable the local video capture.\n      \n true: (Default) Enable the local video capture.\n false: Disable the local video capture. Once the local video is disabled, the remote users can no longer receive the video stream of this user, while this user can still receive the video streams of the other remote users. When set to false, this method does not require a local camera.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enableloopbackrecording",
        "name": "enableLoopbackRecording",
        "description": "Enables loopback audio capturing.If you enable loopback audio capturing, the output of the sound card is mixed into the audio stream sent to the other end.\n   \n       \n  \n      macOS does not support loopback capturing of the default sound card. If you need to use this method, please use a virtual sound card and pass its name to the deviceName parameter. Agora has tested and recommends using soundflower.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "enabled": "Whether to enableloopback capturing.\n true: Enable loopback audio capturing.\n false: (Default) Disable loopback capturing.\n      "
            },
            {
                "deviceName": "The device name of the sound card. The default value is NULL (the default sound card). If the user uses a virtual sound card, such as \"Soundflower\", the virtual sound card name \"Soundflower\" can be passed to this parameter, and the SDK finds the corresponding virtual sound card device and starts collecting."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_enablesoundpositionindication",
        "name": "enableSoundPositionIndication",
        "description": "Enables/Disables stereo panning for remote users.Ensure that you call this method before joining a channel to enable stereo panning for remote users so that the local user can track the position of a remote user by calling setRemoteVoicePosition.",
        "parameters": [
            {
                "enabled": "Whether to enable stereo panning for remote users:\n true: Enable stereo panning.\n false: Disable stereo panning.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablevideo",
        "name": "enableVideo",
        "description": "Enable the video module.Call this method either before joining a channel or during a call. If this method is called before joining a channel, the call starts in the video mode. If this method is called during a call, the call switches to the video mode. Call the disableVideo method to disable the video mode.A successful call of this method triggers the onRemoteVideoStateChanged callback on the remote client.\n                \n                    This method enables the internal engine and is valid after leaveChannel.\n                    This method resets the internal engine and takes some time to take effect. Agora recommends using the following API methods to control the video engine modules separately:\n                            enableLocalVideo: Whether to enable the camera to create the local video stream.\n                            muteLocalVideoStream: Whether to publish the local video stream.\n                            muteRemoteVideoStream: Whether to subscribe to and play the remote video stream.\n                            muteAllRemoteVideoStreams: Whether to subscribe to and play all remote video streams.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enablewebsdkinteroperability",
        "name": "enableWebSdkInteroperability",
        "description": "Enables interoperability with the Agora Web SDK (applicable only in the live streaming scenarios).Deprecated:\n  As of v3.0.0, the Native SDK automatically enables interoperability with the Web SDK, so you no longer need to call this method.\n       \n   \n   This method enables or disables interoperability with the Agora Web SDK. If the channel has Web SDK users, ensure that you call this method, or the video of the Native user will be a black screen for the Web user.\n   This method is only applicable in live streaming scenarios, and interoperability is enabled by default in communication scenarios.",
        "parameters": [
            {
                "enabled": "Whether to enable interoperability with the Agora Web SDK.\n      true: Enable interoperability.\n      false: (Default) Disable interoperability.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_enumerateplaybackdevices",
        "name": "enumeratePlaybackDevices",
        "description": "Enumerates the audio playback devices.This method returns an IAudioDeviceCollection object that includes all audio\n                playback devices in the system. With the IAudioDeviceCollection\n                object, the application can enumerate the audio playback devices. The application\n                must call the release method to release the\n                returned object after using it.",
        "parameters": [],
        "returns": "Success: Returns an IAudioDeviceCollection object that includes all audio playback devices in the system.\n       Failure: NULL."
    },
    {
        "id": "api_enumeraterecordingdevices",
        "name": "enumerateRecordingDevices",
        "description": "Enumerates the audio capture devices.This method returns an IAudioDeviceCollection object that includes all audio capture devices in the system. With the IAudioDeviceCollection object, the application can enumerate the audio capture devices. The application must call the release method to release the returned object after using it.",
        "parameters": [],
        "returns": "Success: An IAudioDeviceCollection object including all audio capture devices.\n       Failure: NULL."
    },
    {
        "id": "api_enumeratevideodevices",
        "name": "enumerateVideoDevices",
        "description": "Enumerates the video devices.This method returns an IVideoDeviceCollection object including all video devices in the system. With the IVideoDeviceCollection object, the application can enumerate video devices. The application must call the release method to release the returned object after using it.",
        "parameters": [],
        "returns": "Success: An IVideoDeviceCollection object including all video devices in the system.\n       Failure: NULL."
    },
    {
        "id": "api_getapplicationvolume",
        "name": "getApplicationVolume",
        "description": "Retrieves the volume of the application.",
        "parameters": [
            {
                "volume": "The application volume. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingcurrentposition",
        "name": "getAudioMixingCurrentPosition",
        "description": "Retrieves the playback position (ms) of the music file.Retrieves the playback position (ms) of the audio.\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The current playback position of the audio mixing, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingduration",
        "name": "getAudioMixingDuration",
        "description": "Retrieves the duration (ms) of the music file.Retrieves the total duration (ms) of the audio.\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing duration, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingplayoutvolume",
        "name": "getAudioMixingPlayoutVolume",
        "description": "Retrieves the audio mixing volume for local playback.This method helps troubleshoot audio volume related issues.\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getaudiomixingpublishvolume",
        "name": "getAudioMixingPublishVolume",
        "description": "Retrieves the audio mixing volume for publishing.This method helps troubleshoot audio volume related issues.\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [],
        "returns": "≥ 0: The audio mixing volume, if this method call succeeds. The value range is [0,100].\n       < 0: Failure."
    },
    {
        "id": "api_getbuffertype",
        "name": "getBufferType",
        "description": "Gets the video frame type.Before you initialize the custom video source, the SDK triggers this callback to query the video frame type. You must specify the video frame type in the return value and then pass it to the SDK.\n   Ensure that the video frame type that you specify in this callback is the same as that in the consumeRawVideoFrame method.",
        "parameters": [],
        "returns": "VIDEO_PIXEL_FORMAT"
    },
    {
        "id": "api_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.When a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID.\n   \n       0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getcameramaxzoomfactor",
        "name": "getCameraMaxZoomFactor",
        "description": "Gets the maximum zoom ratio supported by the camera.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "The maximum zoom factor."
    },
    {
        "id": "api_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.Since\n                    v2.3.2\n                \n            \n            You can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": "The current connection state of the SDK. See CONNECTION_STATE_TYPE."
    },
    {
        "id": "api_geteffectsvolume",
        "name": "getEffectsVolume",
        "description": "Retrieves the volume of the audio effects.The volume is an integer ranging from 0 to 100. The default value is 100, the original volume.\n   Call this method after playEffect.",
        "parameters": [],
        "returns": "Volume of the audio effects, if this method call succeeds.\n       < 0: Failure."
    },
    {
        "id": "api_geterrordescription",
        "name": "getErrorDescription",
        "description": "Gets the warning or error description.",
        "parameters": [
            {
                "code": "The error code or warning code reported by the SDK."
            }
        ],
        "returns": "The specific error or warning description. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_getmaxmetadatasize",
        "name": "getMaxMetadataSize",
        "description": "Occurs when the SDK requests the maximum size of Metadata.The SDK triggers this callback after you successfully call the registerMediaMetadataObserver method. You need to specify the maximum size of the Metadata in the return value of this callback.",
        "parameters": [],
        "returns": "The maximum size of the buffer of the Metadata that you want to use. The highest value is 1024 bytes. Ensure that you set the return value."
    },
    {
        "id": "api_getmirrorapplied",
        "name": "getMirrorApplied",
        "description": "Occurs each time the SDK receives a video frame and prompts you whether or not to mirror the captured video.If the video data you want to obtain is a mirror image of the original video, you need to register this callback when calling registerVideoFrameObserver. After you successfully register the video frame observer, the SDK triggers this callback each time it receives a video frame. You need to set whether or not to mirror the video frame in the return value of this callback.\n   This callback applies to RGBA video data only.",
        "parameters": [],
        "returns": "Sets whether or not to mirror the captured video:\n  true: Mirror.\n  false: (Default) Do not mirror."
    },
    {
        "id": "api_getnativehandle",
        "name": "getNativeHandle",
        "description": "Gets the C++ handle of the Native SDK.This method is used to retrieve the native C++ handle of the SDK engine used in special scenarios, such as registering the audio and video frame observer.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_getobservedframeposition",
        "name": "getObservedFramePosition",
        "description": "Sets the frame position for the video observer.Since\n      v3.0.1\n  \n       \n   After successfully registering the video data observer, the SDK uses this callback to determine whether to trigger onCaptureVideoFrame, onRenderVideoFrame and onPreEncodeVideoFrame callback at each specific video frame processing position, so that you can observe the locally collected video data, the video data sent by the remote end, and the video data before encoding. You can set one or more positions you need to observe by modifying the return value of getObservedFramePosition according to your scenario:POSITION_POST_CAPTURER(1 << 0) : The position after capturing the video data, which corresponds to theonCaptureVideoFrame callback.\n       POSITION_PRE_RENDERER(1 << 1): The position before receiving the remote video data, which corresponds to the onRenderVideoFrame callback.\n       POSITION_PRE_ENCODER(1 << 2): The position before encoding the video data, which corresponds to the onPreEncodeVideoFrame callback.\n   \n   \n       \n  Use '|' (the OR operator) to observe multiple frame positions.\n  This callback observesPOSITION_POST_CAPTURER (1 << 0) andPOSITION_PRE_RENDERER (1 << 1) by default.\n  To conserve the system consumption, you can reduce the number of frame positions that you want to observe.",
        "parameters": [],
        "returns": "A bit mask that controls the frame position of the video observer: VIDEO_OBSERVER_POSITION."
    },
    {
        "id": "api_getplaybackdevice",
        "name": "getPlaybackDevice",
        "description": "Retrieves the audio playback device associated with the device ID.",
        "parameters": [
            {
                "deviceId": "The device ID of the audio playback device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getplaybackdeviceinfo",
        "name": "getPlaybackDeviceInfo",
        "description": "Retrieves the audio playback device information associated with the device ID and device name.",
        "parameters": [
            {
                "deviceId": "The device ID of the playback device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            },
            {
                "deviceName": "The device name of the playback device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getplaybackdevicemute",
        "name": "getPlaybackDeviceMute",
        "description": "Retrieves the mute status of the audio playback device.",
        "parameters": [
            {
                "mute": "Pointer to whether the audio playback device is muted/unmuted.\ntrue: The audio playback device is muted.\nfalse: The audio playback device is unmuted.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getplaybackdevicevolume",
        "name": "getPlaybackDeviceVolume",
        "description": "Retrieves the volume of the audio playback device.",
        "parameters": [
            {
                "volume": "The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getrecordingdevice",
        "name": "getRecordingDevice",
        "description": "Retrieves the audio capture device associated with the device ID.",
        "parameters": [
            {
                "deviceId": "The device ID of the capture device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getrecordingdeviceinfo",
        "name": "getRecordingDeviceInfo",
        "description": "Retrieves the audio capture device information associated with the device ID and device name.",
        "parameters": [
            {
                "deviceId": "The device ID of the audio capture device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            },
            {
                "deviceName": "The name of the audio capture device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getrecordingdevicemute",
        "name": "getRecordingDeviceMute",
        "description": "Retrieves the microphone's mute status.",
        "parameters": [
            {
                "mute": "Pointer to whether the microphone is muted/unmuted.\n      true: The microphone is muted.\n      false: The microphone is unmuted.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getrecordingdevicevolume",
        "name": "getRecordingDeviceVolume",
        "description": "Retrieves the volume of the microphone.",
        "parameters": [
            {
                "volume": "The volume of the microphone. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getrotationapplied",
        "name": "getRotationApplied",
        "description": "Occurs each time the SDK receives a video frame and prompts you whether or not to rotate the captured video.If you want to rotate the captured video according to the rotation member in the VideoFrame class, register this callback by calling registerVideoFrameObserver. After you successfully register the video frame observer, the SDK triggers this callback each time it receives a video frame. You need to set whether or not to rotate the video frame in the return value of this callback.\n   This callback applies to RGBA video data only.",
        "parameters": [],
        "returns": "Sets whether or not to rotate the captured video:\n  true: Rotate.\n  false: (Default) Do not rotate."
    },
    {
        "id": "api_getsmoothrenderingenabled",
        "name": "getSmoothRenderingEnabled",
        "description": "Sets whether to output the acquired video frame smoothly.Since\n  v3.0.0\n       \n   \n   If you want the video frames acquired from onRenderVideoFrame to be more evenly spaced, you can register the callback by calling registerVideoFrameObserver and set its return value as true.\n   \n       \n  Register this callback before joining a channel.\n  This callback applies to scenarios where the acquired video frame is self-rendered after being processed, not to scenarios where the video frame is sent back to the SDK after being processed.",
        "parameters": [],
        "returns": "Set whether or not to smooth the video frames:\n  true: Smooth the video frame.\n  false: (Default) Do not smooth."
    },
    {
        "id": "api_getuserinfobyuid",
        "name": "getUserInfoByUid",
        "description": "Gets the user information by passing in the user ID.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object (`userInfo`), and triggers the onUserInfoUpdated callback on the local client. \n   After receiving the callback, you can call this method to get the user account of the remote user from the UserInfo object by passing in the user ID.",
        "parameters": [
            {
                "uid": "The user ID. It is mandatory."
            },
            {
                "userInfo": "Identifiers of a user. See UserInfo for details."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getuserinfobyuseraccount",
        "name": "getUserInfoByUserAccount",
        "description": "Gets the user information by passing in the user account.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object, and triggers the onUserInfoUpdated callback on the local client.\n   After receiving the callback, you can call this method to get the user ID of the remote user from the UserInfo object by passing in the user account.",
        "parameters": [
            {
                "userAccount": "The user account. It is mandatory."
            },
            {
                "userInfo": "Identifiers of a user. See UserInfo for details."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_getversion",
        "name": "getVersion",
        "description": "Gets the SDK version.",
        "parameters": [],
        "returns": "The SDK version number. The format is a string, such as 3.3.0."
    },
    {
        "id": "api_getvideocapturetype",
        "name": "getVideoCaptureType",
        "description": "Gets the capture type of the custom video source.Before you initialize the custom video source, the SDK triggers this callback to query the capture type of the video source. You must specify the capture type in the return value and then pass it to the SDK. The SDK enables the corresponding video processing algorithm according to the capture type after receiving the video frame.",
        "parameters": [],
        "returns": "VIDEO_CAPTURE_TYPE"
    },
    {
        "id": "api_getvideocontenthint",
        "name": "getVideoContentHint",
        "description": "Gets the content hint for the custom video source.If you specify the custom video source as a screen-sharing video, the SDK triggers this callback to query the content hint of the video source before you initialize the video source. You must specify the content hint in the return value and then pass it to the SDK. The SDK enables the corresponding video processing algorithm according to the content hint after receiving the video frame.",
        "parameters": [],
        "returns": "VideoContentHint"
    },
    {
        "id": "api_getvideoformatpreference",
        "name": "getVideoFormatPreference",
        "description": "Occurs each time the SDK receives a video frame and prompts you to set the video format.If you want to receive other video formats than YUV420, register this callback when calling registerVideoFrameObserver. After you successfully register the video frame observer, the SDK triggers this callback each time it receives a video frame. You need to set your preferred video data in the return value of this callback.",
        "parameters": [],
        "returns": "Sets the video format VIDEO_FRAME_TYPE:\n  FRAME_TYPE_YUV420 (0): (Default) YUV420.\n  FRAME_TYPE_RGBA (2): RGBA."
    },
    {
        "id": "api_iaudiodevicecollection_getcount",
        "name": "getCount",
        "description": "Gets the total number of audio playback or audio capturing devices.If you call enumeratePlaybackDevices before this method, the SDK returns the number of audio playback devices. If you call enumerateRecordingDevices before this method, the SDK returns the number of audio capturing devices.",
        "parameters": [],
        "returns": "The number of audio playback or audio capturing devices."
    },
    {
        "id": "api_iaudiodevicecollection_getdevice",
        "name": "getDevice",
        "description": "Gets the information of a specified audio device.",
        "parameters": [
            {
                "index": "An input parameter. The index of the device."
            },
            {
                "deviceName": "An output parameter. The device name. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            },
            {
                "deviceId": "An output parameter. The device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_iaudiodevicecollection_release",
        "name": "release",
        "description": "Releases all IAudioDeviceCollection resources.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_iaudiodevicecollection_setdevice",
        "name": "setDevice",
        "description": "Specifies an audio device.",
        "parameters": [
            {
                "deviceId": "The device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_iaudiodevicemanager_release",
        "name": "release",
        "description": "Releases all the resources occupied by the IAudioDeviceManager object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_iaudioframeobserver_ismultiplechannelframewanted",
        "name": "isMultipleChannelFrameWanted",
        "description": "Determines whether to receive audio data from multiple channels.Since\n      v3.0.1\n  \n       \n   After you register the audio frame observer, the SDK triggers this callback every time it captures an audio frame.\n   In the multi-channel scenario, if you want to get audio data from multiple channels, set the return value of this callback as true. After that, the SDK triggers the onPlaybackAudioFrameBeforeMixingEx callback to send you the before-mixing audio frame from various channels. You can also get the channel ID of each audio frame.\n   \n       \n  Once you set the return value of the callback as true, the SDK triggers only the onPlaybackAudioFrameBeforeMixingEx callback to send the audio data. onPlaybackAudioFrameBeforeMixing will not be triggered. In the multi-channel scenario, Agora recommends setting the return value as true.\n  If you set the return value of this callback as false, the SDK triggers only the onPlaybackAudioFrameBeforeMixing callback to send the audio data.",
        "parameters": [],
        "returns": "true: Receive audio data from multiple channels.\n       false: Do not receive audio data from multiple channels."
    },
    {
        "id": "api_ichannel_addinjectstreamurl",
        "name": "addInjectStreamUrl",
        "description": "Injects an online media stream to a live streaming channel.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .\n   \n  \n      Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n      This method applies to the Native SDK v2.4.1 and later.\n      This method takes effect only when you are a host in a LIVE_BROADCASTING channel.\n      Only one online media stream can be injected into the same channel at the same time.\n      Call this method after joining a channel.\n  \n       \n   This method injects the currently playing audio and video as audio and video sources into the ongoing live broadcast. This applies to scenarios where all users in the channel can watch a live show and interact with each other. After calling this method, the SDK triggers the onStreamInjectedStatus callback on the local client to report the state of injecting the online media stream; after successfully injecting the media stream, the stream joins the channel, and all users in the channel receive the onUserJoined callback, where uid is 666.",
        "parameters": [
            {
                "url": "\n      The URL address to be added to the ongoing streaming. Valid protocols are RTMP, HLS, and HTTP-FLV.\n     Supported audio codec type: AAC.\n     Supported video codec type: H264 (AVC).\n \n      \n  "
            },
            {
                "config": "The configuration information for the added voice or video stream: InjectStreamConfig."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n      ERR_INVALID_ARGUMENT (-2): The injected URL does not exist. Call this method again to inject the stream and ensure that the URL is valid.\n      ERR_NOT_READY (-3): The user is not in the channel.\n      #ERR_NOT_SUPPORTED (-4): The channel profile is not LIVE_BROADCASTING. Call setChannelProfile and set the channel profile live broadcasting before calling this method.\n      ERR_NOT_INITIALIZED (-7): The SDK is not initialized. Ensure that the IRtcEngine object is Initialized before using this method."
    },
    {
        "id": "api_ichannel_addpublishstreamurl",
        "name": "addPublishStreamUrl",
        "description": "Publishes the local stream to a specified CDN live streaming URL.Call this method after joining a channel.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  This method takes effect only when you are a host in live interactive streaming.\n  This method adds only one stream CDN streaming URL each time it is called. To push multiple URLs, call this method multiple times.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n        After calling this method, you can push media streams in RTMP or RTMPS protocol to the CDN. The SDK triggers the onRtmpStreamingStateChanged callback on the local client to report the state of adding a local stream to the CDN.",
        "parameters": [
            {
                "url": "The CDN streaming URL in the RTMP or RTMPS format. The maximum length of this parameter is 1024 bytes. The URL address must not contain special characters, such as Chinese language characters."
            },
            {
                "transcodingEnabled": "Whether to enable transcoding.  in a CDN live streaming converts the audio and video streams before pushing them to the CDN server. It applies to scenarios where a channel has multiple broadcasters and composite layout is needed\n                                true: Enable transcoding.\n                                false: Disable transcoding.\n                            \n      If you set this parameter as true, ensure that you call the setLiveTranscoding method before this method.\n       "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n                        ERR_INVALID_ARGUMENT(-2): Invalid argument, usually because the URL address is null or the string length is 0.\n                        ERR_NOT_INITIALIZED(-7): You have not initialized the RTC engine when publishing the stream."
    },
    {
        "id": "api_ichannel_adjustuserplaybacksignalvolume",
        "name": "adjustUserPlaybackSignalVolume",
        "description": "Adjusts the playback signal volume of a specified remote user.Since\n  v3.0.0\n       \n   \n   You can call this method as many times as necessary to adjust the playback volume of different remote users, or to repeatedly adjust the playback volume of the same remote user.\n   \n       \n  Call this method after joining a channel.\n  The playback volume here refers to the mixed volume of a specified remote user.",
        "parameters": [
            {
                "volume": "\n      The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume.\n  "
            },
            {
                "userId": "The ID of the remote user."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_channelId",
        "name": "channelId",
        "description": "Gets the current channel ID.",
        "parameters": [],
        "returns": "The current channel ID, if the method call succeeds.\n       The empty string \"\", if the method call fails."
    },
    {
        "id": "api_ichannel_createdatastream1",
        "name": "createDataStream[1/2]",
        "description": "Creates a data stream.Call this method after joining a channel.\n  Agora does not support setting reliable as true and ordered as false.\n       \n   \n        Each user can create up to five data streams during the lifecycle of RtcEngine.\n   \n       \n  Deprecated:\n  This method is deprecated as of v2.4.0. Please use createDataStream[2/2] instead.",
        "parameters": [
            {
                "ordered": "Whether or not the recipients receive the data stream in the sent order:\n      true: The recipients receive the data in the sent order.\n      false: The recipients do not receive the data in the sent order.\n  "
            },
            {
                "reliable": "Whether or not the data stream is reliable:\n      true: The recipients receive the data from the sender within five seconds. If the recipient does not receive the data within five seconds, the SDK triggers the onStreamMessageError callback and returns an error code.\n      false: There is no guarantee that the recipients receive the data stream within five seconds and no error message is reported for any delay or missing data stream.\n  "
            }
        ],
        "returns": "Returns the stream ID, if the method call is successful.\n       0: The data stream is successfully created.\n       < 0: Fails to create the data stream. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_ichannel_createdatastream2",
        "name": "createDataStream[2/2]",
        "description": "Creates a data stream.Compared with createDataStream[1/2], this method does not support data reliability. If a data packet is not received five seconds after it was sent, the SDK directly discards the data.\n        Creates a data stream. Each user can create up to five data streams in a single channel.\n   \n       \n  Since\n  v3.3.0. Used to replace createDataStream[1/2].",
        "parameters": [
            {
                "streamId": "Output parameter. Pointer to the ID of the created data stream."
            },
            {
                "config": "The configurations for the data stream. See DataStreamConfig."
            }
        ],
        "returns": "0: The data stream is successfully created.\n       ID of the created data stream, if the method call succeeds.\n       < 0: Failure. You can refer to Error Codes and Warning Codes for troubleshooting."
    },
    {
        "id": "api_ichannel_enableencryption",
        "name": "enableEncryption",
        "description": "Enables/Disables the built-in encryption.Since\n                         v3.1.0\n                    \n               \n               In scenarios requiring high security, Agora recommends calling this method to enable the built-in encryption before joining a channel.\n               All users in the same channel must use the same encryption mode and encryption key. After the user leaves the channel, the SDK automatically disables the built-in encryption. To enable the built-in encryption, call this method before the user joins the channel again.\n               If you enable the built-in encryption, you cannot use the RTMP or RTMPS streaming function.",
        "parameters": [
            {
                "enabled": "\n                              Whether to enable built-in encryption:\n                                        true: Enable the built-in encryption.\n                                        false: Disable the built-in encryption.\n                                   \n                              \n                         "
            },
            {
                "config": "Configurations of built-in encryption schemas. See EncryptionConfig."
            }
        ],
        "returns": "0: Success.\n                    \n                         < 0: Failure.\n                              -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. Set the parameter with a valid value.\n                              -4(ERR_NOT_SUPPORTED): The encryption mode is incorrect or the SDK fails to load the external encryption library. Check the enumeration or reload the external encryption library.\n                              -7(ERR_NOT_INITIALIZED): The SDK is not initialized. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_ichannel_getcallid",
        "name": "getCallId",
        "description": "Retrieves the call ID.When a user joins a channel on a client, a callId is generated to identify the call from the client. Some methods, such as rate and complain, must be called after the call ends to submit feedback to the SDK. These methods require the callId parameter.\n   Call this method after joining a channel.",
        "parameters": [],
        "returns": "The current call ID.\n   \n       0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_getconnectionstate",
        "name": "getConnectionState",
        "description": "Gets the current connection state of the SDK.Since\n                    v2.3.2\n                \n            \n            You can call this method either before or after joining a channel.",
        "parameters": [],
        "returns": "The current connection state of the SDK. See CONNECTION_STATE_TYPE."
    },
    {
        "id": "api_ichannel_joinchannel",
        "name": "joinChannel",
        "description": "Joins the channel with a user ID.This method differs from the joinChannel method in the IRtcEngine class in the following aspects:\n   \n       \n  \n  \n  \n      \n joinChannel\n joinChannel\n      \n      \n Does not contain the channelId parameter. Because channelId is specified when creating the IChannel object.\n You need to fill in the channelId that can identify the channel.\n      \n      \n Users can join multiple channels simultaneously by creating multiple IChannel objects and calling the joinChannel methods of each object.\n Users can join only one channel.\n      \n      \n By default, the SDK does not publish any stream after the user joins the channel. You need to call the publish method to do that.\n By default, the SDK publishes streams once the user joins the channel.\n      \n  \n       \n   \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different UIDs for different channels.\n  If you want to join the same channel from different devices, ensure that the user IDs in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            },
            {
                "uid": "The user ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. This parameter is a 32-bit unsigned integer with a value ranging from 1 to 232 -1. If the user ID is not assigned (or set as 0), the SDK assigns a user ID and reports it in theonJoinChannelSuccess callback. Your app must maintain this user ID."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an IChannel object with the same channel name.\n      You have joined and published a stream in an IChannel channel created by the IChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_ichannel_joinchannelwithuseraccount",
        "name": "joinChannelWithUserAccount",
        "description": "Joins the channel with a user account.This method differs from the joinChannelWithUserAccount method in the IRtcEngine class in the following aspects:\n   \n       \n  \n  \n  \n      \n joinChannelWithUserAccount\n joinChannelWithUserAccount\n      \n      \n Does not contain the channelId parameter. Because channelId is specified when creating the IChannel object.\n You need to fill in the channelId that can identify the channel.\n      \n      \n Users can join multiple channels simultaneously by creating multiple IChannel objects and calling the joinChannelWithUserAccount methods of each object.\n Users can join only one channel.\n      \n      \n By default, the SDK does not publish any stream after the user joins the channel. You need to call the publish method to do that.\n By default, the SDK publishes streams once the user joins the channel.\n      \n  \n       \n   \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  If you are already in a channel, you cannot rejoin it with the user ID.\n  We recommend using different user accounts for different channels.\n  If you want to join the same channel from different devices, ensure that the user accounts in all devices are different.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as nullNULL. Supported characters are (89 in total):\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n "
            },
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an IChannel object with the same channel name.\n      You have joined and published a stream in an IChannel channel created by the IChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_ichannel_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.This method lets the user leave the channel, for example, by hanging up or exiting the call. This method releases all resources related to the session. This method call is asynchronous, and the user has not left the channel when the method call returns.\n   After calling joinChannel, you must call leaveChannel to end the call, otherwise the next call cannot be started.\n   No matter whether you are currently in a call or not, you can call leaveChannelwithout side effects.\n   A successful call of this method triggers the following callbacks: The local client: onLeaveChannel.The remote client: onUserOffline, if the user joining the channel is in the COMMUNICATION profile, or is a host in the LIVE_BROADCASTING profile.\n   \n       \n  If you call the release method immediately after calling leaveChannel, the SDK will not be able to trigger the onLeaveChannel callback.\n  If you call the leaveChannel method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "mute": "Whether to subscribe to the audio streams of all remote users.\n      \n true: Do not subscribe to the audio streams of all remote users.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the video streams of all remote users.\n \n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The user ID of the specified user."
            },
            {
                "mute": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user by default.\n false: (Default) Subscribe to the audio stream of the specified user by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.",
        "parameters": [
            {
                "userId": "\n      The user ID of the specified user.\n  "
            },
            {
                "mute": "Whether to stop subscribing to the video stream of the specified user.\n      true:Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_onactivespeaker",
        "name": "onActiveSpeaker",
        "description": "Occurs when the most active speaker is detected.After a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of user is no less than two and an active speaker exists, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker is always the same user, the SDK triggers the onActiveSpeaker callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": "The user ID of the most active speaker."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onaudiopublishstatechanged",
        "name": "onAudioPublishStateChanged",
        "description": "Occurs when the audio publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onaudiosubscribestatechanged",
        "name": "onAudioSubscribeStateChanged",
        "description": "Occurs when the audio subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelerror",
        "name": "onChannelError",
        "description": "TheIChannel error code reported.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            },
            {
                "err": "The error code. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelmediarelayevent",
        "name": "onChannelMediaRelayEvent",
        "description": "Reports events during the media stream relay.",
        "parameters": [
            {
                "code": "The event code. For details, see CHANNEL_MEDIA_RELAY_EVENT."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelmediarelaystatechanged",
        "name": "onChannelMediaRelayStateChanged",
        "description": "Occurs when the state of the media stream relay changes.The SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "code": "The error code. For details, see CHANNEL_MEDIA_RELAY_ERROR."
            },
            {
                "state": "The state code. For details, see CHANNEL_MEDIA_RELAY_STATE."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onchannelwarning",
        "name": "onChannelWarning",
        "description": "Reports the warning code of IChannel.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            },
            {
                "warn": "Warning codes. For details, see Error Codes and Warning Codes."
            },
            {
                "msg": "The warning message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onclientrolechanged",
        "name": "onClientRoleChanged",
        "description": "Occurs when the user role switches in the interactive live streaming.The SDK triggers this callback when the local user uses the setClientRole method to change the user role after joining the channel.",
        "parameters": [
            {
                "newRole": "Role that the user switches to: CLIENT_ROLE_TYPE."
            },
            {
                "oldRole": "Role that the user switches from: CLIENT_ROLE_TYPE."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onconnectionlost",
        "name": "onConnectionLost",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.The SDK triggers this callback when it cannot connect to the server 10 seconds after calling the joinChannel method, regardless of whether it is in the channel.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onconnectionstatechanged",
        "name": "onConnectionStateChanged",
        "description": "Occurs when the network connection state changes.When the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "reason": "The reason for a connection state change. See CONNECTION_CHANGED_REASON_TYPE."
            },
            {
                "state": "The current connection state. See CONNECTION_STATE_TYPE."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onjoinchannelsuccess",
        "name": "onJoinChannelSuccess",
        "description": "Occurs when a user joins a channel.This callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            },
            {
                "uid": "The user ID. If you have specified a uid in joinChannel, the ID will be returned here; otherwise, the SDK returns an ID automatically assigned by the Agora server."
            },
            {
                "elapsed": "The time elapsed (in milliseconds) from the local user calling joinChannel till this event."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onleavechannel",
        "name": "onLeaveChannel",
        "description": "Occurs when a user leaves a channel.When a user leaves the channel by using the leaveChannel method, the SDK uses this callback to notify the app when the user leaves the channel. With this callback, the app gets the channel information, such as the call duration and quality statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onlocalpublishfallbacktoaudioonly",
        "name": "onLocalPublishFallbackToAudioOnly",
        "description": "Occurs when the published media stream falls back to an audio-only stream due to poor network conditions or switches back to the video after the network conditions improve.If you call setLocalPublishFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   If the local stream fallbacks to the audio-only stream, the remote user receives the onUserMuteVideo callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n      \n true: The published stream falls back to audio-only due to poor network conditions.\n false: The published stream switches back to the video after the network conditions improve.\n      \n  "
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onnetworkquality",
        "name": "onNetworkQuality",
        "description": "Reports the last mile network quality of each user in the channel.This callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate, average RTT, and jitter of the downlink network. See QUALITY_TYPE."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the uplink network. This parameter is a quality rating helping you understand how well the current uplink network conditions can support the selected video encoder configuration. For example, a 1000 Kbps uplink network may be adequate for video frames with a resolution of 640 × 480 and a frame rate of 15 fps in the LIVE_BROADCASTING profile, but may be inadequate for resolutions higher than 1280 × 720. See QUALITY_TYPE."
            },
            {
                "uid": "The user ID. The network quality of the user with this user ID is reported. If uid is 0, the local network quality is reported."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrejoinchannelsuccess",
        "name": "onRejoinChannelSuccess",
        "description": "Occurs when a user rejoins the channel.When a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this callback."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremoteaudiostatechanged",
        "name": "onRemoteAudioStateChanged",
        "description": "Occurs when the remote audio state changes.Since\n                        v2.9.0\n                    \n                \n               When the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": "The reason of the remote audio state change. See REMOTE_AUDIO_STATE_REASON."
            },
            {
                "state": "The state of the remote audio. See REMOTE_AUDIO_STATE."
            },
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "rtcChannel": "IChannel。"
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremoteaudiostats",
        "name": "onRemoteAudioStats",
        "description": "Reports the statistics of the audio stream from each remote user/host.The SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotesubscribefallbacktoaudioonly",
        "name": "onRemoteSubscribeFallbackToAudioOnly",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.If you call setRemoteSubscribeFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n      \n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            },
            {
                "uid": "The ID of the remote user sending the stream."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotevideostatechanged",
        "name": "onRemoteVideoStateChanged",
        "description": "Occurs when the remote video state changes.Since\n                        v2.9.0\n                    \n                \n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "reason": "The reason for the remote video state change. See REMOTE_VIDEO_STATE_REASON."
            },
            {
                "state": "The state of the remote video, see REMOTE_VIDEO_STATE."
            },
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "rtcChannel": "IChannel。"
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onremotevideostats",
        "name": "onRemoteVideoStats",
        "description": "Reports the transport-layer statistics of each remote video stream.Reports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. See RemoteVideoStats."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrequesttoken",
        "name": "onRequestToken",
        "description": "Occurs when the token expires.When the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n            Once you receive this callback, generate a new token on your app server, and call joinChannel to rejoin the channel.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtcstats",
        "name": "onRtcStats",
        "description": "Reports the statistics of the current call.The SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": "\n      Statistics of the RTC engine, see RtcStats for details.\n  "
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtmpstreamingevent",
        "name": "onRtmpStreamingEvent",
        "description": "Reports events during the RTMP or RTMPS streaming.Since\n  v3.1.0",
        "parameters": [
            {
                "eventCode": "The event code of the streaming. See RTMP_STREAMING_EVENT."
            },
            {
                "url": "The RTMP or RTMPS streaming URL."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onrtmpstreamingstatechanged",
        "name": "onRtmpStreamingStateChanged",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.The SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "errCode": "The detailed error information for streaming. See RTMP_STREAM_PUBLISH_ERROR."
            },
            {
                "state": "The RTMP or RTMPS streaming state. See RTMP_STREAM_PUBLISH_STATE. When the streaming status is RTMP_STREAM_PUBLISH_STATE_FAILURE (4), you can view the error information in the errorCode parameter."
            },
            {
                "url": "The CDN streaming URL."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreaminjectedstatus",
        "name": "onStreamInjectedStatus",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.",
        "parameters": [
            {
                "status": "State of the externally injected stream. See INJECT_STREAM_STATUS."
            },
            {
                "uid": "The user ID."
            },
            {
                "url": "The URL address of the externally injected stream."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreammessage",
        "name": "onStreamMessage",
        "description": "Occurs when the local user receives the data stream from the remote user within five seconds.The SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "length": "The data length (byte)."
            },
            {
                "data": "The data received."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onstreammessageerror",
        "name": "onStreamMessageError",
        "description": "Occurs when the local user does not receive the data stream from the remote user within five seconds.The SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "code": "The error code. See Error Codes and Warning Codes."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_ontokenprivilegewillexpire",
        "name": "onTokenPrivilegeWillExpire",
        "description": "Occurs when the token expires in 30 seconds.When the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token. Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_ontranscodingupdated",
        "name": "onTranscodingUpdated",
        "description": "Occurs when the publisher's transcoding is updated.If you callsetLiveTranscoding the method to set the class for the first timeLiveTranscoding, the SDK does not trigger this callback.\n        When the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the onTranscodingUpdated callback to report the update information.",
        "parameters": [
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onuserjoined",
        "name": "onUserJoined",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.In a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n  A remote user/host joins the channel by calling the joinChannel method.\n  A remote user switches the user role to the host by calling the setClientRole method after joining the channel.\n  A remote user/host rejoins the channel after a network interruption.\n  The host injects an online media stream into the channel by calling the addInjectStreamUrl method.",
        "parameters": [
            {
                "uid": "The ID of the user or host who joins the channel."
            },
            {
                "rtcChannel": "IChannel。"
            },
            {
                "elapsed": "Time delay (ms) from the local user calling joinChannel until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onuseroffline",
        "name": "onUserOffline",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.There are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections, so we recommend using the Agora RTM SDK for more reliable offline detection.",
        "parameters": [
            {
                "reason": "Reason why the user goes offline: USER_OFFLINE_REASON_TYPE."
            },
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideopublishstatechanged",
        "name": "onVideoPublishStateChanged",
        "description": "Occurs when the video publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideosizechanged",
        "name": "onVideoSizeChanged",
        "description": "Occurs when the video size or rotation of a specified user changes.",
        "parameters": [
            {
                "rotation": "The rotation information. The value range is [0,360)."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "uid": "The ID of the user whose video size or rotation changes. uid is 0 for the local user."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_onvideosubscribestatechanged",
        "name": "onVideoSubscribeStateChanged",
        "description": "Occurs when the video subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "rtcChannel": "IChannel。"
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_publish",
        "name": "publish",
        "description": "Publish local audio and video streams to the channel.The call of this method must meet the following requirements, otherwise the SDK returns -5(ERR_REFUSED):\n  This method only supports publishing audio and video streams to the channel corresponding to the current IChannel object.\n  In the interactive live streaming channel, only a host can call this method. To switch the client role, call setClientRole of the current IChannel object.\n  You can publish a stream to only one channel at a time. For details on joining multiple channels, see the advanced guide Join Multiple Channels.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      -5(ERR_REFUSED): The request is rejected."
    },
    {
        "id": "api_ichannel_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.Call this method before joinChannel.\n  This method applies only to interactive live streaming.",
        "parameters": [
            {
                "observer": "Pointers to the registered metadata observer. See IMetadataObserver."
            },
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA. See METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_registerpacketobserver",
        "name": "registerPacketObserver",
        "description": "Registers a packet observer.Call this method registers a packet observer. When the Agora SDK triggers callbacks registered by for voice or video packet transmission, youIPacketObserver can call this method to process the packets, such as encryption and decryption.\n   \n       \n  The size of the packet sent to the network after processing should not exceed 1200 bytes, otherwise, the SDK may fail to send the packet.\n  Ensure that both receivers and senders call this method, otherwise, you may meet undefined behaviors such as no voice and black screen.\n  When you use CDN live streaming, recording, or storage functions, Agora doesn't recommend calling this method.\n  Call this method before joining a channel.",
        "parameters": [
            {
                "observer": "IPacketObserver 。"
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_release",
        "name": "release",
        "description": "Releases the IChannel instance.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      ERR_NOT_INITIALIZED(7): The SDK is not initialized before calling this method. Initialize the IChannel instance before calling this method."
    },
    {
        "id": "api_ichannel_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .\n   After a successful method, the SDK triggers theonUserOffline callback with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.\n       \n   \n        After a successful method call, the SDK triggers onRtmpStreamingStateChanged on the local client to report the result of deleting the address.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese language characters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_renewtoken",
        "name": "renewToken",
        "description": "Gets a new token when the current token expires after a period of time.Passes a new token to the SDK. A token expires after a certain period of time. The app should get a new token and call this method to pass the token to the SDK. Failure to do so results in the SDK disconnecting from the server.\n                    The SDK triggers the onTokenPrivilegeWillExpire callback.\n                    The onConnectionStateChanged callback reports CONNECTION_CHANGED_TOKEN_EXPIRED(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ichannel_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.Sends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the onStreamMessage callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the onStreamMessageError callback on the remote client.\n   \n       Ensure that you call createDataStream to create a data channel before calling this method.\n       In live broadcast streaming, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStream."
            },
            {
                "message": "The message to be sent."
            },
            {
                "data": "The custom data."
            },
            {
                "length": "The length of the data."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setchanneleventhandler",
        "name": "setChannelEventHandler",
        "description": "Set the event handler of the IChannel object.After setting the channel event handler, you can listen for channel events and receive the statistics of the corresponding IChannel object.",
        "parameters": [
            {
                "channelEh": "The event handler of the IChannel object. See IChannelEventHandler."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setclientrole1",
        "name": "setClientRole[1/2]",
        "description": "Sets the user role in live interactive streaming.You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:The local client: onClientRoleChanged.The remote client: onUserJoined or onUserOffline(USER_OFFLINE_BECOME_AUDIENCE).\n   This method applies only to interactive live streaming.",
        "parameters": [
            {
                "role": "\n      The user role in the interactive live streaming. See CLIENT_ROLE_TYPE.\n  "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -1(ERR_FAILED): A general error occurs (no specified reason).\n -2(ERR_INALID_ARGUMENT): The parameter is invalid.\n -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_setclientrole2",
        "name": "setClientRole[2/2]",
        "description": "Sets the user role and level in a live interactive streaming.You can call this method either before or after joining the channel to set the user role as audience or host.\n   \n       \n  Since\n  v3.2.0\n       \n   \n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:\n       The local client: onClientRoleChanged.\n       The remote client: onUserJoined oronUserOffline.\n   \n   \n       \n       This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).\n       The difference between this method and \n      The user role determines the permissions that the SDK grants to a user, such as permission to send local streams, receive remote streams, and push streams to a CDN address.\n      The user level determines the level of services that a user can enjoy within the permissions of the user's role. For example, an audience can choose to receive remote streams with low latency or ultra-low latency. Levels affect prices.\n    setClientRole [1/2] is that this method can set the user level in addition to the user role.",
        "parameters": [
            {
                "role": "The user role in a live interactive streaming. See CLIENT_ROLE_TYPE."
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_ichannel_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       \n  Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n       \n  If you need to resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream (false), and specify the user ID.\n  If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream(false) multiple times.",
        "parameters": [
            {
                "mute": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_ichannel_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            \n       \n  Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   \n       If you need to resume subscribing to the video streams of remote users in the channel, do the following:\n       \n  If you need to resume subscribing to a single user, call muteRemoteVideoStream(false) and specify the ID of the remote user you want to subscribe to.\n  If you want to resume subscribing to multiple users, call muteRemoteVideoStream(false) multiple times.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.The Agora SDK supports built-in encryption. The default encryption is AES-128-XTS. Call this method to use other encryption modes. All users in the same channel must use the same encryption mode and password. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   \n       \n  Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.\n       \n   \n   Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "\n      Encryption mode.\n     \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     \"\": When setting as NULL, the encryption mode is set as \"aes-128-xts\" by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.Do not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.\n       \n   \n        Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If the secret is not set or set secret as null, the built-in encryption is disabled.\n   \n       \n  Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.This method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the onTranscodingUpdated callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.\n       \n   \n   This method sets the video layout and audio settings for CDN live streaming. The SDK triggers the onTranscodingUpdated callback when you call this method to update the transcoding setting.",
        "parameters": [
            {
                "transcoding": "\n      The transcoding configurations for CDN live streaming. See LiveTranscoding."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote videos.The method result returns in the onApiCallExecuted callback.\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n   Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream).\n   Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setremoterendermode",
        "name": "setRemoteRenderMode",
        "description": "Updates the display mode of the video view of a remote user.Since\n  v3.0.0\n       \n   \n   After initializing the video view of a remote user, you can call this method to update its rendering and mirror modes. This method affects only the video view that the local user sees.\n   \n       \n  Please call thissetupRemoteVideo method after calling the method to initialize the remote view.\n  During a call, you can call this method as many times as necessary to update the display mode of the video view of a remote user.",
        "parameters": [
            {
                "userId": "\n      Remote user ID.\n  "
            },
            {
                "renderMode: The video display mode:": "\n      The rendering mode of the remote user view, see for detailsRENDER_MODE_TYPE.\n  "
            },
            {
                "mirrorMode": "\n      The mirror mode of the remote user view, see for detailsVIDEO_MIRROR_MODE_TYPE.\n      Note: The SDK disables the mirror mode by default.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.Since\n                         v2.4.0\n                    \n               \n               Prioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See PRIORITY_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "Sets the stream type of the remote video.The method result returns in the onApiCallExecuted callback.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n               Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               Call this method after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "userId": "The user ID."
            },
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_ichannel_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the sound position and gain of a remote user.This method sets the sound position and gain of a remote user.\n   When the local user calls this method to set the sound position of a remote user, the sound difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a real sense of space. This method applies to massively multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n  This method requires hardware support. For the best sound positioning, we recommend using a stereo speaker.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "pan": "The sound position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: the remote sound comes from the front.\n -1.0: the remote sound comes from the left.\n 1.0: the remote sound comes from the right.\n      \n  "
            },
            {
                "gain": "The gain of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original gain of the remote user). The smaller the value, the less the gain."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.After a successful method call, the SDK triggers the onChannelMediaRelayStateChanged and onChannelMediaRelayEvent callbacks, and these callbacks return the state and events of the media stream relay.\n  If the onChannelMediaRelayStateChanged callback returns RELAY_STATE_RUNNING(2) and RELAY_OK(0), and the onChannelMediaRelayEvent callback returns RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL(4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the onChannelMediaRelayStateChanged callback returns RELAY_STATE_FAILURE(3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a LIVE_BROADCASTING channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.After a successful method call, the SDK triggers the onChannelMediaRelayStateChanged callback. If the callback reports RELAY_STATE_IDLE(0) and RELAY_OK(0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the onChannelMediaRelayStateChanged callback with the RELAY_ERROR_SERVER_NO_RESPONSE(2) or RELAY_ERROR_SERVER_CONNECTION_LOST(8) status code. You can callleaveChannel the method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ichannel_unpublish",
        "name": "unpublish",
        "description": "Stops publishing a stream to the channel.If you call this method in a channel where you are not publishing streams, the SDK returns -5 (ERR_REFUSED).",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure.\n      -5(ERR_REFUSED): The request is rejected."
    },
    {
        "id": "api_ichannel_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.After the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the onChannelMediaRelayEvent callback with the RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL(7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. For details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_initialize",
        "name": "initialize",
        "description": "InitializeIRtcEngine.Before calling other APIs, you must call to initialize create an IRtcEngine object.",
        "parameters": [
            {
                "config": "\n                        Configurations for the IRtcEngine instance. See RtcEngineContext.\n                    "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2(ERR_INVALID_ARGUMENT): An invalid parameter is used. For example, IRtcEngineEventHandler is not set.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -22(ERR_RESOURCE_LIMITED): The resource is limited. The SDK fails to allocate resources because your app uses too many system resources or system resources are insufficient.\n  -101(ERR_INVALID_APP_ID): The App ID is invalid."
    },
    {
        "id": "api_isapplicationmute",
        "name": "isApplicationMute",
        "description": "Checks whether the app is muted.",
        "parameters": [
            {
                "mute": "Whether the app is muted:\n      true: The app is muted.\n      false: The app is not muted.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_iscameraautofocusfacemodesupported",
        "name": "isCameraAutoFocusFaceModeSupported",
        "description": "Checks whether the device supports the face auto-focus function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "true: The device supports the face auto-focus function.\n       false: The device does not support the face auto-focus function."
    },
    {
        "id": "api_iscameraexposurepositionsupported",
        "name": "isCameraExposurePositionSupported",
        "description": "Check whether the device supports the manual exposure function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "true: The device supports the manual exposure function.\n       false: The device does not support the manual exposure function."
    },
    {
        "id": "api_iscamerafocussupported",
        "name": "isCameraFocusSupported",
        "description": "Check whether the device supports the manual focus function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "true: The device supports the manual focus function.\n       false: The device does not support the manual focus function."
    },
    {
        "id": "api_iscameratorchsupported",
        "name": "isCameraTorchSupported",
        "description": "Check whether the device supports the camera flash function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).\n            The app enables the front camera by default. If your front camera does not support the flash function, this method returns false. If you want to check whether the rear camera supports the flash function, call switchCamera before this method.",
        "parameters": [],
        "returns": "true: The device supports the camera flash function.\n       false: The device does not support the camera flash function."
    },
    {
        "id": "api_iscamerazoomsupported",
        "name": "isCameraZoomSupported",
        "description": "Checks whether the device supports the camera zoom function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "true: The device supports the camera zoom function.\n       false: The device does not support the camera zoom function."
    },
    {
        "id": "api_isspeakerphoneenabled",
        "name": "isSpeakerphoneEnabled",
        "description": "Checks whether the speakerphone is enabled.",
        "parameters": [],
        "returns": "true: The speakerphone is enabled, and the audio plays from the speakerphone.\n       false: The speakerphone is not enabled, and the audio plays from devices other than the speakerphone. For example, the headset or earpiece."
    },
    {
        "id": "api_ivideodevicecollection_getcount",
        "name": "getCount",
        "description": "Gets the total number of the indexed video devices in the system.",
        "parameters": [],
        "returns": "The total number of the indexed video devices in the system."
    },
    {
        "id": "api_ivideodevicecollection_getdevice",
        "name": "getDevice",
        "description": "Gets a specified piece of information about an indexed video device.",
        "parameters": [
            {
                "index": "The index value of the video device. The value of this parameter must be less than the value returned in getCount."
            },
            {
                "deviceName": "The name of the device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            },
            {
                "deviceId": "The device ID of the video device. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ivideodevicecollection_release",
        "name": "release",
        "description": "Releases all the resources occupied by the IVideoDeviceCollection object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ivideodevicecollection_setdevice",
        "name": "setDevice",
        "description": "Sets the device with the device ID.",
        "parameters": [
            {
                "deviceId": "The device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ivideodevicemanager_getdevice",
        "name": "getDevice",
        "description": "Gets the video capture device that is in use.",
        "parameters": [
            {
                "deviceId": "Output parameter. The device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ivideodevicemanager_release",
        "name": "release",
        "description": "Releases all the resources occupied by the IVideoDeviceManager object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_ivideodevicemanager_setdevice",
        "name": "setDevice",
        "description": "Sets the device with the device ID.Plugging or unplugging a device does not change its device ID.",
        "parameters": [
            {
                "deviceId": "The device ID. You can get the device ID by calling enumerateVideoDevices. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_ivideoframeobserver_ismultiplechannelframewanted",
        "name": "isMultipleChannelFrameWanted",
        "description": "Sets whether to get video data from multiple channels in the multi-channel scenario.Since\n      v3.0.1\n  \n       \n   After you register the video frame observer, the SDK triggers this callback every time it captures a video frame.\n   In the multi-channel scenario, if you want to get video data from multiple channels, you need to set the return value of this callback as true. After that, the SDK triggers the onRenderVideoFrameEx callback to send you the received remote video frame and report which channel the video frame comes from.\n   \n       \n  If you set the return value of this callback as true, the SDK triggers onRenderVideoFrameEx to send the before-mixing video data. onRenderVideoFrame will not be triggered. In the multi-channel scenario, Agora recommends setting the return value as true.\n  If you set the return value of this callback as false, the SDK triggers onRenderVideoFrame to send you the received video data.",
        "parameters": [],
        "returns": "true: Receive video data from multiple channels.\n       false: Do not receive video data from multiple channels."
    },
    {
        "id": "api_joinchannel",
        "name": "joinChannel[1/2]",
        "description": "Allows a user to join a channel.When the connection between the client and Agora's server is interrupted due to poor network conditions, the SDK tries reconnecting to the server. When the local client successfully rejoins the channel, the SDK triggers the onRejoinChannelSuccess callback on the local client.\n   A successful call of this method triggers the following callbacks:\n                The local client: The onJoinChannelSuccess and onConnectionStateChanged callbacks.\n                The remote client: onUserJoined, if the user joining the channel is in the communication profile, or is a host in the live streaming profile.\n            \n            This method joins an Agora RTC channel. Users with the same App ID in the same channel can talk to each other, and multiple users in the same channel can start a group chat.\n            Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.",
        "parameters": [
            {
                "uid": "The user ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. A 32-bit unsigned integer with a value ranging from 1 to 232-1. If the user ID is not assigned (or set to 0), the SDK assigns and returns a user ID in the onJoinChannelSuccess callback. Your application must record and maintain the returned user ID, because the SDK does not do so."
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an IChannel object with the same channel name.\n      You have joined and published a stream in an IChannel channel created by the IChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_joinchannel2",
        "name": "joinChannel[2/2]",
        "description": "Joins a channel with the user ID, and configures whether to automatically subscribe to the audio or video streams.Since\n  v3.3.0\n       \n   \n            This method joins an Agora RTC channel. Users with the same App ID in the same channel can talk to each other, and multiple users in the same channel can start a group chat.\n            A successful call of this method triggers the following callbacks:\n                The local client: The onJoinChannelSuccess and onConnectionStateChanged callbacks.\n                The remote client: onUserJoined, if the user joining the channel is in the communication profile, or is a host in the live streaming profile.\n            \n            When the connection between the client and Agora's server is interrupted due to poor network conditions, the SDK tries reconnecting to the server. When the local client successfully rejoins the channel, the SDK triggers the onRejoinChannelSuccess callback on the local client.\n   Compared to joinChannel[1/2], this method adds the options parameter to configure whether to automatically subscribe to all remote audio and video streams in the channel when the user joins the channel. By default, the user subscribes to the audio and video streams of all the other users in the channel, thus incurring all associated usage costs. To unsubscribe, set the options parameter or call the mute methods accordingly.",
        "parameters": [
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            },
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "info": "\n      Reserved for future use.\n  "
            },
            {
                "uid": "The user ID. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user IDs yourself, and ensure that each user ID in the same channel is unique. A 32-bit unsigned integer with a value ranging from 1 to 232-1. If the user ID is not assigned (or set to 0), the SDK assigns and returns a user ID in the onJoinChannelSuccess callback. Your application must record and maintain the returned user ID, because the SDK does not do so."
            },
            {
                "options": "The channel media options. See ChannelMediaOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an IChannel object with the same channel name.\n      You have joined and published a stream in an IChannel channel created by the IChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_joinchannelwithuseraccount1",
        "name": "joinChannelWithUserAccount[1/2]",
        "description": "Allows a user to join a channel.Since\n  v2.8.0\n       \n   \n   This method allows a user to join the channel with the user account. After the user successfully joins the channel, the SDK triggers the following callbacks:\n       The local client: onLocalUserRegistered, onJoinChannelSuccess and the onConnectionStateChangedcallbacks.\n       The remote client: onUserJoined and onUserInfoUpdated, if the user is in the COMMUNICATION profile, or if the user is a host in the LIVE_BROADCASTING profile.\n   \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.",
        "parameters": [
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            },
            {
                "channelName": "The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as null\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n NULL. Supported characters are (89 in total):"
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected."
    },
    {
        "id": "api_joinchannelwithuseraccount2",
        "name": "joinChannelWithUserAccount[2/2]",
        "description": "Joins the channel with a user account, and configures whether to automatically subscribe to audio or video streams after joining the channel.Since\n  v3.3.0\n       \n   \n   This method allows a user to join the channel with the user account. After the user successfully joins the channel, the SDK triggers the following callbacks:\n  The local client: onLocalUserRegistered, onJoinChannelSuccess and the onConnectionStateChangedcallbacks.\n  The remote client: The onUserJoined callback if the user is in the COMMUNICATION profile, and the onUserInfoUpdated callback if the user is a host in the LIVE_BROADCASTING profile.\n       \n   Once the user joins the channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.\n   \n       \n  Compared to joinChannelWithUserAccount[1/2], this method adds the options parameter to configure whether to automatically subscribe to all remote audio and video streams in the channel when the user joins the channel. By default, the user subscribes to the audio and video streams of all the other users in the channel, thus incurring all associated usage costs. To unsubscribe, set the options parameter or call the mute methods accordingly.\n  To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.",
        "parameters": [
            {
                "options": "The channel media options. See ChannelMediaOptions."
            },
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n \n  "
            },
            {
                "token": "\n    The token generated on your server for authentication. For details, see .\n    Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n      "
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as nullNULL. Supported characters are (89 in total):\n     The 26 lowercase English letters: a to z.\n     The 26 uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     Space\n     \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -3(ERR_NOT_READY): The SDK fails to be initialized. You can try re-initializing the SDK.\n  -5(ERR_REFUSED): The request is rejected. This may be caused by the following:\n      You have created an IChannel object with the same channel name.\n      You have joined and published a stream in an IChannel channel created by the IChannel object.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized before calling this method. Initialize the IRtcEngine instance before calling this method."
    },
    {
        "id": "api_leavechannel",
        "name": "leaveChannel",
        "description": "Leaves a channel.This method releases all resources related to the session. This method call is asynchronous, and the user has not left the channel when the method call returns.\n   After calling joinChannel, you must call leaveChannel to end the call, otherwise the next call cannot be started.\n   A successful call of this method triggers the following callbacks:\n                    The local client: onLeaveChannel.\n                    The remote client: onUserOffline, if the user joining the channel is in the communication profile, or is a host in the live streaming profile.\n                \n   \n       \n  If you call the release method immediately after calling leaveChannel, the SDK will not be able to trigger the onLeaveChannel callback.\n  If you call the leaveChannel method during a CDN live streaming, the SDK automatically calls the removePublishStreamUrl method.",
        "parameters": [],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_muteallremoteaudiostreams",
        "name": "muteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the audio streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "mute": "Whether to subscribe to the audio streams of all remote users.\n      \n true: Do not subscribe to the audio streams of all remote users.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_muteallremotevideostreams",
        "name": "muteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users.As of v3.3.0, after successfully calling this method, the local user stops or resumes subscribing to the video streams of all remote users, including all subsequent users.\n   \n       \n  Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the video streams of all remote users.\n \n     true: Stop subscribing to the video streams of all remote users.\n     false: (Default) Subscribe to the audio streams of all remote users by default.\n \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_mutelocalaudiostream",
        "name": "muteLocalAudioStream",
        "description": "Stops or resumes publishing the local audio stream.A successful call of this method triggers the onUserMuteAudio callback on the remote client.\n   \n       \n  This method does not affect any ongoing audio recording, because it does not disable the microphone.\n  You can call this method either before or after joining a channel. If you call the setChannelProfile method after this method, the SDK resets whether or not to stop publishing the local audio according to the channel profile and user role. Therefore, we recommend calling this method after the setChannelProfile method.",
        "parameters": [
            {
                "mute": "Whether to stop publishing the local audio stream.\n  \n      true: Stop publishing the local audio stream.\n      false: (Default) Resumes publishing the local audio stream.\n  \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_mutelocalvideostream",
        "name": "muteLocalVideoStream",
        "description": "Stops or resumes publishing the local audio stream.A successful call of this method triggers the onUserMuteVideo callback on the remote client.\n                    \n                        This method executes faster than the enableLocalVideo(false) method, which controls the sending of the local video stream.\n                        This method does not affect any ongoing video recording, because it does not disable the camera.\n                        You can call this method either before or after joining a channel. If you call setChannelProfile after this method, the SDK resets whether or not to stop publishing the local video according to the channel profile and user role. Therefore, Agora recommends calling this method after the setChannelProfile method.",
        "parameters": [
            {
                "mute": "\n                        Whether to stop publishing the local video stream.\n                            true: Stop publishing the local video stream.\n                            false: (Default) Publish the local video stream.\n                        \n                        \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_muteremoteaudiostream",
        "name": "muteRemoteAudioStream",
        "description": "Stops or resumes subscribing to the audio stream of a specified user.Call this method after joining a channel.\n  See recommended settings in Set the Subscribing State.",
        "parameters": [
            {
                "userId": "The user ID of the specified user."
            },
            {
                "mute": "Whether to stop subscribing to the audio stream of the specified user.\n      \n true: Stop subscribing to the audio stream of the specified user by default.\n false: (Default) Subscribe to the audio stream of the specified user by default.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_muteremotevideostream",
        "name": "muteRemoteVideoStream",
        "description": "Stops or resumes subscribing to the video stream of a specified user.",
        "parameters": [
            {
                "userId": "\n      The user ID of the specified user.\n  "
            },
            {
                "mute": "Whether to stop subscribing to the video stream of the specified user.\n      true:Stop subscribing to the video streams of the specified user.\n      false: (Default) Subscribe to the video stream of the specified user.\n  \n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_onactivespeaker",
        "name": "onActiveSpeaker",
        "description": "Occurs when the most active speaker is detected.After a successful call of enableAudioVolumeIndication, the SDK continuously detects which remote user has the loudest volume. During the current period, the remote user, who is detected as the loudest for the most times, is the most active user.\n   When the number of user is no less than two and an active speaker exists, the SDK triggers this callback and reports the uid of the most active speaker.\n  If the most active speaker is always the same user, the SDK triggers the onActiveSpeaker callback only once.\n  If the most active speaker changes to another user, the SDK triggers this callback again and reports the uid of the new active speaker.",
        "parameters": [
            {
                "uid": "The user ID of the most active speaker."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onapicallexecuted",
        "name": "onApiCallExecuted",
        "description": "Occurs when a method is executed by the SDK.",
        "parameters": [
            {
                "err": "The error code returned by the SDK when the method call fails. For detailed error information and troubleshooting methods, see Error Code and Warning Code. If the SDK returns 0, then the method call is successful."
            },
            {
                "api": "The method executed by the SDK."
            },
            {
                "result": "The result of the method call."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiodevicestatechanged",
        "name": "onAudioDeviceStateChanged",
        "description": "Occurs when the audio device state changes.This callback notifies the application that the system's audio device state is changed. For example, a headset is unplugged from the device.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "The device type. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "The device state. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiodevicevolumechanged",
        "name": "onAudioDeviceVolumeChanged",
        "description": "Occurs when the volume on the playback or audio capture device, or the volume in the application changes.",
        "parameters": [
            {
                "deviceType": "The device type. See MEDIA_DEVICE_TYPE."
            },
            {
                "volume": "The volume value. The range is [0, 255]."
            },
            {
                "muted": "Whether the audio device is muted:\n      true: The audio device is muted.\n      false: The audio device is not muted.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudioeffectfinished",
        "name": "onAudioEffectFinished",
        "description": "Occurs when the playback of the local audio effect file finishes.This callback occurs when the local audio effect file finishes playing.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiomixingfinished",
        "name": "onAudioMixingFinished",
        "description": "Occurs when the playback of the local music file finishes.Deprecated:\n  This method is deprecated as of v2.4.0. Use onAudioMixingStateChanged instead.\n       \n   \n   After you call startAudioMixing to play a local music file, this callback occurs when the playback finishes. If the call of startAudioMixing fails, the onError callback returns the error code WARN_AUDIO_MIXING_OPEN_ERROR.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onaudiomixingstatechanged",
        "name": "onAudioMixingStateChanged",
        "description": "Occurs when the playback state of the music file changes.Since\n  v2.4.0\n       \n   \n   This callback occurs when the playback state of the music file changes, and reports the current state and error code.\n   If the local music file does not exist, or if the SDK does not support the file format, or if the SDK cannot access the URL of the online music file, the SDK returns the warning code WARN_AUDIO_MIXING_OPEN_ERROR (701).",
        "parameters": [
            {
                "state": "The playback state of the music file. See AUDIO_MIXING_STATE_TYPE."
            },
            {
                "errorCode": "The error code. See AUDIO_MIXING_ERROR_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiopublishstatechanged",
        "name": "onAudioPublishStateChanged",
        "description": "Occurs when the audio publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "oldState": "For the previous publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "newState": "For the current publishing state, see STREAM_PUBLISH_STATE."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudioquality",
        "name": "onAudioQuality",
        "description": "Reports the statistics of the audio stream from each remote user.Deprecated:\n      Deprecated as of v2.3.2. Please use the onRemoteAudioStats method instead.\n  \n       \n   \n   The SDK triggers this callback once every two seconds to report the audio quality of each remote user/host sending an audio stream. If a channel has multiple users/hosts sending audio streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the audio stream."
            },
            {
                "quality": "The audio quality, see QUALITY_TYPE."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver, including the delay caused by sound sampling pre-processing, network transmission, and network jitter buffering."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the receiver."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudioroutechanged",
        "name": "onAudioRouteChanged",
        "description": "Occurs when the local audio route changes.",
        "parameters": [
            {
                "routing": "The current audio routing. For details, see AUDIO_ROUTE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiosubscribestatechanged",
        "name": "onAudioSubscribeStateChanged",
        "description": "Occurs when the audio subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onaudiovolumeindication",
        "name": "onAudioVolumeIndication",
        "description": "Reports the volume information of users.By default, this callback is disabled. You can enable it by calling enableAudioVolumeIndication. Once this callback is enabled and users send streams in the channel, the SDK triggers the onAudioVolumeIndication callback at the time interval set in enableAudioVolumeIndication. The SDK triggers two independent onAudioVolumeIndication callbacks simultaneously, which separately report the volume information of the local user who sends a stream and the remote users (up to three) whose instantaneous volumes are the highest.\n   After you enable this callback, calling muteLocalAudioStream affects the SDK's behavior as follows:\n  If the local user stops publishing the audio stream, the SDK stops triggering the local user's callback.\n  20 seconds after a remote user whose volume is one of the three highest stops publishing the audio stream, the callback excludes this user's information; 20 seconds after all remote users stop publishing audio streams, the SDK stops triggering the callback for remote users.",
        "parameters": [
            {
                "speakers": "The volume information of the users, see AudioVolumeInfo. An empty speakers array in the callback indicates that no remote user is in the channel or sending a stream at the moment."
            },
            {
                "totalVolume": "\n      The volume of the speaker. The value ranges between 0 (lowest volume) and 255 (highest volume).\n     In the callback for the local user, totalVolume is the volume of the local user who sends a stream.\n     In the callback for remote users, totalVolume is the sum of the volume of all remote users (up to three) whose instantaneous volumes are the highest. If the user calls startAudioMixing, then totalVolume is the volume after audio mixing.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncameraexposureareachanged",
        "name": "onCameraExposureAreaChanged",
        "description": "Occurs when the camera exposure area changes.The SDK triggers this callback when the local user changes the camera exposure position by calling the setCameraExposurePosition method.",
        "parameters": [
            {
                "x": "The x coordinate of the changed camera exposure area."
            },
            {
                "y": "The y coordinate of the changed camera exposure area."
            },
            {
                "width": "The width of the changed camera exposure area."
            },
            {
                "height": "The height of the changed exposure area."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncamerafocusareachanged",
        "name": "onCameraFocusAreaChanged",
        "description": "Occurs when the camera focus area changes.The SDK triggers this callback when the local user changes the camera focus position by calling the setCameraFocusPositionInPreview method.",
        "parameters": [
            {
                "x": "The x coordinate of the changed camera focus area."
            },
            {
                "y": "The y coordinate of the changed camera focus area."
            },
            {
                "width": "The width of the changed camera focus area."
            },
            {
                "height": "The height of the changed camera focus area."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oncameraready",
        "name": "onCameraReady",
        "description": "Occurs when the camera turns on and is ready to capture the video.Deprecated:\n  \n                        This callback is deprecated. Please use LOCAL_VIDEO_STREAM_STATE_CAPTURING(1) in onLocalVideoStateChanged instead.\n                    \n       \n   \n   This callback indicates that the camera has been successfully turned on and you can start to capture video.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_oncapturevideoframe",
        "name": "onCaptureVideoFrame",
        "description": "Occurs each time the SDK receives a video frame captured by the local camera.After you successfully register the video frame observer, the SDK triggers this callback each time when it receives a video frame. In this callback, you can get the video data captured by the local camera. You can then pre-process the data according to your scenarios.\n   After pre-processing, you can send the processed video data back to the SDK by setting the `videoFrame` parameter in this callback.\n   \n       \n  This callback does not support sending processed RGBA video data back to the SDK.\n  The video data that this callback gets has not been pre-processed, without the watermark, the cropped content, the rotation, and the image enhancement.",
        "parameters": [
            {
                "videoFrame": "Video frame data, see VideoFrame for details."
            }
        ],
        "returns": "Whether to ignore the current video frame if the processing fails:\n  true: Do not ignore.\n  false: Ignore the current video frame, and do not send it back to the SDK."
    },
    {
        "id": "api_onchannelmediarelayevent",
        "name": "onChannelMediaRelayEvent",
        "description": "Reports events during the media stream relay.",
        "parameters": [
            {
                "code": "The event code. For details, see CHANNEL_MEDIA_RELAY_EVENT."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onchannelmediarelaystatechanged",
        "name": "onChannelMediaRelayStateChanged",
        "description": "Occurs when the state of the media stream relay changes.The SDK returns the state of the current media relay with any error message.",
        "parameters": [
            {
                "state": "The state code. For details, see CHANNEL_MEDIA_RELAY_STATE."
            },
            {
                "code": "The error code. For details, see CHANNEL_MEDIA_RELAY_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onclientrolechanged",
        "name": "onClientRoleChanged",
        "description": "Occurs when the user role switches in the interactive live streaming.The SDK triggers this callback when the local user switches the user role by calling setClientRole after joining the channel.",
        "parameters": [
            {
                "oldRole": "Role that the user switches from: CLIENT_ROLE_TYPE."
            },
            {
                "newRole": "Role that the user switches to: CLIENT_ROLE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onconnectionbanned",
        "name": "onConnectionBanned",
        "description": "Occurs when the connection is banned by the Agora server.Deprecated:\n  Deprecated as of v2.3.2. Please use onConnectionStateChanged instead.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectioninterrupted",
        "name": "onConnectionInterrupted",
        "description": "Occurs when the connection between the SDK and the server is interrupted.Deprecated:\n  Deprecated as of v2.3.2. Please use onConnectionStateChanged instead.\n       \n   \n   The SDK triggers this callback when it loses connection with the server for more than four seconds after the connection is established. After triggering this callback, the SDK tries to reconnect to the server. You can use this callback to implement pop-up reminders. The difference between this callback and onConnectionLost is:\n       The SDK triggers the onConnectionInterrupted callback when it loses connection with the server for more than four seconds after it successfully joins the channel.\n       The SDK triggers the onConnectionLost callback when it loses connection with the server for more than 10 seconds, whether or not it joins the channel.\n   If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectionlost",
        "name": "onConnectionLost",
        "description": "Occurs when the SDK cannot reconnect to Agora's edge server 10 seconds after its connection to the server is interrupted.The SDK triggers this callback when it cannot connect to the server 10 seconds after calling the joinChannel method, regardless of whether it is in the channel. If the SDK fails to rejoin the channel 20 minutes after being disconnected from Agora's edge server, the SDK stops rejoining the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onconnectionstatechanged",
        "name": "onConnectionStateChanged",
        "description": "Occurs when the network connection state changes.Since\n  v2.3.2\n       \n   \n   When the network connection state changes, the SDK triggers this callback and reports the current connection state and the reason for the change.",
        "parameters": [
            {
                "state": "The current connection state. See CONNECTION_STATE_TYPE."
            },
            {
                "reason": "The reason for a connection state change. See CONNECTION_CHANGED_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ondispose",
        "name": "onDispose",
        "description": "Notification for disabling the custom video source.The SDK triggers this callback to remind you to disable the custom video source device. This callback tells you that the SDK is about to release the IVideoFrameConsumer object. Ensure that you no longer use IVideoFrameConsumer after receiving this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onerror",
        "name": "onError",
        "description": "Reports an error during SDK runtime.This callback indicates that an error occurs during SDK runtime. In most cases, the SDK cannot fix the issue and resume running. The SDK requires the application to take action or informs the user about the issue. For example, the SDK reports an ERR_START_CALL error when failing to initialize a call. The app informs the user that the call initialization failed and invokes the leaveChannel method to leave the channel.",
        "parameters": [
            {
                "err": "The error code, see ."
            },
            {
                "msg": "The error message."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfacepositionchanged",
        "name": "onFacePositionChanged",
        "description": "Reports the face detection result of the local user.Since\n  v3.0.1\n       \n   \n   Once you enable face detection by calling enableFaceDetection(true), you can get the following information on the local user in real-time:\n  The width and height of the local video.\n  The position of the human face in the local video.\n  The distance between the human face and the screen.\n       \n   \n   This value is based on the fitting calculation of the local video size and the position of the human face.\n   \n       \n           This method is for Android and iOS only.\n  If the SDK does not detect a face, it reduces the frequency of this callback to reduce power consumption on the local device.\n  The SDK stops triggering this callback when a human face is in close proximity to the screen.\n  On Android, the value of distance reported in this callback may be slightly different from the actual distance. Therefore, Agora does not recommend using it for accurate calculation.",
        "parameters": [
            {
                "imageWidth": "The width (px) of the video image captured by the local camera."
            },
            {
                "imageHeight": "The height (px) of the video image captured by the local camera."
            },
            {
                "vecRectangle": "\n      The position and size of the human face on the local video:\n     x: The x coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the x coordinate represents the relative lateral displacement of the top left corner of the human face to the origin.\n     y: The y coordinate (px) of the human face in the local video. Taking the top left corner of the captured video as the origin, the y coordinate represents the relative longitudinal displacement of the top left corner of the human face to the origin.\n     width: The width (px) of the human face in the captured video.\n     height: The height (px) of the human face in the captured video.\n \n      \n  "
            },
            {
                "vecDistance": "The distance between the human face and the device screen."
            },
            {
                "numFaces": "The number of faces detected. If the value is 0, it means that no human face is detected."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalaudioframe",
        "name": "onFirstLocalAudioFrame",
        "description": "Occurs when the engine sends the first local audio frame.Deprecated:\n  This callback is deprecated as of v3.1.0, please use the onFirstLocalAudioFramePublished callback instead.",
        "parameters": [
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalaudioframepublished",
        "name": "onFirstLocalAudioFramePublished",
        "description": "Occurs when the first audio frame is published.Since\n                    v3.1.0\n                \n            \n            The SDK triggers this callback under one of the following circumstances:\n                    The local client enables the audio module and calls joinChannel successfully.\n                    The local client calls muteLocalAudioStream(true) and muteLocalAudioStream(false) in sequence.\n                    The local client calls disableAudio and enableAudio in sequence.\n                    The local client calls pushAudioFrame to successfully push the audio frame to the SDK.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalvideoframe",
        "name": "onFirstLocalVideoFrame",
        "description": "Occurs when the first local video frame is rendered.The SDK triggers this callback when the first local video frame is displayed/rendered on the local video view.",
        "parameters": [
            {
                "width": "The width (px) of the first local video frame."
            },
            {
                "height": "The height (px) of the first local video frame."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback. If you call startPreview before calling joinChannel, then this parameter is the time elapsed from calling startPreview method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstlocalvideoframepublished",
        "name": "onFirstLocalVideoFramePublished",
        "description": "Occurs when the first video frame is published.Since\n  v3.1.0\n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n  The local client enables the video module and calls joinChannel successfully.\n  The local client calls muteLocalVideoStream(true) and muteLocalVideoStream(false) in sequence.\n  The local client calls disableVideo and enableVideo in sequence.\n           The local client calls pushVideoFrame to successfully push the video frame to the SDK.",
        "parameters": [
            {
                "elapsed": "The time elapsed (ms) from the local client calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremoteaudiodecoded",
        "name": "onFirstRemoteAudioDecoded",
        "description": "Occurs when the SDK decodes the first remote audio frame for playback.Deprecated:\n  Deprecated as of v3.0.0. Please use onRemoteAudioStateChanged instead.\n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n                    The remote user joins the channel and sends the audio stream.\n                    The remote user stops sending the audio stream and re-sends it after 15 seconds. The remote user stops sending the audio stream and re-sends it after 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalAudioStream to stop sending the audio stream.\n                            The remote user calls disableAudio to disable audio.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremoteaudioframe",
        "name": "onFirstRemoteAudioFrame",
        "description": "Occurs when the SDK receives the first audio frame from a specific remote user.Deprecated:\n  This callback is deprecated as of v3.0.0. Please use onRemoteAudioStateChanged instead.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremotevideodecoded",
        "name": "onFirstRemoteVideoDecoded",
        "description": "Occurs when the first remote video frame is received and decoded.Deprecated:\n  Deprecated as of v2.9.0, please use the onRemoteVideoStateChanged callback with the following parameters:\n      REMOTE_VIDEO_STATE_STARTING (1).\n      REMOTE_VIDEO_STATE_DECODING (2).\n  \n  \n       \n   \n   The SDK triggers this callback under one of the following circumstances:\n                    The remote user joins the channel and sends the video stream.\n                    The remote user stops sending the video stream and re-sends it after 15 seconds. Reasons for such an interruption include:\n                            The remote user leaves the channel.\n                            The remote user drops offline.\n                            The remote user calls muteLocalVideoStream to stop sending the video stream.\n                            The remote user calls disableVideo to disable video.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onfirstremotevideoframe",
        "name": "onFirstRemoteVideoFrame",
        "description": "Occurs when the first remote video frame is rendered.The SDK triggers this callback when the first local video frame is displayed/rendered on the local video view. The application can retrieve the time elapsed (the elapsed parameter) from a user joining the channel until the first video frame is displayed.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "width": "The width (px) of the video stream."
            },
            {
                "height": "The height (px) of the video stream."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling joinChannel until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_oninitialize",
        "name": "onInitialize",
        "description": "Notification for initializing the custom video source.The SDK triggers this callback to remind you to initialize the custom video source. After receiving this callback, you can do some preparation, such as enabling the camera, and then use the return value to tell the SDK whether the custom video source is prepared.",
        "parameters": [
            {
                "consumer": "A IVideoFrameConsumer object passed to you by the SDK. You need to reserve this object and use it to send the video frame to the SDK once the custom video source is started."
            }
        ],
        "returns": "true: The custom video source is initialized.\n       false: The custom video source is not ready or fails to initialize. The SDK stops and reports the error."
    },
    {
        "id": "api_onjoinchannelsuccess",
        "name": "onJoinChannelSuccess",
        "description": "Occurs when a user joins a channel.This callback notifies the application that a user joins a specified channel.",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The ID of the user who joins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlastmileproberesult",
        "name": "onLastmileProbeResult",
        "description": "Reports the last-mile network probe result.Since\n                    v2.4.0\n                \n            \n            The SDK triggers this callback within 30 seconds after the app calls startLastmileProbeTest.",
        "parameters": [
            {
                "result": "The uplink and downlink last-mile network probe test result. See LastmileProbeResult."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlastmilequality",
        "name": "onLastmileQuality",
        "description": "Reports the last mile network quality of the local user once every two seconds before the user joins the channel.This callback reports the last-mile network conditions of the local user before the user joins the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   After the app calls enableLastmileTest, the SDK triggers this callback once every two seconds.",
        "parameters": [
            {
                "quality": "The last mile network quality. See QUALITY_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onleavechannel",
        "name": "onLeaveChannel",
        "description": "Occurs when a user leaves a channel.This callback notifies the app that a user leaves the channel when the application calls leaveChannel. From this callback, the app can get information such as the call duration and statistics.",
        "parameters": [
            {
                "stats": "The statistics of the call, see RtcStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalaudiostatechanged",
        "name": "onLocalAudioStateChanged",
        "description": "Occurs when the local audio stream state changes.Since\n                    v2.9.0\n                \n            \n            When the state of the local audio stream changes (including the state of the audio capture and encoding), the SDK triggers this callback to report the current state. This callback allows you to troubleshoot issues when audio exceptions occur.\n            When the state is LOCAL_AUDIO_STREAM_STATE_FAILED(3), you can view the error information in the error parameter.",
        "parameters": [
            {
                "state": "The state of the local audio. See LOCAL_AUDIO_STREAM_STATE."
            },
            {
                "error": "The error information of the local audio. See LOCAL_AUDIO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalaudiostats",
        "name": "onLocalAudioStats",
        "description": "Reports the statistics of the local audio stream.The SDK triggers this callback once every two seconds.",
        "parameters": [
            {
                "stats": "The statistics of the local audio stream. See LocalAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalpublishfallbacktoaudioonly",
        "name": "onLocalPublishFallbackToAudioOnly",
        "description": "Occurs when the published media stream falls back to an audio-only stream due to poor network conditions or switches back to the video after the network conditions improve.If you call setLocalPublishFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   If the local stream fallbacks to the audio-only stream, the remote user receives the onUserMuteVideo callback.",
        "parameters": [
            {
                "isFallbackOrRecover": "\n      \n true: The published stream falls back to audio-only due to poor network conditions.\n false: The published stream switches back to the video after the network conditions improve.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocaluserregistered",
        "name": "onLocalUserRegistered",
        "description": "Occusr when the local use registers a user account.Since\n  v2.8.0\n       \n   \n   After the local user successfully calls registerLocalUserAccount to register the user account or calls joinChannelWithUserAccount to join a channel, the SDK triggers the callback and informs the local user's UID and User Account.",
        "parameters": [
            {
                "uid": "The ID of the local user."
            },
            {
                "userAccount": "The user account of the local user."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalvideostatechanged",
        "name": "onLocalVideoStateChanged",
        "description": "Occurs when the local video stream state changes.Since\n                    v2.4.1\n                \n            \n            When the state of the local video stream changes (including the state of the video capture and encoding), the SDK triggers this callback to report the current state. This callback indicates the state of the local video stream, including camera capturing and video encoding, and allows you to troubleshoot issues when exceptions occur.\n            The SDK triggers the onLocalVideoStateChanged callback with the state code of LOCAL_VIDEO_STREAM_STATE_FAILED and error code of LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE in the following situations:\n                    The application exits to the background, and the system recycles the camera.\n                    The camera starts normally, but the captured video is not output for four seconds.\n                \n            \n            When the camera outputs the captured video frames, if all the video frames are the same for 15 consecutive frames, the SDK triggers the onLocalVideoStateChanged(LOCAL_VIDEO_STREAM_STATE_CAPTURING, LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE) callback. Note that the video frame duplication detection is only available for video frames with a resolution greater than 200 × 200, a frame rate greater than or equal to 10 fps, and a bitrate less than 20 Kbps.\n            For some device models, the SDK does not trigger this callback when the state of the local video changes while the local video capturing device is in use, so you have to make your own timeout judgment.",
        "parameters": [
            {
                "localVideoState": "The state of the local video, see LOCAL_VIDEO_STREAM_STATE."
            },
            {
                "error": "The detailed error information, see LOCAL_VIDEO_STREAM_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onlocalvideostats",
        "name": "onLocalVideoStats",
        "description": "Reports the statistics of the local video stream.The SDK triggers this callback once every two seconds to report the statistics of the local video stream.",
        "parameters": [
            {
                "stats": "The statistics of the local video stream. See LocalVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onmediaengineloadsuccess",
        "name": "onMediaEngineLoadSuccess",
        "description": "Occurs when the media engine loads.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onmediaenginestartcallsuccess",
        "name": "onMediaEngineStartCallSuccess",
        "description": "Occurs when the media engine call starts.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onmetadatareceived",
        "name": "onMetadataReceived",
        "description": "Occurs when the local user receives Metadata.",
        "parameters": [
            {
                "metadata": "The received Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onmicrophoneenabled",
        "name": "onMicrophoneEnabled",
        "description": "Occurs when the microphone is enabled/disabled.Deprecated:\n                    \n                        This callback is deprecated as of v2.9.0. Please use the onLocalAudioStateChanged callback:\n                                LOCAL_AUDIO_STREAM_STATE_STOPPED(0).\n                                LOCAL_AUDIO_STREAM_STATE_RECORDING(1).\n                            \n                    \n                \n            \n            The SDK triggers this callback when the local user resumes or stops capturing the local audio stream by calling the enableLocalAudio method.",
        "parameters": [
            {
                "enabled": "\n                        Whether the microphone is enabled/disabled:\n                                true: The microphone is enabled.\n                                false: The microphone is disabled.\n                            \n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onmixedaudioframe",
        "name": "onMixedAudioFrame",
        "description": "Retrieves the mixed captured and playback audio frame.This callback only returns the single-channel data.",
        "parameters": [
            {
                "audioFrame": "The audio frame. See AudioFrame."
            }
        ],
        "returns": "true: Valid buffer in AudioFrame, and the captured audio frame is sent out.\n       false: Invalid buffer in AudioFrame, and the captured audio frame is discarded."
    },
    {
        "id": "api_onnetworkquality",
        "name": "onNetworkQuality",
        "description": "Reports the last mile network quality of each user in the channel.This callback reports the last mile network conditions of each user in the channel. Last mile refers to the connection between the local device and Agora's edge server.\n   The SDK triggers this callback once every two seconds. If a channel includes multiple users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "uid": "The user ID. The network quality of the user with this user ID is reported. If uid is 0, the local network quality is reported."
            },
            {
                "txQuality": "Uplink network quality rating of the user in terms of the transmission bit rate, packet loss rate, average RTT (Round-Trip Time) and jitter of the uplink network. This parameter is a quality rating helping you understand how well the current uplink network conditions can support the selected video encoder configuration. For example, a 1000 Kbps uplink network may be adequate for video frames with a resolution of 640 × 480 and a frame rate of 15 fps in the LIVE_BROADCASTING profile, but may be inadequate for resolutions higher than 1280 × 720. See QUALITY_TYPE."
            },
            {
                "rxQuality": "Downlink network quality rating of the user in terms of packet loss rate, average RTT, and jitter of the downlink network. See QUALITY_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onnetworktypechanged",
        "name": "onNetworkTypeChanged",
        "description": "Occurs when the local network type changes.Since\n  v2.4.1\n       \n   \n   This callback occurs when the connection state of the local user changes. You can get the connection state and reason for the state change in this callback. When the network connection is interrupted, this callback indicates whether the interruption is caused by a network type change or poor network conditions.",
        "parameters": [
            {
                "type": "The type of the local network connection. See NETWORK_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onplaybackaudioframe",
        "name": "onPlaybackAudioFrame",
        "description": "Gtes the audio frame for playback.",
        "parameters": [
            {
                "audioFrame": "The audio frame. See AudioFrame."
            }
        ],
        "returns": "true: Valid buffer in AudioFrame, and the captured audio frame is sent out.\n       false: Invalid buffer in AudioFrame, and the captured audio frame is discarded."
    },
    {
        "id": "api_onplaybackaudioframebeforemixingex",
        "name": "onPlaybackAudioFrameBeforeMixingEx",
        "description": "Gets the before-mixing playback audio frame from multiple channels.After you successfully register the audio frame observer, if you set the return value of isMultipleChannelFrameWanted as true, the SDK triggers this callback each time it receives a audio frame from any of the channel.",
        "parameters": [
            {
                "channelId": "The channel name of this audio frame."
            },
            {
                "uid": "The ID of the user sending the audio frame."
            },
            {
                "audioFrame": "The audio frame. See AudioFrame."
            }
        ],
        "returns": "true: Valid buffer in AudioFrame, and the captured audio frame is sent out.\n       false: Invalid buffer in AudioFrame, and the captured audio frame is discarded."
    },
    {
        "id": "api_onplaybacksasudioframebeforemixing",
        "name": "onPlaybackAudioFrameBeforeMixing",
        "description": "Retrieves the audio frame of a specified user before mixing.",
        "parameters": [
            {
                "uid": "The user ID of the specified user."
            },
            {
                "audioFrame": "The audio frame. See AudioFrame."
            }
        ],
        "returns": "true: Valid buffer in AudioFrame, and the captured audio frame is sent out.\n       false: Invalid buffer in AudioFrame, and the captured audio frame is discarded."
    },
    {
        "id": "api_onpreencodevideoframe",
        "name": "onPreEncodeVideoFrame",
        "description": "Occurs each time the SDK receives a video frame before encoding.Since\n  v3.0.0\n       \n   \n   After you successfully register the video frame observer, the SDK triggers this callback each time when it receives a video frame. In this callback, you can get the video data before encoding and then process the data according to your particular scenarios.\n   After processing, you can send the processed video data back to the SDK in this callback.",
        "parameters": [
            {
                "videoFrame": "Video frame data, see VideoFrame for details."
            }
        ],
        "returns": "Whether to ignore the current video frame if the processing fails:\n  true: Do not ignore.\n  false: Ignore the current video frame, and do not send it back to the SDK."
    },
    {
        "id": "api_onreadytosendmetadata",
        "name": "onReadyToSendMetadata",
        "description": "Occurs when the SDK is ready to send Metadata.This callback is triggeredMetadata when the SDK is ready to receive and send .\n   Ensure that the size of theMetadata does not exceed thegetMaxMetadataSize value set in the callback.",
        "parameters": [
            {
                "metadata": "The to be sentMetadata."
            }
        ],
        "returns": "true: Send.\n       false: Do not send."
    },
    {
        "id": "api_onreceiveaudiopacket",
        "name": "onReceiveAudioPacket",
        "description": "Occurs when the local user receives an audio packet.",
        "parameters": [
            {
                "packet": "The received audio packet, see Packet."
            }
        ],
        "returns": "true: The audio packet is received successfully.\n       false: The audio packet is discarded."
    },
    {
        "id": "api_onreceivevideopacket",
        "name": "onReceiveVideoPacket",
        "description": "Occurs when the local user receives a video packet.",
        "parameters": [
            {
                "packet": "The received video packet, see Packet."
            }
        ],
        "returns": "true: The video packet is received successfully.\n       false: The video packet is discarded."
    },
    {
        "id": "api_onrecordaudioframe",
        "name": "onRecordAudioFrame",
        "description": "Gets the captured audio frame.",
        "parameters": [
            {
                "audioFrame": "The audio frame. See AudioFrame."
            }
        ],
        "returns": "true: Valid buffer in AudioFrame, and the captured audio frame is sent out.\n       false: Invalid buffer in AudioFrame, and the captured audio frame is discarded."
    },
    {
        "id": "api_onrejoinchannelsuccess",
        "name": "onRejoinChannelSuccess",
        "description": "Occurs when a user rejoins the channel.When a user loses connection with the server because of network problems, the SDK automatically tries to reconnect and triggers this callback upon reconnection.",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The ID of the user who rejoins the channel."
            },
            {
                "elapsed": "Time elapsed (ms) from starting to reconnect until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiomixingbegin",
        "name": "onRemoteAudioMixingBegin",
        "description": "Occurs when a remote user starts audio mixing.When a remote user calls startAudioMixing to play the background music, the SDK reports this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiomixingend",
        "name": "onRemoteAudioMixingEnd",
        "description": "Occurs when a remote user finishes audio mixing.The SDK triggers this callback when a remote user finishes audio mixing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiostatechanged",
        "name": "onRemoteAudioStateChanged",
        "description": "Occurs when the remote audio state changes.Since\n                        v2.9.0\n                    \n                \n               When the audio state of a remote user (in the voice/video call channel) or host (in the live streaming channel) changes, the SDK triggers this callback to report the current state of the remote audio stream.\n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose audio state changes."
            },
            {
                "state": "The state of the remote audio. See REMOTE_AUDIO_STATE."
            },
            {
                "reason": "The reason of the remote audio state change. See REMOTE_AUDIO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiostats",
        "name": "onRemoteAudioStats",
        "description": "Reports the statistics of the audio stream from each remote user/host.The SDK triggers this callback once every two seconds for each remote user who is sending audio streams. If a channel includes multiple remote users, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "The statistics of the received remote audio streams. See RemoteAudioStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremoteaudiotransportstats",
        "name": "onRemoteAudioTransportStats",
        "description": "Reports the transport-layer statistics of each remote audio stream.Deprecated:\n      This callback is deprecated, please use onRemoteAudioStats instead.\n  \n       \n   \n            This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives an audio packet from a remote user. During a call, when the user receives the audio packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the audio streams."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "Packet loss rate (%) of the audio packet sent from the sender to the receiver."
            },
            {
                "rxKBitrate": "Bitrate of the received audio (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotesubscribefallbacktoaudioonly",
        "name": "onRemoteSubscribeFallbackToAudioOnly",
        "description": "Occurs when the remote media stream falls back to audio-only stream due to poor network conditions or switches back to the video stream after the network conditions improve.If you call setRemoteSubscribeFallbackOption and set option as STREAM_FALLBACK_OPTION_AUDIO_ONLY, the SDK triggers this callback when the remote media stream falls back to audio-only mode due to poor uplink conditions, or when the remote media stream switches back to the video after the uplink network condition improves.\n   Once the remote media stream switches to the low stream due to poor network conditions, you can monitor the stream switch between a high and low stream in the RemoteVideoStats callback.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the stream."
            },
            {
                "isFallbackOrRecover": "\n      \n true: The remotely subscribed media stream falls back to audio-only due to poor network conditions.\n false: The remotely subscribed media stream switches back to the video stream after the network conditions improved.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideostatechanged",
        "name": "onRemoteVideoStateChanged",
        "description": "Occurs when the remote video state changes.Since\n                        v2.9.0\n                    \n                \n               This callback does not work properly when the number of users (in the voice/video call channel) or hosts (in the live streaming channel) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user whose video state changes."
            },
            {
                "state": "The state of the remote video, see REMOTE_VIDEO_STATE."
            },
            {
                "reason": "The reason for the remote video state change. See REMOTE_VIDEO_STATE_REASON."
            },
            {
                "elapsed": "Time elapsed (ms) from the local user calling the joinChannel method until the SDK triggers this callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideostats",
        "name": "onRemoteVideoStats",
        "description": "Reports the transport-layer statistics of each remote video stream.Reports the statistics of the video stream from the remote users. The SDK triggers this callback once every two seconds for each remote user. If a channel has multiple users/hosts sending video streams, the SDK triggers this callback as many times.",
        "parameters": [
            {
                "stats": "Statistics of the remote video stream. See RemoteVideoStats."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onremotevideotransportstats",
        "name": "onRemoteVideoTransportStats",
        "description": "Reports the transport-layer statistics of each remote video stream.Deprecated:\n  This callback is deprecated, please use onRemoteVideoStats instead.\n       \n   \n   This callback reports the transport-layer statistics, such as the packet loss rate and network time delay, once every two seconds after the local user receives a video packet from a remote user.\n   During a call, when the user receives the video packet sent by the remote user/host, the callback is triggered every 2 seconds.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the video packets."
            },
            {
                "delay": "The network delay (ms) from the sender to the receiver."
            },
            {
                "lost": "The packet loss rate (%) of the video packet sent from the remote user."
            },
            {
                "rxKBitRate": "The bitrate of the received video (Kbps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrendervideoframe",
        "name": "onRenderVideoFrame",
        "description": "Occurs each time the SDK receives a video frame sent by the remote user.Since\n  v3.0.0\n       \n   \n   After you successfully register the video frame observer, the SDK triggers this callback each time when it receives a video frame. In this callback, you can get the video data before encoding. You can then process the data according to your particular scenarios.\n   After processing, you can send the processed video data back to the SDK in this callback.\n   This callback does not support sending processed RGBA video data back to the SDK.",
        "parameters": [
            {
                "uid": "The ID of the remote user who sends the current video frame."
            },
            {
                "videoFrame": "Video frame data, see VideoFrame for details."
            }
        ],
        "returns": "Whether to ignore the current video frame if the processing fails:\n  true: Do not ignore.\n  false: Ignore the current video frame, and do not send it back to the SDK."
    },
    {
        "id": "api_onrendervideoframeex",
        "name": "onRenderVideoFrameEx",
        "description": "Gets the video frame from multiple channels.After you successfully register the video frame observer, if you set the return value of isMultipleChannelFrameWanted as true, the SDK triggers this callback each time it receives a video frame from any of the channel.\n   You can process the video data retrieved from this callback according to your scenario, and send the processed data back to the SDK using the videoFrame parameter in this callback.\n   This callback does not support sending RGBA video data back to the SDK.",
        "parameters": [
            {
                "channelId": "The channel ID of this video frame."
            },
            {
                "uid": "The ID of the user sending this video frame."
            },
            {
                "videoFrame": "VideoFrame"
            }
        ],
        "returns": "Whether to send this video frame to the SDK if post-processing fails:\n  true: Send.\n  false: Do not send."
    },
    {
        "id": "api_onrequesttoken",
        "name": "onRequestToken",
        "description": "Occurs when the token expires.When the token expires during a call, the SDK triggers this callback to remind the app to renew the token.\n   Once you receive this callback, generate a new token on your app server, and call joinChannel to rejoin the channel.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onrtcstats",
        "name": "onRtcStats",
        "description": "Reports the statistics of the current call.The SDK triggers this callback once every two seconds after the user joins the channel.",
        "parameters": [
            {
                "stats": "\n      Statistics of the RTC engine, see RtcStats for details.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrtmpstreamingevent",
        "name": "onRtmpStreamingEvent",
        "description": "Reports events during the RTMP or RTMPS streaming.Since\n  v3.1.0",
        "parameters": [
            {
                "url": "The RTMP or RTMPS streaming URL."
            },
            {
                "eventCode": "The event code of the streaming. See RTMP_STREAMING_EVENT."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onrtmpstreamingstatechanged",
        "name": "onRtmpStreamingStateChanged",
        "description": "Occurs when the state of the RTMP or RTMPS streaming changes.The SDK triggers this callback to report the result of the local user calling the addPublishStreamUrl or removePublishStreamUrl method. When the RTMP/RTMPS streaming status changes, the SDK triggers this callback and report the URL address and the current status of the streaming. This callback indicates the state of the RTMP or RTMPS streaming. When exceptions occur, you can troubleshoot issues by referring to the detailed error descriptions in the error code parameter.",
        "parameters": [
            {
                "url": "The CDN streaming URL."
            },
            {
                "state": "The RTMP or RTMPS streaming state. See RTMP_STREAM_PUBLISH_STATE. When the streaming status is RTMP_STREAM_PUBLISH_STATE_FAILURE (4), you can view the error information in the errorCode parameter."
            },
            {
                "errCode": "The detailed error information for streaming. See RTMP_STREAM_PUBLISH_ERROR."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onsendaudiopacket",
        "name": "onSendAudioPacket",
        "description": "Occurs when the local user sends an audio packet.",
        "parameters": [
            {
                "packet": "The sent audio packet, see Packet."
            }
        ],
        "returns": "true: The audio packet is sent successfully.\n       false: The audio packet is discarded."
    },
    {
        "id": "api_onsendvideopacket",
        "name": "onSendVideoPacket",
        "description": "Occurs when the local user sends a video packet.",
        "parameters": [
            {
                "packet": "The sent video packet, see Packet."
            }
        ],
        "returns": "true: The video packet is sent successfully.\n       false: The video packet is discarded."
    },
    {
        "id": "api_onstart",
        "name": "onStart",
        "description": "Notification for starting the custom video source.The SDK triggers this callback to remind you to start the custom video source for capturing video. The SDK uses IVideoFrameConsumer to receive the video frame that you capture after the video source is started. You must use the return value to tell the SDK whether the custom video source is started.",
        "parameters": [],
        "returns": "true: The custom video source is started.\n       false: The custom video source fails to start. The SDK stops and reports the error."
    },
    {
        "id": "api_onstreaminjectedstatus",
        "name": "onStreamInjectedStatus",
        "description": "Occurs when a media stream URL address is added to the interactive live streaming.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .",
        "parameters": [
            {
                "url": "The URL address of the externally injected stream."
            },
            {
                "uid": "The user ID."
            },
            {
                "status": "State of the externally injected stream. See INJECT_STREAM_STATUS."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreammessage",
        "name": "onStreamMessage",
        "description": "Occurs when the local user receives the data stream from the remote user within five seconds.The SDK triggers this callback when the local user receives the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "data": "The data received."
            },
            {
                "length": "The data length (byte)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreammessageerror",
        "name": "onStreamMessageError",
        "description": "Occurs when the local user does not receive the data stream from the remote user within five seconds.The SDK triggers this callback when the local user fails to receive the stream message that the remote user sends by calling the sendStreamMessage method.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the message."
            },
            {
                "streamId": "Stream ID of the received message."
            },
            {
                "code": "The error code. See Error Codes and Warning Codes."
            },
            {
                "missed": "The number of lost messages."
            },
            {
                "cached": "Number of incoming cached messages when the data stream is interrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreampublished",
        "name": "onStreamPublished",
        "description": "Occurs when an RTMP or RTMPS stream is published.Deprecated:\n  v3.0.0\n       \n   \n   This method is deprecated, please use onRtmpStreamingStateChanged instead.\n   Reports the result of publishing an RTMP or RTMPS stream.",
        "parameters": [
            {
                "url": "The CDN streaming URL."
            },
            {
                "error": "\n      ERROR_CODE_TYPE.\n     ERR_OK (0): The publishing succeeds.\n     ERR_FAILED (1): The publishing fails.\n     ERR_INVALID_ARGUMENT (-2): Invalid argument used. If you do not call setLiveTranscoding to configure LiveTranscoding before calling addPublishStreamUrl, the SDK reports ERR_INVALID_ARGUMENT.\n     ERR_TIMEDOUT (-10): The publishing timed out.\n     ERR_ALREADY_IN_USE (-19): The chosen URL address is alreadyin usefor CDN live streaming.\n     ERR_ENCRYPTED_STREAM_NOT_ALLOWED_PUBLISH (130): You cannot publish an encrypted stream.\n          ERR_PUBLISH_STREAM_CDN_ERROR (151): CDN related error. Remove the original URL address and add a new one by calling the removePublishStreamUrl and addPublishStreamUrl methods.\n          ERR_PUBLISH_STREAM_NUM_REACH_LIMIT (152): The host manipulates more than 10 URLs. Delete the unnecessary URLs before adding new ones.\n          ERR_PUBLISH_STREAM_NOT_AUTHORIZED (153): The host manipulates other hosts' URLs. Please check your app logic.\n     ERR_PUBLISH_STREAM_INTERNAL_SERVER_ERROR: An error occurs in Agora's streaming server. Call the removePublishStreamUrl method to publish the streaming again.\n     ERR_PUBLISH_STREAM_FORMAT_NOT_SUPPORTED (156): The format of the CDN streaming URL is not supported. Please check the format.\n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onstreamunpublished",
        "name": "onStreamUnpublished",
        "description": "Occurs when an RTMP or RTMPS stream is removed.Deprecated:\n  v3.0.0\n       \n   \n   This method is deprecated, please use onRtmpStreamingStateChanged instead.",
        "parameters": [
            {
                "url": "The URL of the removed RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ontokenprivilegewillexpire",
        "name": "onTokenPrivilegeWillExpire",
        "description": "Occurs when the token expires in 30 seconds.When the token is about to expire in 30 seconds, the SDK triggers this callback to remind the app to renew the token.\n   Upon receiving this callback, generate a new token on your server, and call renewToken to pass the new token to the SDK.",
        "parameters": [
            {
                "token": "The token that expires in 30 seconds."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_ontranscodingupdated",
        "name": "onTranscodingUpdated",
        "description": "Occurs when the publisher's transcoding is updated.When the LiveTranscoding class in the setLiveTranscoding method updates, the SDK triggers the onTranscodingUpdated callback to report the update information.\n   If you callsetLiveTranscoding the method to set the class for the first timeLiveTranscoding, the SDK does not trigger this callback.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onuploadlogresult",
        "name": "onUploadLogFile",
        "description": "Reports the result of uploading the SDK log files.Since\n  v3.3.0\n       \n   \n   After uploadLogFile is called, the SDK triggers the callback to report the result of uploading the SDK log files. If the upload fails, refer to the reason parameter to troubleshoot.",
        "parameters": [
            {
                "requestId": "The request ID. The request ID is the same as the requestId returned in uploadLogFile. You can associate specific uploads with callbacks through the requestId."
            },
            {
                "success": "Whether the log file is uploaded successfully:\n      true: Successfully upload the log files.\n      false: Fails to upload the log files. For details, see the reason parameter.\n  "
            },
            {
                "reason": "The reason for the upload failure. See UPLOAD_ERROR_REASON."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserenablelocalvideo",
        "name": "onUserEnableLocalVideo",
        "description": "Occurs when a specific remote user enables/disables the local video capturing function.The SDK triggers this callback when the remote user resumes or stops capturing the video stream by calling the enableLocalVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "Whether the specified remote user enables/disables the local video capturing function:\n true: Enable. Other users in the channel can see the video of this remote user.\n false: Disable. Other users in the channel can no longer receive the video stream from this remote user, while this remote user can still receive the video streams from other users.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserenablevideo",
        "name": "onUserEnableVideo",
        "description": "Occurs when a remote user enables/disables the video module.Once the video module is disabled, the user can only use a voice call. The user cannot send or receive any video.\n   The SDK triggers this callback when a remote user enables or disables the video module by calling the enableVideo or disableVideo method.",
        "parameters": [
            {
                "uid": "The user ID of the remote user."
            },
            {
                "enabled": "\n      \n true: Enable.\n false: Disable.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserinfoupdated",
        "name": "onUserInfoUpdated",
        "description": "Occurs when the SDK gets the user ID and user account of the remote user.Since\n  v2.8.0\n       \n   \n   After a remote user joins the channel, the SDK gets the UID and user account of the remote user, caches them in a mapping table object (userInfo), and triggers this callback on the local client.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userInfo": "The UserInfo object that contains the user ID and user account of the remote user. See UserInfo for details."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuserjoined",
        "name": "onUserJoined",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) joins the channel.In a communication channel, this callback indicates that a remote user joins the channel. The SDK also triggers this callback to report the existing users in the channel when a user joins the channel.\n   In a live-broadcast channel, this callback indicates that a host joins the channel. The SDK also triggers this callback to report the existing hosts in the channel when a host joins the channel. Agora recommends limiting the number of hosts to 17.\n        \n  The SDK triggers this callback under one of the following circumstances:\n  \n   A remote user/host joins the channel by calling the joinChannel method.\n   A remote user switches the user role to the host by calling the setClientRole method after joining the channel.\n   A remote user/host rejoins the channel after a network interruption.\n   The hostinjects an online media stream into the channel by calling the addInjectStreamUrl method.",
        "parameters": [
            {
                "uid": "The ID of the user or host who joins the channel."
            },
            {
                "elapsed": "Time delay (ms) from the local user calling joinChannel until this callback is triggered."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onusermuteaudio",
        "name": "onUserMuteAudio",
        "description": "Occurs when a remote user's audio stream playback pauses/resumes.The SDK triggers this callback when the remote user stops or resumes sending the audio stream by calling the muteLocalAudioStream method.\n   This callback does not work properly when the number of users (in the COMMUNICATION profile) or hosts (in the LIVE_BROADCASTING profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The user ID."
            },
            {
                "muted": "Whether the remote user's audio stream is muted/unmuted:\n      true: Muted.\n      false: Unmuted.\n  \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onusermutevideo",
        "name": "onUserMuteVideo",
        "description": "Occurs when a remote user's video stream playback pauses/resumes.The SDK triggers this callback when the remote user stops or resumes sending the video stream by calling the muteLocalVideoStream method.\n   This callback does not work properly when the number of users (in the COMMUNICATION profile) or hosts (in the LIVE_BROADCASTING profile) in the channel exceeds 17.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "muted": "Whether the remote user's video stream playback is paused/resumed:\n true: Paused.\n false: Resumed.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onuseroffline",
        "name": "onUserOffline",
        "description": "Occurs when a remote user (COMMUNICATION)/ host (LIVE_BROADCASTING) leaves the channel.There are two reasons for users to become offline:\n                    Leave the channel: When a user/host leaves the channel, the user/host sends a goodbye message. When this message is received, the SDK determines that the user/host leaves the channel.\n                    Drop offline: When no data packet of the user or host is received for a certain period of time (20 seconds for the communication profile, and more for the live broadcast profile), the SDK assumes that the user/host drops offline. A poor network connection may lead to false detections, so we recommend using the Agora RTM SDK for more reliable offline detection.",
        "parameters": [
            {
                "uid": "The ID of the user who leaves the channel or goes offline."
            },
            {
                "reason": "Reason why the user goes offline: USER_OFFLINE_REASON_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideodevicestatechanged",
        "name": "onVideoDeviceStateChanged",
        "description": "Occurs when the video device state changes.This callback reports the change of system video devices, such as being unplugged or removed. On a Windows device with an external camera for video capturing, the video disables once the external camera is unplugged.",
        "parameters": [
            {
                "deviceId": "The device ID."
            },
            {
                "deviceType": "Media device types. See MEDIA_DEVICE_TYPE."
            },
            {
                "deviceState": "Device state. See MEDIA_DEVICE_STATE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideopublishstatechanged",
        "name": "onVideoPublishStateChanged",
        "description": "Occurs when the video publishing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "oldState": "The previous publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "newState": "The current publishing state, see STREAM_PUBLISH_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideosizechanged",
        "name": "onVideoSizeChanged",
        "description": "Occurs when the video size or rotation of a specified user changes.",
        "parameters": [
            {
                "uid": "The ID of the user whose video size or rotation changes. uid is 0 for the local user."
            },
            {
                "width": "The width (pixels) of the video stream."
            },
            {
                "height": "The height (pixels) of the video stream."
            },
            {
                "rotation": "The rotation information. The value range is [0,360)."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onvideostopped",
        "name": "onVideoStopped",
        "description": "Occurs when the video stops playing.Deprecated:\n  Deprecated as of v2.4.1. Please use LOCAL_VIDEO_STREAM_STATE_STOPPED(0) in the onLocalVideoStateChanged callback instead.\n       \n   \n   The application can use this callback to change the configuration of the view (for example, displaying other pictures in the view) after the video stops playing.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_onvideosubscribestatechanged",
        "name": "onVideoSubscribeStateChanged",
        "description": "Occurs when the video subscribing state changes.Since\n  v3.1.0",
        "parameters": [
            {
                "channel": "The channel name."
            },
            {
                "uid": "The ID of the remote user."
            },
            {
                "oldState": "The previous subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "newState": "The current subscribing status, see STREAM_SUBSCRIBE_STATE for details."
            },
            {
                "elapseSinceLastState": "The time elapsed (ms) from the previous state to the current state."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_onwarning",
        "name": "onWarning",
        "description": "Reports a warning during SDK runtime.Occurs when a warning occurs during SDK runtime. In most cases, the app can ignore the warnings reported by the SDK because the SDK can usually fix the issue and resume running. For example, when losing connection with the server, the SDK may report WARN_LOOKUP_CHANNEL_TIMEOUT and automatically try to reconnect.",
        "parameters": [
            {
                "warn": "Warning code, see ."
            },
            {
                "msg": "Warning description."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_pausealleffects",
        "name": "pauseAllEffects",
        "description": "Pauses all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pauseaudiomixing",
        "name": "pauseAudioMixing",
        "description": "Pauses playing and mixing the music file.Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pauseeffect",
        "name": "pauseEffect",
        "description": "Pauses a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_playeffect1",
        "name": "playEffect[1/3]",
        "description": "This method plays the specified local or online audio effect file.To play multiple audio effect files at the same time, call this method multiple times with different soundId and filePath. For the best user experience, Agora recommends playing no more than three audio effect files at the same time. After the playback of an audio effect file completes, the SDK triggers the onAudioEffectFinished callback.Call this method after joining a channel.\n        \n                \n                    Deprecated:\n                    This method is deprecated as of v2.3.0, please use playEffect[3/3] instead.",
        "parameters": [
            {
                "gain": "The volume of the audio effect. The value range is 1 to10000. The default value is 100.0, which means the original volume. The smaller the value, the less the gain."
            },
            {
                "pan": "The spatial position of the audio effect. The value range is 1 to10000.\n               -1.0: The audio effect displays to the left.\n               0.0: The audio effect displays ahead.\n               1.0: The audio effect displays to the right.\n           \n  "
            },
            {
                "pitch": "The pitch of the audio effect. The value range is 0.5 to 2.0. The default value is 1.0, which means the original pitch. The lower the value, the lower the pitch."
            },
            {
                "loopCount": "The number of times the audio effect loops:\n          ≥ 0: The number of playback times. For example, 1 means loop one time, which means play the audio effect two times in total.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            },
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique.If you preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as soundId in preloadEffect.\n  "
            },
            {
                "filePath": "\n                        The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See .\n               "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_playeffect2",
        "name": "playEffect[2/3]",
        "description": "This method plays the specified local or online audio effect file.To play multiple audio effect files at the same time, call this method multiple times with different soundId and filePath. For the best user experience, Agora recommends playing no more than three audio effect files at the same time. After the playback of an audio effect file completes, the SDK triggers the onAudioEffectFinished callback.Call this method after joining a channel.\n        \n                \n                    Deprecated:\n                    This method is deprecated as of v3.4.0. Use playEffect[3/3] instead.",
        "parameters": [
            {
                "publish": "Whether to publish the audio effect to the remote users.\n          true: Publish the audio effect to the remote users. Both the local user and remote users can hear the audio effect.\n          false: Do not publish the audio effect to the remote users. Only the local user can hear the audio effect.\n      \n  "
            },
            {
                "gain": "The volume of the audio effect. The value range is 1 to10000. The default value is 100.0, which means the original volume. The smaller the value, the less the gain."
            },
            {
                "pan": "The spatial position of the audio effect. The value range is 1 to10000.\n               -1.0: The audio effect displays to the left.\n               0.0: The audio effect displays ahead.\n               1.0: The audio effect displays to the right.\n           \n  "
            },
            {
                "pitch": "The pitch of the audio effect. The value range is 0.5 to 2.0. The default value is 1.0, which means the original pitch. The lower the value, the lower the pitch."
            },
            {
                "loopCount": "The number of times the audio effect loops:\n          ≥ 0: The number of playback times. For example, 1 means loop one time, which means play the audio effect two times in total.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            },
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique.If you preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as soundId in preloadEffect.\n  "
            },
            {
                "filePath": "\n                        The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See .\n               "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_playeffect3",
        "name": "playEffect[3/3]",
        "description": "This method plays the specified local or online audio effect file.Since\n                    v3.4.0\n                \n            \n            To play multiple audio effect files at the same time, call this method multiple times with different soundId and filePath. For the best user experience, Agora recommends playing no more than three audio effect files at the same time. After the playback of an audio effect file completes, the SDK triggers the onAudioEffectFinished callback.Call this method after joining a channel.",
        "parameters": [
            {
                "soundId": "The audio effect ID. The ID of each audio effect file is unique.If you preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as soundId in preloadEffect.\n  "
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See .\n               If you preloaded an audio effect into memory by calling preloadEffect, ensure that this parameter is set to the same value as filePath in preloadEffect.\n           "
            },
            {
                "loopCount": "The number of times the audio effect loops:\n          ≥ 0: The number of playback times. For example, 1 means loop one time, which means play the audio effect two times in total.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            },
            {
                "pitch": "The pitch of the audio effect. The value range is 0.5 to 2.0. The default value is 1.0, which means the original pitch. The lower the value, the lower the pitch."
            },
            {
                "pan": "The spatial position of the audio effect. The value range is 1 to10000.\n               -1.0: The audio effect displays to the left.\n               0.0: The audio effect displays ahead.\n               1.0: The audio effect displays to the right.\n           \n  "
            },
            {
                "gain": "The volume of the audio effect. The value range is 1 to10000. The default value is 100.0, which means the original volume. The smaller the value, the less the gain."
            },
            {
                "publish": "Whether to publish the audio effect to the remote users.\n          true: Publish the audio effect to the remote users. Both the local user and remote users can hear the audio effect.\n          false: Do not publish the audio effect to the remote users. Only the local user can hear the audio effect.\n      \n  "
            },
            {
                "startPos": "\n                        The playback position (ms) of the audio effect file.\n                    "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_preloadeffect",
        "name": "preloadEffect",
        "description": "Preloads a specified audio effect file into the memory.To ensure smooth communication, limit the size of the audio effect file. We recommendjoinChannel using this method to preload the audio effect before calling the method. Supported audio formats: mp3, aac, m4a, 3gp, and wav.\n            This method does not support online audio effect files.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            },
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See .\n               "
            }
        ],
        "returns": "0: Success.\n  < 0: Failure."
    },
    {
        "id": "api_pullaudioframe",
        "name": "pullAudioFrame",
        "description": "Pulls the remote audio data.Before calling this method, call the setExternalAudioSink (enabled:true) method to notify the app to enable and set the external audio sink.\n   After a successful method call, the app pulls the decoded and mixed audio data for playback.\n   \n       \n  After a successful call of this method, the app will not get any audio data from the onPlaybackAudioFrame callback.\n  The difference between this method and theonPlaybackAudioFrame callback is as follows:\n onPlaybackAudioFrame: The SDK sends the audio data to the app through this callback. Any delay in processing the audio frames may result in audio jitter.\n pullAudioFrame: The app pulls the remote audio data. After setting the audio data parameters, the SDK adjusts the frame buffer and avoids problems caused by jitter in the external audio playback.",
        "parameters": [
            {
                "frame": "\n      Pointers toAudioFrame .\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pushaudioframe1",
        "name": "pushAudioFrame[1/2]",
        "description": "Pushes the external audio frame.Deprecated:\n  Use pushAudioFrame[2/2] instead.",
        "parameters": [
            {
                "type": "\n      The type of the audio capturing device. See MEDIA_SOURCE_TYPE.\n  "
            },
            {
                "frame": "Pointers to the audio frame. See AudioFrame."
            },
            {
                "wrap": "\n      Whether to use the placeholder. Agora recommends setting the default value.\n     true: Use the placeholder.\n     false: (Default) Do not use the placeholder.\n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pushaudioframe2",
        "name": "pushAudioFrame[2/2]",
        "description": "Pushes the external audio frame.",
        "parameters": [
            {
                "frame": "\n      Pointers to the audio frame. See AudioFrame.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_pushvideoframe",
        "name": "pushVideoFrame",
        "description": "PushesExternalVideoFrame the video frame using and passes the video frame to the Agora SDK.In the communication profile, this method does not support video frames in the Texture format.",
        "parameters": [
            {
                "frame": "\n      Video frames to be pushed. See ExternalVideoFrame.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_queryinterface",
        "name": "queryInterface",
        "description": "Gets the pointer to the device manager object.",
        "parameters": [
            {
                "iid": "The ID of the interface. See INTERFACE_ID_TYPE."
            },
            {
                "inter": "Output parameter. The pointer to the interface."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_rate",
        "name": "rate",
        "description": "Allows a user to rate a call after the call ends.Ensure that you call this method after joining a channel.",
        "parameters": [
            {
                "callId": "The current call ID. You can get the call ID by calling getCallId."
            },
            {
                "rating": "The rating of the call. The value is between 1 (lowest score) and 5 (highest score). If you set a value out of this range, the SDK returns the ERR_INVALID_ARGUMENT(2) error."
            },
            {
                "description": "(Optional) A description of the call. The string length should be less than 800 bytes."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -2 (ERR_INVALID_ARGUMENT).\n  -3(ERR_NOT_READY())."
    },
    {
        "id": "api_registeraudioframeobserver",
        "name": "registerAudioFrameObserver",
        "description": "Registers an audio frame observer object.Call this method to register an audio frame observer object (register a callback). When you need the SDK to trigger onRecordAudioFrame oronPlaybackAudioFrame callback, you need to use this method to register the callbacks.\n   Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "observer": "\n      The observer object instance. See IAudioFrameObserver. Set the value as NULL to release the observer object. Agora recommends releasing the observer object after receiving the onLeaveChannel callback.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_registerlocaluseraccount",
        "name": "registerLocalUserAccount",
        "description": "Registers a user account.Since\n  v2.8.0\n       \n   \n   Once registered, the user account can be used to identify the local user when the user joins the channel. After the registration is successful, the user account can identify the identity of the local user, and the user can use it to join the channel.\n   After the user successfully registers a user account, the SDK triggers the onLocalUserRegistered callback on the local client, reporting the user ID and user account of the local user.\n   This method is optional. To join a channel with a user account, you can choose either of the following ways:\n       First call registerLocalUserAccount to register the Account, and then call joinChannelWithUserAccount to join the channel.\n       Call the joinChannelWithUserAccount method to join the channel.\n   \n   The difference between the two ways is that the time elapsed between calling the registerLocalUserAccount method and joining the channel is shorter than directly calling joinChannelWithUserAccount.\n   \n       \n  Ensure that you set the userAccount parameter. Otherwise, this method does not take effect.\n  Ensure that the user account is unique in the channel.\n  To ensure smooth communication, use the same parameter type to identify the user. For example, if a user joins the channel with a user ID, then ensure all the other users use the user ID too. The same applies to the user account. If a user joins the channel with the Agora Web SDK, ensure that the uid of the user is set to the same parameter type.",
        "parameters": [
            {
                "appId": "The App ID of your Agora project."
            },
            {
                "userAccount": "The user account. This parameter is used to identify the user in the channel for real-time audio and video interaction. You need to set and manage user accounts yourself and ensure that each user account in the same channel is unique. The maximum length of this parameter is 255 bytes. Ensure that you set this parameter and do not set it as nullNULL. Supported characters are (89 in total):\n      The 26 lowercase English letters: a to z.\n      The 26 uppercase English letters: A to Z.\n      All numeric characters: 0 to 9.\n      Space\n      \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_registermediametadataobserver",
        "name": "registerMediaMetadataObserver",
        "description": "Registers the metadata observer.Since\n  v2.4.1\n       \n   \n   \n       \n  \n      Call this method before joinChannel.\n      This method applies only to interactive live streaming.",
        "parameters": [
            {
                "observer": "Pointers to the registered metadata observer. See IMetadataObserver."
            },
            {
                "type": "The type of the metadata. The SDK currently only supports VIDEO_METADATA. See METADATA_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_registerpacketobserver",
        "name": "registerPacketObserver",
        "description": "Registers a packet observer.Call this method registers a packet observer. When the Agora SDK triggers callbacks registered by for voice or video packet transmission, youIPacketObserver can call this method to process the packets, such as encryption and decryption.\n   \n       \n  The size of the packet sent to the network after processing should not exceed 1200 bytes, otherwise, the SDK may fail to send the packet.\n  Ensure that both receivers and senders call this method, otherwise, you may meet undefined behaviors such as no voice and black screen.\n  When you use CDN live streaming, recording, or storage functions, Agora doesn't recommend calling this method.\n  Call this method before joining a channel.",
        "parameters": [
            {
                "observer": "IPacketObserver 。"
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_registervideoframeobserver",
        "name": "registerVideoFrameObserver",
        "description": "Registers a video frame observer object.You need to implement the IVideoFrameObserver class in this method and register callbacks according to your scenarios. After you successfully register the video frame observer, the SDK triggers the registered callbacks each time a video frame is received.\n   \n       \n  When handling the video data returned in the callbacks, pay attention to the changes in the width and height parameters, which may be adapted under the following circumstances:\n When the network condition deteriorates, the video resolution decreases incrementally.\n If the user adjusts the video profile, the resolution of the video returned in the callbacks also changes.\n      \n  Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "observer": "\n      The observer object instance. Set the value as NULL to release the instance. See IVideoFrameObserver.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_release",
        "name": "release",
        "description": "Releases the IRtcEngine instance.This method releases all resources used by the Agora SDK. Use this method for apps in which users occasionally make voice or video calls. When users do not make calls, you can free up resources for other operations.\n   After a successful method call, you cannot use any method or callback in the SDK anymore. If you want to use the real-time communication functions again, you must call initialize to create a new IRtcEngine instance.\n   If you want to create a new `IRtcEngineIRtcEngine` instancerelease after destroying the current one, ensure that you wait till the `release` method completes executing.",
        "parameters": [
            {
                "sync": "\n      \n true: Synchronous call. Agora suggests calling this method in a sub-thread to avoid congestion in the main thread because the synchronous call and the app cannot move on to another task until the resources used by IRtcEngine are released. Besides, you cannot call release in any method or callback of the SDK. Otherwise, the SDK cannot release the resources until the callbacks return results, which may result in a deadlock. The SDK automatically detects the deadlock and converts this method into an asynchronous call, causing the test to take additional time.\n          false: Asynchronous call. The app can move on to another task, no matter the resources used by IRtcEngine are released or not. Do not immediately uninstall the SDK's dynamic library after the call, or it may cause a crash due to the SDK clean-up thread not quitting.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "api_removehandler",
        "name": "removeHandler",
        "description": "Removes the specified callback handler.Since\n  v2.9.1\n       \n   \n   This method removes the specified callback handler. For callback events that you want to listen for only once, call this method to remove the relevant callback handler after you have received them.",
        "parameters": [
            {
                "handler": "The callback handler to be deleted. See IRtcEngineEventHandler."
            }
        ],
        "returns": ""
    },
    {
        "id": "api_removeinjectstreamurl",
        "name": "removeInjectStreamUrl",
        "description": "Removes the voice or video stream URL address from the live streaming.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .\n   After a successful method, the SDK triggers theonUserOffline callback with the uid of 666.",
        "parameters": [
            {
                "url": "The URL address of the injected stream to be removed."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_removepublishstreamurl",
        "name": "removePublishStreamUrl",
        "description": "Removes an RTMP or RTMPS stream from the CDN.After a successful method call, the SDK triggers onRtmpStreamingStateChanged on the local client to report the result of deleting the address.\n   \n       \n           Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in Push Streams to CDN.\n           This method takes effect only when you are a host in live interactive streaming.\n           Call this method after joining a channel.\n           This method removes only one CDN streaming URL each time it is called. To remove multiple URLs, call this method multiple times.",
        "parameters": [
            {
                "url": "The CDN streaming URL to be removed. The maximum length of this parameter is 1024 bytes. The CDN streaming URL must not contain special characters, such as Chinese language characters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_renewtoken",
        "name": "renewToken",
        "description": "Gets a new token when the current token expires after a period of time.Passes a new token to the SDK. A token expires after a certain period of time. In the following two cases, the app should call this method to pass in a new token. Failure to do so will result in the SDK disconnecting from the server.\n       The SDK triggers the onTokenPrivilegeWillExpire callback.\n       The onConnectionStateChanged callback reports CONNECTION_CHANGED_TOKEN_EXPIRED(9).",
        "parameters": [
            {
                "token": "The new token."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_resumealleffects",
        "name": "resumeAllEffects",
        "description": "Resumes playing all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_resumeaudiomixing",
        "name": "resumeAudioMixing",
        "description": "Resumes playing and mixing the music file.This method resumes playing and mixing the music file. Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_resumeeffect",
        "name": "resumeEffect",
        "description": "Resumes playing a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_sendcustomreportmessage",
        "name": "sendCustomReportMessage",
        "description": "Agora supports reporting and analyzing customized messages.Since\n  v3.1.0\n       \n   \n   This function is in the beta stage with a free trial. The ability provided in its beta test version is reporting a maximum of 10 message pieces within 6 seconds, with each message piece not exceeding 256 bytes and each string not exceeding 100 bytes. To try out this function, contact support@agora.io and discuss the format of customized messages with us.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "api_sendstreammessage",
        "name": "sendStreamMessage",
        "description": "Sends data stream messages.Sends data stream messages to all users in a channel. The SDK has the following restrictions on this method:Up to 30 packets can be sent per second in a channel with each packet having a maximum size of 1 KB.Each client can send up to 6 KB of data per second.Each user can have up to five data streams simultaneously.\n   A successful method call triggers the onStreamMessage callback on the remote client, from which the remote user gets the stream message. A failed method call triggers the onStreamMessageError callback on the remote client.\n   \n       Ensure that you call createDataStream to create a data channel before calling this method.\n       In live broadcast streaming, this method only applies to hosts.",
        "parameters": [
            {
                "streamId": "The data stream ID. You can get the data stream ID by calling createDataStream."
            },
            {
                "data": "The custom data."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setapplicationmute",
        "name": "setApplicationMute",
        "description": "Mutes the app.",
        "parameters": [
            {
                "mute": "Whether to mute the app.\n      true: Mute the app.\n      false: Do not mute the app.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setapplicationvolume",
        "name": "setApplicationVolume",
        "description": "Sets the volume of the app.",
        "parameters": [
            {
                "volume": "The application volume. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudioeffectparameters",
        "name": "setAudioEffectParameters",
        "description": "Sets parameters for SDK preset audio effects.Since\n  v3.2.0\n       \n   \n   Call this method to set the following parameters for the local user who sends an audio stream:\n  3D voice effect: Sets the cycle period of the 3D voice effect.\n  Pitch correction effect: Sets the basic mode and tonic pitch of the pitch correction effect. Different songs have different modes and tonic pitches. Agora recommends bounding this method with interface elements to enable users to adjust the pitch correction interactively.\n       \n   \n   After setting the audio parameters, all users in the channel can hear the effect.\n   \n       \n  You can call this method either before or after joining a channel.\n  To get better audio effect quality, Agora recommends calling setAudioProfile and setting the scenario parameter as AUDIO_SCENARIO_GAME_STREAMING before calling this method.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT(6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setAudioEffectParameters, Agora recommends not calling the following methods, because they can override setAudioEffectParameters:\n setAudioEffectPreset\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for the preset audio effect.\n 3D voice effect:ROOM_ACOUSTICS_3D_VOICE\nCall and set the setAudioProfileprofile parameter toAUDIO_PROFILE_MUSIC_STANDARD_STEREO (3) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before setting this enumerator; otherwise, the enumerator setting does not take effect.\nIf the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n     \n \n Pitch correction effect: PITCH_CORRECTION. To achieve better audio effect quality, Agora recommends calling and setting the setAudioProfileprofile parameter toAUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before setting this enumerator.\n      \n  "
            },
            {
                "param1": "\n      \n If you set preset toROOM_ACOUSTICS_3D_VOICE , param1 sets the cycle period of the 3D voice effect. The value range is [1,60] and the unit is a second. The default value is 10 seconds, indicating that the voice moves around you every 10 seconds.\n If you set preset toPITCH_CORRECTION , param1 sets the basic mode of the pitch correction effect:\n1: (Default) Natural major scale.\n2: Natural minor scale.\n3: Japanese pentatonic scale.\n     \n \n      \n  "
            },
            {
                "param2": "\n      \n If you set preset toROOM_ACOUSTICS_3D_VOICE , you need to set param2 to 0.\n If you set preset toPITCH_CORRECTION , param2 sets the tonic pitch of the pitch correction effect:\n1: A\n2: A#\n3: B\n4: (Default) C\n5: C#\n6: D\n7: D#\n8: E\n9: F\n10: F#\n11: G\n12: G#\n     \n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudioeffectpreset",
        "name": "setAudioEffectPreset",
        "description": "Sets an SDK preset audio effect.Since\n  v3.2.0\n       \n   \n   Call this method to set an SDK preset audio effect for the local user who sends an audio stream. This audio effect does not change the gender characteristics of the original voice. After setting an audio effect, all users in the channel can hear the effect.\n   You can set different audio effects for different scenarios. See Set the Voice Beautifier and Audio Effects.\n   To get better audio effect quality, Agora recommends calling setAudioProfile and setting the scenario parameter as AUDIO_SCENARIO_GAME_STREAMING before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT(6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  If you call setAudioEffectPreset and set the preset parameter to enumerators except for ROOM_ACOUSTICS_3D_VOICE or PITCH_CORRECTION, do not call setAudioEffectParameters; otherwise, setAudioEffectPreset is overridden.\n  After calling setAudioEffectPreset, Agora recommends not calling the following methods, because they can override setAudioEffectPreset:\n         setVoiceBeautifierPreset\n         setLocalVoiceReverbPreset\n         setLocalVoiceChanger\n         setLocalVoicePitch\n         setLocalVoiceEqualization\n         setLocalVoiceReverb\n         setVoiceBeautifierParameters\n         setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for SDK preset audio effects. SeeAUDIO_EFFECT_PRESET."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudiomixingpitch",
        "name": "setAudioMixingPitch",
        "description": "Sets the pitch of the local music file.Since\n  v3.0.1\n       \n   \n   When a local music file is mixed with a local human voice, call this method to set the pitch of the local music file only.\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "pitch": "Sets the pitch of the local music file by the chromatic scale. The default value is 0, which means keeping the original pitch. The value ranges from -12 to 12, and the pitch value between consecutive values is a chromatic value. The greater the absolute value of this parameter, the higher or lower the pitch of the local music file."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudiomixingposition",
        "name": "setAudioMixingPosition",
        "description": "Sets the audio mixing position.Call this method to set the playback position of the music file to a different starting position (the default plays from the beginning).\n            You need to call this method after calling startAudioMixing and receiving the onAudioMixingStateChanged(PLAY) callback.",
        "parameters": [
            {
                "pos": "Integer. The playback position (ms)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setaudioprofile",
        "name": "setAudioProfile",
        "description": "Sets the audio parameters and application scenarios.This method needs to bejoinChannel set before . If you call this method after ,joinChannel the settings do not take effect.\n  In the COMMUNICATION and LIVE_BROADCASTING profiles, the bitrate may be different from your settings due to network self-adaptation.\n  In scenes requiring high-quality audio, such as online music tutoring, Agora recommends you set profile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) and scenario as AUDIO_SCENARIO_GAME_STREAMING(3).",
        "parameters": [
            {
                "profile": "\n      The sample rate, bitrate, encoding mode, and the number of channels. See AUDIO_PROFILE_TYPE.\n  "
            },
            {
                "scenario": "The audio application scenario. SeeAUDIO_SCENARIO_TYPE . Under different audio scenarios, the device uses different volume types. For details, see ."
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setaudiosessionoperationrestriction",
        "name": "setAudioSessionOperationRestriction",
        "description": "Sets the operational permission of the SDK on the audio session.The SDK and the app can both configure the audio session by default. If you need to only use the app to configure the audio session, this method restricts the operational permission of the SDK on the audio session.\n   You can call this method either before or after joining a channel. Once you call this method to restrict the operational permission of the SDK on the audio session, the restriction takes effect when the SDK needs to change the audio session.\n   \n       This method does not restrict the operational permission of the app on the audio session.",
        "parameters": [
            {
                "restriction": "The operational permission of the SDK on the audio session. See AUDIO_SESSION_OPERATION_RESTRICTION. This parameter is in bit mask format, and each bit corresponds to a permission."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setbeautyeffectoptions",
        "name": "setBeautyEffectOptions",
        "description": "Sets the image enhancement options.Since\n  v2.4.0\n  \n   \n   Enables or disables image enhancement and sets the options.\n   Call this method after enableVideo.",
        "parameters": [
            {
                "enabled": "Whether to enable the image enhancement function:\n      true: Enable the image enhancement function.\n      false: (Default) Disable the image enhancement function.\n  "
            },
            {
                "options": "The image enhancement options. See BeautyOptions."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameraautofocusfacemodeenabled",
        "name": "setCameraAutoFocusFaceModeEnabled",
        "description": "Enables the camera auto-face focus function.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [
            {
                "enabled": "Whether to enable the camera auto-face focus function:\n      true: Enable the camera auto-face focus function.\n      false: (Default) Disable the camera auto-face focus function.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameracapturerconfiguration",
        "name": "setCameraCapturerConfiguration",
        "description": "Sets the camera capture configuration.For a video call or the interactive live video streaming, generally the SDK controls the camera output parameters. When the default camera capturer settings do not meet special requirements or cause performance problems, we recommend using this method to set the camera capturer configuration:\n                    If the resolution or frame rate of the captured raw video data are higher than those set by setVideoEncoderConfiguration, processing video frames requires extra CPU and RAM usage and degrades performance. Agora recommends setting the camera capture configuration to CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE(1) to avoid such problems.\n                    If you do not need a local video preview or are willing to sacrifice preview quality, we recommend setting config as CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE(1) to optimize CPU and RAM usage.\n                    If you want better quality for the local video preview, we recommend setting config as CAPTURER_OUTPUT_PREFERENCE_PREVIEW(2).\n                    To customize the width and height of the video image captured by the local camera, set the camera capture configuration as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3).\n                \n            \n   Call this method before enabling the local camera. That said, you can call this method before calling joinChannel, enableVideo, or enableLocalVideo, depending on which method you use to turn on your local camera.",
        "parameters": [
            {
                "config": "The camera capturer configuration. See CameraCapturerConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameraexposureposition",
        "name": "setCameraExposurePosition",
        "description": "Sets the camera exposure position.Since\n  v2.3.2\n       \n   \n   This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).\n   After a successful method call, the SDK triggers the onCameraExposureAreaChanged callback.",
        "parameters": [
            {
                "positionXinView": "The horizontal coordinate of the touchpoint in the view."
            },
            {
                "positionYinView": "The vertical coordinate of the touchpoint in the view."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcamerafocuspositioninpreview",
        "name": "setCameraFocusPositionInPreview",
        "description": "Sets the camera manual focus position.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel). After a successful method call, the SDK triggers the onCameraFocusAreaChanged callback.",
        "parameters": [
            {
                "positionX": "The horizontal coordinate of the touchpoint in the view."
            },
            {
                "positionY": "The vertical coordinate of the touchpoint in the view."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setcameratorchon",
        "name": "setCameraTorchOn",
        "description": "Enables the camera flash.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [
            {
                "isOn": "Whether to turn on the camera flash:\n      true: Turn on the flash.\n      false: (Default) Turn off the flash.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0 : Failure."
    },
    {
        "id": "api_setcamerazoomfactor",
        "name": "setCameraZoomFactor",
        "description": "Sets the camera capture configuration.This method needs to be called after the camera is started (for example, bystartPreview calling orjoinChannel realization).",
        "parameters": [
            {
                "factor": "Camera zoom ratio, the effective range is from 1.0 to the maximum zoom ratio. You cangetCameraMaxZoomFactor get the maximum zoom ratio supported by the device through the method."
            }
        ],
        "returns": "Method call succeeded: Return the set factor value.\n       Method call failed: return value < 0."
    },
    {
        "id": "api_setchannelprofile",
        "name": "setChannelProfile",
        "description": "Set the channel profile.Sets the profile of the Agora channel. The Agora SDK differentiates channel profiles and applies optimization algorithms accordingly. For example, it prioritizes smoothness and low latency for a video call and prioritizes video quality for interactive live video streaming.\n   \n       \n  To ensure the quality of real-time communication, Agora recommends that all users in a channel use the same channel profile.\n  This method must be called and set before joinChannel, and cannot be set again after entering the channel.\n  The default audio route and video encoding bitrate are different in different channel profiles. For details, see setDefaultAudioRouteToSpeakerphone and setVideoEncoderConfiguration.",
        "parameters": [
            {
                "profile": "\n      The channel profile. See CHANNEL_PROFILE_TYPE.\n      "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n      -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setclientrole1",
        "name": "setClientRole[1/2]",
        "description": "Sets the user role in live interactive streaming.You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:The local client: onClientRoleChanged.The remote client: onUserJoined or onUserOffline(USER_OFFLINE_BECOME_AUDIENCE).\n   This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).",
        "parameters": [
            {
                "role": "\n      The user role in the interactive live streaming. See CLIENT_ROLE_TYPE.\n  "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n      -1(ERR_FAILED): A general error occurs (no specified reason).\n -2(ERR_INALID_ARGUMENT): The parameter is invalid.\n -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setclientrole2",
        "name": "setClientRole[2/2]",
        "description": "Sets the user role and level in a live interactive streaming.Since\n  v3.2.0\n       \n   \n   You can call this method either before or after joining the channel to set the user role as audience or host.\n   If you call this method to switch the user role after joining the channel, the SDK triggers the following callbacks:\n      The local client: onClientRoleChanged.\n      The remote client: onUserJoined oronUserOffline.\n   \n   The difference between this method and setClientRole [1/2] is that this method can set the user level in addition to the user role.\n      The user role determines the permissions that the SDK grants to a user, such as permission to send local streams, receive remote streams, and push streams to a CDN address.\n      The user level determines the level of services that a user can enjoy within the permissions of the user's role. For example, an audience can choose to receive remote streams with low latency or ultra-low latency. Levels affect prices.\n    \n   This method only takes effect when the channel profile is live interactive streaming (when the profile parameter in setChannelProfile set as CHANNEL_PROFILE_LIVE_BROADCASTING).",
        "parameters": [
            {
                "role": "The user role in a live interactive streaming. See CLIENT_ROLE_TYPE."
            },
            {
                "options": "The detailed options of a user, including the user level. See ClientRoleOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setcloudproxy",
        "name": "setCloudProxy",
        "description": "Sets the Agora cloud proxy service.Since\n                    3.3.0\n                \n            \n            When the user's firewall restricts the IP address and port, refer to Use Cloud Proxy to add the specific IP addresses and ports to the firewall whitelist; then, call this method to enable the cloud proxy and set the cloud proxyType as UDP_PROXY.\n            After successfully connecting to the cloud proxy, the SDK triggers theonConnectionStateChanged (CONNECTION_STATE_CONNECTING,CONNECTION_CHANGED_SETTING_PROXY_SERVER) callback.\n            To disable the cloud proxy that has been set, call setCloudProxy(NONE_PROXY).\n            To change the cloud proxy type that has been set, call setCloudProxy(NONE_PROXY) first, and then call setCloudProxy and pass the value that you expect in proxyType.\n            \n                \n                    Agora recommends that you call this method before joining the channel or after leaving the channel.\n                    When you use the cloud proxy for the UDP protocol, the services for pushing streams to CDN and co-hosting across channels are not available.",
        "parameters": [
            {
                "proxyType": "The type of the cloud proxy. SeeCLOUD_PROXY_TYPE . This parameter is required. The SDK reports an error if you do not pass in a value."
            }
        ],
        "returns": "0: Success.\n                \n                    < 0: Failure.\n                        -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n                        -7(ERR_NOT_INITIALIZED): The SDK is not initialized."
    },
    {
        "id": "api_setdefaultaudioroutetospeakerphone",
        "name": "setDefaultAudioRouteToSpeakerphone",
        "description": "Sets the default audio playback route.This method sets whether the received audio is routed to the earpiece or speakerphone by default before joining a channel. If a user does not call this method, the audio is routed to the earpiece by default.\n            The default settings for each profile:\n                    For the communication profile:\n                            In a voice call, the default audio route is the earpiece.\n                            In a video call, the default audio route is the speakerphone. If a user calls the disableVideo, muteLocalVideoStream, or muteAllRemoteVideoStreams method, the default audio route switches back to the earpiece automatically.\n                        \n                    For the live broadcasting profile: Speakerphone.\n                \n            \n            \n                \n                    This method is for iOS only.\n                    This method needs to be set before joinChannel, otherwise, it will not take effect.",
        "parameters": [
            {
                "defaultToSpeaker": "The default audio playback route.\n                            true: Route the audio to the speakerphone. If the playback device connects to the earpiece or Bluetooth, the audio cannot be routed to the speakerphone.\n                            false: (Default) Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n                        \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setdefaultmuteallremoteaudiostreams",
        "name": "setDefaultMuteAllRemoteAudioStreams",
        "description": "Stops or resumes subscribing to the audio streams of all remote users by default.Deprecated:\n  This method is deprecated as of v3.3.0.\n       \n   \n   Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n   \n       If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:\n       \n  If you need to resume subscribing to the audio stream of a specified user, call muteRemoteAudioStream (false), and specify the user ID.\n  If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteAudioStream(false) multiple times.",
        "parameters": [
            {
                "mute": "Whether to stop subscribing to the audio streams of all remote users by default.\n true: Stop subscribing to the audio streams of all remote users by default.\n false: (Default) Subscribe to the audio streams of all remote users by default.\n      \n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setdefaultmuteallremotevideostreams",
        "name": "setDefaultMuteAllRemoteVideoStreams",
        "description": "Stops or resumes subscribing to the video streams of all remote users by default.Deprecated:\n           This method is deprecated as of v3.3.0.\n       \n   \n            Call this method after joining a channel. After successfully calling this method, the local user stops or resumes subscribing to the audio streams of all subsequent users.\n            If you need to resume subscribing to the audio streams of remote users in the channel after calling this method, do the following:If you need to resume subscribing to the audio stream of a specified user, call muteRemoteVideoStream(false), and specify the user ID.\n                    If you need to resume subscribing to the audio streams of multiple remote users, call muteRemoteVideoStream(false) multiple times.",
        "parameters": [
            {
                "mute": "\n      Whether to stop subscribing to the audio streams of all remote users by default.\n     true: Stop subscribing to the audio streams of all remote users by default.\n     false: (Default) Resume subscribing to the audio streams of all remote users by default.\n \n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_seteffectsvolume",
        "name": "setEffectsVolume",
        "description": "Sets the volume of the audio effects.Call this method after playEffect.",
        "parameters": [
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setenablespeakerphone",
        "name": "setEnableSpeakerphone",
        "description": "Enables/Disables the audio playback route to the speakerphone.This method sets whether the audio is routed to the speakerphone or earpiece. After a successful method call, the SDK triggers the onAudioRouteChanged callback.\n            \n                \n                    This method is for Android and iOS only.\n                    Ensure that you call joinChannel to create a data channel before calling this method.",
        "parameters": [
            {
                "enabled": "Whether the audio is routed to the speakerphone or earpiece.\n                            true: Route the audio to the speakerphone. If the playback device connects to the earpiece or Bluetooth, the audio cannot be routed to the speakerphone.\n                            false: Route the audio to the earpiece. If a headset is plugged in, the audio is routed to the headset.\n                        \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setencryptionmode",
        "name": "setEncryptionMode",
        "description": "Sets the built-in encryption mode.Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.\n       \n   \n   The Agora SDK supports built-in encryption. The default encryption is AES-128-XTS. Call this method to use other encryption modes. All users in the same channel must use the same encryption mode and password. Refer to the information related to the AES encryption algorithm on the differences between the encryption modes.\n   Before calling this method, please call setEncryptionSecret to enable the built-in encryption function.",
        "parameters": [
            {
                "encryptionMode": "\n      Encryption mode.\n     \"aes-128-xts\": (Default) 128-bit AES encryption, XTS mode.\n     \"aes-128-ecb\": 128-bit AES encryption, ECB mode.\n     \"aes-256-xts\": 256-bit AES encryption, XTS mode.\n     \"\": When setting as NULL, the encryption mode is set as \"aes-128-xts\" by default.\n \n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setencryptionsecret",
        "name": "setEncryptionSecret",
        "description": "Enables built-in encryption with an encryption password before users join a channel.Deprecated:\n  Deprecated as of v3.1.0. Please use the enableEncryption method instead.\n       \n   \n   Before joining the channel, you need to call this method to set the secret parameter to enable the built-in encryption. All users in the same channel should use the same secret. The secret is automatically cleared once a user leaves the channel. If the secret is not set or set secret as null, the built-in encryption is disabled.\n   \n       \n  Do not use this method for CDN live streaming.\n  For optimal transmission, ensure that the encrypted data size does not exceed the original data size + 16 bytes. 16 bytes is the maximum padding size for AES encryption.",
        "parameters": [
            {
                "secret": "The encryption password."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setexternalaudiosink",
        "name": "setExternalAudioSink",
        "description": "Sets the external audio sink.This method applies to scenarios where you want to use external audio data for playback. After enabling the external audio sink, you can call the pullAudioFrame method to pull the remote audio data, process it, and play it with the audio effects that you want.\n   \n       \n  Once you enable the external audio sink, the app will not retrieve any audio data from the onPlaybackAudioFrame callback.\n  Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "enabled": "\n      \n true: Enables the external audio sink.\n false: (Default) Disables the external audio sink.\n      \n  "
            },
            {
                "sampleRate": "The sample rate (Hz) of the external audio sink, which can be set as 16000, 32000, 44100, or 48000."
            },
            {
                "channels": "The number of audio channels of the external audio sink:\n 1: Mono.\n 2: Stereo.\n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setexternalaudiosource",
        "name": "setExternalAudioSource",
        "description": "Sets the external audio source.Call this method before calling joinChannel and startPreview.",
        "parameters": [
            {
                "enabled": "\n      \n true: Enables the external audio source.\n false: (Default) Disables the external audio source.\n      \n  "
            },
            {
                "sampleRate": "The sample rate (Hz) of the external audio source, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz."
            },
            {
                "channels": "\n      The number of audio channels of the external audio source:\n     1: Mono.\n     2: Stereo.\n \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setexternalvideosource",
        "name": "setExternalVideoSource",
        "description": "Configures the external video source.Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "enable": "\n      Whether to use the external video source:\n     true: Use the external video source.\n     false: (Default) Do not use the external video source.\n \n  "
            },
            {
                "useTexture": "Whether to use texture as an input:\n true: Use texture as an input.\n      false: (Default) Do not use texture as an input.\n      "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_sethighqualityaudioparameters",
        "name": "setHighQualityAudioParameters",
        "description": "Set audio high quality options.Deprecated:\n  This method is deprecated. Agora does not recommend using this method. If you want to set the audio high-quality options, use the setAudioProfile method instead.",
        "parameters": [
            {
                "fullband": "Whether to enable full-band codec (48-kHz sample rate). Not compatible with SDK versions before v1.7.4.\n      \n true: Enable full-band codec.\n false: Disable full-band codec.\n      \n  "
            },
            {
                "stereo": "Whether to enable stereo codec. Not compatible with SDK versions before v1.7.4.\n      \n true: Enable stereo codec.\n false: Disable stereo codec.\n      \n  "
            },
            {
                "fullBitrate": "High bit rate mode. Recommended in voice-only mode.\n      \n true: Enable high-bitrate mode.\n false: Disable high-bitrate mode.\n      \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_seiinearmonitoringvolume",
        "name": "setInEarMonitoringVolume",
        "description": "Sets the volume of the in-ear monitor.This method is for Android and iOS only.\n      Users must use wired earphones to hear their own voices.\n      You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "volume": "The volume of the in-ear monitor. The value ranges between 0 and 100. The default value is 100."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlivetranscoding",
        "name": "setLiveTranscoding",
        "description": "Sets the transcoding configurations for CDN live streaming.This method sets the video layout and audio settings for CDN live streaming. The SDK triggers the onTranscodingUpdated callback when you call this method to update the transcoding setting.\n   \n       \n  This method takes effect only when you are a host in live interactive streaming.\n  Ensure that you enable the RTMP Converter service before using this function. See Prerequisites in the advanced guide Push Streams to CDN.\n  If you call this method to set the transcoding configuration for the first time, the SDK does not trigger the onTranscodingUpdated callback.\n  Call this method after joining a channel.\n  Agora supports pushing media streams in RTMPS protocol to the CDN only when you enable transcoding.",
        "parameters": [
            {
                "transcoding": "\n      The transcoding configurations for CDN live streaming. See LiveTranscoding."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalpublishfallbackoption",
        "name": "setLocalPublishFallbackOption",
        "description": "Sets the fallback option for the published video stream based on the network conditions.An unstable network affects the audio and video quality in a video call or interactive live video streaming. If option is set as STREAM_FALLBACK_OPTION_AUDIO_ONLY(2), the SDK disables the upstream video but enables audio only when the network conditions deteriorate and cannot support both video and audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the published video stream falls back to audio only or when the audio-only stream switches back to the video, the SDK triggers the onLocalPublishFallbackToAudioOnly callback.\n   \n       \n  Agora does not recommend using this method for CDN live streaming, because the remote CDN live user will have a noticeable lag when the published video stream falls back to STREAM_FALLBACK_OPTION_AUDIO_ONLY(2).\n  Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "The stream fallback option.\n STREAM_FALLBACK_OPTION_DISABLED (0): (Default) No fallback behavior for the published video stream when the uplink network condition is poor. The stream quality is not guaranteed.\n STREAM_FALLBACK_OPTION_AUDIO_ONLY (2): The published video stream falls back to audio only when the uplink network condition is poor.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalrendermode1",
        "name": "setLocalRenderMode [1/2]",
        "description": "Sets the local video display mode.Deprecated:\n                    This method is deprecated. Use setLocalRenderMode instead.\n                \n            \n   \n   Call this method to set the local video display mode. This method can be called multiple times during a call to change the display mode.",
        "parameters": [
            {
                "renderMode": "\n      The local video display mode. See RENDER_MODE_TYPE.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalrendermode2",
        "name": "setLocalRenderMode [2/2]",
        "description": "Updates the display mode of the local video view.Since\n  v3.3.0\n       \n   \n   After initializing the local video view, you can call this method to update its rendering and mirror modes. It affects only the video view that the local user sees, not the published local video stream.\n   \n       \n  Ensure that you have called the setupLocalVideo method to initialize the local video view before calling this method.\n  During a call, you can call this method as many times as necessary to update the display mode of the local video view.",
        "parameters": [
            {
                "renderMode": "The rendering mode of the local video view. See RENDER_MODE_TYPE."
            },
            {
                "mirrorMode": "The rendering mode of the local video view. See VIDEO_MIRROR_MODE_TYPE.\n      If you use a front camera, the SDK enables the mirror mode by default; if you use a rear camera, the SDK disables the mirror mode by default.\n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setlocalvideomirrormode",
        "name": "setLocalVideoMirrorMode",
        "description": "Sets the local video mirror mode.Deprecated:\n  Deprecated as of v3.0.0. Use setupLocalVideo or setLocalRenderMode instead.",
        "parameters": [
            {
                "mode": "The local video mirror mode. See VIDEO_MIRROR_MODE_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicechanger",
        "name": "setLocalVoiceChanger",
        "description": "Sets the local voice changer option.Deprecated:\n           Deprecated from v3.2.0. Use the following methods instead:\n                   setAudioEffectPreset : Audio effects.\n                   setVoiceBeautifierPreset : Voice beautifier effects.\n                   setVoiceConversionPreset : Voice conversion effects.\n               \n            \n       \n   \n   This method can be used to set the local voice effect for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n  VOICE_CHANGER_XXX: Changes the local voice to an old man, a little boy, or the Hulk. Applies to the voice talk scenario.\n  VOICE_BEAUTY_XXX: Beautifies the local voice by making it sound more vigorous, resounding, or adding spacial resonance. Applies to the voice talk and singing scenario.\n  GENERAL_VOICE_BEAUTY_XXX: Adds gender-based beautification effect to the local voice. Applies to the voice talk scenario. For a male voice: Adds magnetism to the voice. For a female voice: Adds freshness or vitality to the voice.\n       \n   \n   \n       \n  To achieve better voice effect quality, Agora recommends setting the profile parameter in setAudioProfile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceReverbPreset, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Voice Changer and Reverberation.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "voiceChanger": "The local voice changer option. The default value is VOICE_CHANGER_OFF, which means the original voice. For details, see VOICE_CHANGER_PRESET. The gender-based beatification effect works best only when assigned a proper gender. Use GENERAL_BEAUTY_VOICE_MALE_MAGNETIC for male and use GENERAL_BEAUTY_VOICE_FEMALE_FRESH and GENERAL_BEAUTY_VOICE_FEMALE_VITALITY for female. Failure to do so can lead to voice distortion."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoiceequalization",
        "name": "setLocalVoiceEqualization",
        "description": "Sets the local voice equalization effect.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "bandFrequency": "The band frequency. The value ranges between 0 and 9, representing the respective 10-band center frequencies of the voice effects, including 31, 62, 125, 250, 500, 1k, 2k, 4k, 8k, and 16k Hz. For details, see AUDIO_EQUALIZATION_BAND_FREQUENCY."
            },
            {
                "bandGain": "The gain of each band in dB. The value ranges between -15 and 15. The default value is 0."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicepitch",
        "name": "setLocalVoicePitch",
        "description": "Changes the voice pitch of the local speaker.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "pitch": "The value ranges between 0.5 and 2.0. The lower the value, the lower the pitch. The default value is 1 (no change to the pitch)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicereverb",
        "name": "setLocalVoiceReverb",
        "description": "Sets the local voice reverberation.You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbKey": "The reverberation key. Agora provides 5 reverberation keys: AUDIO_REVERB_TYPE."
            },
            {
                "value": "The value of the reverberation key."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlocalvoicereverbpreset",
        "name": "setLocalVoiceReverbPreset",
        "description": "Sets the local voice reverberation option, including the virtual stereo.Deprecated:\n  This method is deprecated as of v2.4.0. Agora recommends using setAudioEffectPreset and setVoiceBeautifierPreset instead.\n       \n   \n   This method sets the local voice reverberation for users in a COMMUNICATION channel or hosts in a LIVE_BROADCASTING channel. After successfully calling this method, all users in the channel can hear the voice with reverberation.\n   \n       \n  When using the enumeration value prefixed with AUDIO_REVERB_FX, please make sure to set the profile parameter in setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5) before calling this method, otherwise, the method setting is invalid.\n  When calling this method with AUDIO_VIRTUAL_STEREO, Agora recommends setting the profile parameter in setAudioProfile as AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5).\n  This method works best with the human voice, and Agora does not recommend using it for audio containing music and a human voice.\n  Do not use this method with setLocalVoiceChanger, because the method called later overrides the one called earlier. For detailed considerations, see the advanced guide Voice Changer and Reverberation.\n  You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "reverbPreset": "The local voice reverberation option. The default value is AUDIO_REVERB_OFF , which means the original voice. For details, see AUDIO_REVERB_PRESET.\n      To achieve better voice effects, Agora recommends the enumeration whose name begins with AUDIO_REVERB_FX."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlogfile",
        "name": "setLogFile",
        "description": "Sets the log files that the SDK outputs.Deprecated:\n  This method is deprecated as of v2.4.0. Use the mLogConfig parameter in initialize instead.\n       \n   \n   By default, the SDK outputs five log files, agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log, each with a default size of 1024 KB. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest logs in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n   Ensure that you call this method immediately after initializing IRtcEngine, otherwise, the output log may not be complete.",
        "parameters": [
            {
                "filePath": "\n                        The absolute path of the log files. The default file path is C: \\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log. Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files.\n                    "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setlogfilesize",
        "name": "setLogFileSize",
        "description": "Sets the size of a log file that the SDK outputs.Deprecated:\n                    v3.3.0. Use logConfig in initialize instead.\n                \n            \n            By default, the SDK outputs five log files, agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log, each with a default size of 1024 KB. Each log file has a default size of 512 KB. These log files are encoded in UTF-8. The SDK writes the latest logs in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest logs.\n            If you want to set the size of the log file, you need tosetLogFile call this method before , otherwise, the log will be cleared.",
        "parameters": [
            {
                "fileSizeInKBytes": "The size (KB) of a log file. The default value is 1024 KB. If you set fileSizeInKByte to 1024 KB, the maximum aggregate size of the log files output by the SDK is 5 MB. if you set fileSizeInKByte to less than 1024 KB, the setting is invalid, and the maximum size of a log file is still 1024 KB."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setlogfilter",
        "name": "setLogFilter",
        "description": "Sets the log output level of the SDK.Deprecated:\n  v3.3.0. Use logConfig in initialize instead.\n       \n   \n   This method sets the output log level of the SDK. You can use one or a combination of the log filter levels. The log level follows the sequence of OFF, CRITICAL, ERROR, WARNING, INFO, and DEBUG. Choose a level to see the logs preceding that level.\n   If, for example, you set the log level to WARNING, you see the logs within levels CRITICAL, ERROR, and WARNING.",
        "parameters": [
            {
                "filter": "The output log level of the SDK. See LOG_FILTER_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setmixedaudioframeparameters",
        "name": "setMixedAudioFrameParameters",
        "description": "Sets the format of mixed audio.Sets the mixed audio format for the onMixedAudioFrame callback.\n   \n       \n  Ensure that you call this method before joining a channel.\n  The SDK calculates the sampling interval based on the samplesPerCall, sampleRate and channel parameters set in this method.Sample interval (sec) = samplePerCall/(sampleRate × channel).. Ensure that the sample interval ≥ 0.01 (s). The SDK triggers the onMixedAudioFrame callback according to the sampling interval.",
        "parameters": [
            {
                "sampleRate": "The sample rate returned in the onMixedAudioFrame callback, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz."
            },
            {
                "samplesPerCall": "The number of samples returned in the onMixedAudioFrame callback. Usually set as 1024 for RTMP or RTMPS streaming."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackaudioframeparameters",
        "name": "setPlaybackAudioFrameParameters",
        "description": "Sets the audio playback format.Sets the mixed audio format for the onPlaybackAudioFrame callback.\n   \n       \n  Ensure that you call this method before joining a channel.\n  The SDK calculates the sampling interval based on the samplesPerCall, sampleRate and channel parameters set in this method.Sample interval (sec) = samplePerCall/(sampleRate × channel).. Ensure that the sample interval ≥ 0.01 (s). The SDK triggers the onPlaybackAudioFrame callback according to the sampling interval.",
        "parameters": [
            {
                "sampleRate": "The sample rate returned in the onPlaybackAudioFrame callback, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz."
            },
            {
                "channel": "\n      The number of channels (channels) returned in the onPlaybackAudioFrame callback:\n     1: Mono.\n     2: Stereo.\n \n  "
            },
            {
                "mode": "The use mode (see RAW_AUDIO_FRAME_OP_MODE_TYPE) of the onPlaybackAudioFrame callback."
            },
            {
                "samplesPerCall": "The number of samples returned in the onPlaybackAudioFrame callback. Usually set as 1024 for RTMP or RTMPS streaming."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackdevice",
        "name": "setPlaybackDevice",
        "description": "Sets the audio playback device.",
        "parameters": [
            {
                "deviceId": "The ID of the audio playback device. You can get the device ID by calling enumeratePlaybackDevices. Plugging or unplugging the audio device does not change the device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackdevicemute",
        "name": "setPlaybackDeviceMute",
        "description": "Mutes the audio playback device.",
        "parameters": [
            {
                "mute": "Whether to mute the audio playback device:\n      true\n      false\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setplaybackdevicevolume",
        "name": "setPlaybackDeviceVolume",
        "description": "Sets the volume of the audio playback device.",
        "parameters": [
            {
                "volume": "The volume of the audio playback device. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingaudioframeparameters",
        "name": "setRecordingAudioFrameParameters",
        "description": "Sets the audio recording format.Sets the audio recording format for the onRecordAudioFrame callback.\n   \n       \n  Ensure that you call this method before joining a channel.\n  The SDK calculates the sampling interval based on the samplesPerCall, sampleRate and channel parameters set in this method.Sample interval (sec) = samplePerCall/(sampleRate × channel).. Ensure that the sample interval ≥ 0.01 (s). The SDK triggers the onRecordAudioFrame callback according to the sampling interval.",
        "parameters": [
            {
                "sampleRate": "The sample rate returned in the onRecordAudioFrame callback, which can be set as 8000, 16000, 32000, 44100, or 48000 Hz."
            },
            {
                "channel": "\n      The number of channels (channels) returned in the onRecordAudioFrame callback:\n     1: Mono.\n     2: Stereo.\n \n  "
            },
            {
                "mode": "The use mode (see RAW_AUDIO_FRAME_OP_MODE_TYPE) of the onRecordAudioFrame callback."
            },
            {
                "samplesPerCall": "The number of samples returned in the onRecordAudioFrame callback. Usually set as 1024 for RTMP or RTMPS streaming."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingdevice",
        "name": "setRecordingDevice",
        "description": "Sets the audio capturing device.",
        "parameters": [
            {
                "deviceId": "The ID of the audio capture device. You can get the device ID by calling enumerateRecordingDevices. Plugging or unplugging the audio device does not change the device ID. The maximum length is \n   \n       \n  MAX_DEVICE_ID_LENGTH\n       \n   \n        ."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingdevicemute",
        "name": "setRecordingDeviceMute",
        "description": "Mutes or unmutes the microphone.",
        "parameters": [
            {
                "mute": "Whether to mute the audio sampling device:\n      true0: Mute the audio sampling device.\n      false: Unmute the audio sampling device.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setrecordingdevicevolume",
        "name": "setRecordingDeviceVolume",
        "description": "Sets the volume of the audio sampling device.",
        "parameters": [
            {
                "volume": "The volume of the microphone. The value ranges between 0 (lowest volume) and 255 (highest volume)."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremotedefaultvideostreamtype",
        "name": "setRemoteDefaultVideoStreamType",
        "description": "Sets the default stream type of remote videos.Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream).\n   By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n   The method result returns in the onApiCallExecuted callback.\n   You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremoterendermode1",
        "name": "setRemoteRenderMode [1/2]",
        "description": "Sets the video display mode of a specified remote user.Deprecated:\n  This method is deprecated. UsesetRemoteRenderMode[2/2] instead.\n       \n   \n   Call this method to set the video display mode of a specified remote user. This method can be called multiple times during a call to change the display mode.",
        "parameters": [
            {
                "userId": "The ID of the remote user."
            },
            {
                "renderMode": "The video display mode of the remote user. For details, see RENDER_MODE_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremoterendermode2",
        "name": "setRemoteRenderMode [2/2]",
        "description": "Updates the display mode of the video view of a remote user.Since\n  v3.0.0\n       \n   \n   After initializing the video view of a remote user, you can call this method to update its rendering and mirror modes. This method affects only the video view that the local user sees.\n   \n       \n  Please call thissetupRemoteVideo method after calling the method to initialize the remote view.\n  During a call, you can call this method as many times as necessary to update the display mode of the video view of a remote user.",
        "parameters": [
            {
                "userId": "\n      Remote user ID.\n  "
            },
            {
                "renderMode: The video display mode:": "\n      The rendering mode of the remote user view, see for detailsRENDER_MODE_TYPE.\n  "
            },
            {
                "mirrorMode": "\n      The mirror mode of the remote user view, see for detailsVIDEO_MIRROR_MODE_TYPE.\n      Note: The SDK disables the mirror mode by default.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setremotesubscribefallbackoption",
        "name": "setRemoteSubscribeFallbackOption",
        "description": "Sets the fallback option for the remotely subscribed video stream based on the network conditions.Unreliable network conditions affect the overall quality of the live interactive streaming. If option is set as STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW(1) or STREAM_FALLBACK_OPTION_AUDIO_ONLY(2), the SDK automatically switches the video from a high stream to a low stream or disables the video when the downlink network conditions cannot support both audio and video to guarantee the quality of the audio. The SDK monitors the network quality and restores the video stream when the network conditions improve. When the remote video stream falls back to audio-only or when the audio-only stream switches back to the video, the SDK triggers the onRemoteSubscribeFallbackToAudioOnly callback.\n               Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "option": "See STREAM_FALLBACK_OPTIONS. The default option is STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW(1)."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremoteuserpriority",
        "name": "setRemoteUserPriority",
        "description": "Prioritizes a remote user's stream.Since\n                         v2.4.0\n                    \n               \n               Prioritizes a remote user's stream. The SDK ensures the high-priority user gets the best possible stream quality.\n               \n                    \n                         The SDK supports setting only one user as high priority.\n                         Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "userPriority": "The priority of the remote user. See PRIORITY_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremotevideostreamtype",
        "name": "setRemoteVideoStreamType",
        "description": "Sets the stream type of the remote video.Under limited network conditions, if the publisher has not disabled the dual-stream mode using enableDualStreamMode(false), the receiver can choose to receive either the high-quality video stream (the high resolution, and high bitrate video stream) or the low-video stream (the low resolution, and low bitrate video stream). The high-quality video stream has a higher resolution and bitrate, and the low-quality video stream has a lower resolution and bitrate.\n               By default, users receive the high-quality video stream. Call this method if you want to switch to the low-video stream. This method allows the app to adjust the corresponding video stream type based on the size of the video window to reduce the bandwidth and resources. The aspect ratio of the low-video stream is the same as the high-quality video stream. Once the resolution of the high-quality video stream is set, the system automatically sets the resolution, frame rate, and bitrate of the low-video stream.\n               The method result returns in the onApiCallExecuted callback.\n               You can call this method either before or after joining a channel. If you call both setRemoteVideoStreamType and setRemoteDefaultVideoStreamType, the setting of setRemoteVideoStreamType takes effect.",
        "parameters": [
            {
                "userId": "The user ID."
            },
            {
                "streamType": "The video stream type: REMOTE_VIDEO_STREAM_TYPE."
            }
        ],
        "returns": "0: Success.\n                    < 0: Failure."
    },
    {
        "id": "api_setremotevoiceposition",
        "name": "setRemoteVoicePosition",
        "description": "Sets the sound position and gain of a remote user.This method sets the sound position and gain of a remote user.\n   When the local user calls this method to set the sound position of a remote user, the sound difference between the left and right channels allows the local user to track the real-time position of the remote user, creating a real sense of space. This method applies to massively multiplayer online games, such as Battle Royale games.\n   \n       \n  For this method to work, enable stereo panning for remote users by calling the enableSoundPositionIndication method before joining a channel.\n  This method requires hardware support. For the best sound positioning, we recommend using a stereo speaker.\n  Call this method after joining a channel.",
        "parameters": [
            {
                "uid": "The ID of the remote user."
            },
            {
                "pan": "The sound position of the remote user. The value ranges from -1.0 to 1.0:\n 0.0: the remote sound comes from the front.\n -1.0: the remote sound comes from the left.\n 1.0: the remote sound comes from the right.\n      \n  "
            },
            {
                "gain": "The gain of the remote user. The value ranges from 0.0 to 100.0. The default value is 100.0 (the original gain of the remote user). The smaller the value, the less the gain."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setscreencapturecontenthint",
        "name": "setScreenCaptureContentHint",
        "description": "Sets the content hint for screen sharing.Since\n  v2.4.0\n       \n   \n   A content hint suggests the type of the content being shared, so that the SDK applies different optimization algorithms to different types of content. If you don't call this method, the default content hint is CONTENT_HINT_NONE.\n   You can call this method either before or after you start screen sharing.",
        "parameters": [
            {
                "contentHint": "The content hint for screen sharing. See VideoContentHint."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setuplocalvideo",
        "name": "setupLocalVideo",
        "description": "Initializes the local video view.This method initializes the video view of a local stream on the local device. It affects only the video view that the local user sees, not the published local video stream. Call this method to bind the local video stream to a video view and to set the rendering and mirror modes of the video view.\n            After initialization, call this method to set the local video and then join the channel. The binding is still valid after the user leaves the channel, which means that the window still displays. To unbind the view, set the view in NULL to NULL.\n            \n                \n                    You can call this method either before or after joining a channel.\n                    To update the rendering or mirror mode of the local video view during a call, use the setLocalRenderMode method.",
        "parameters": [
            {
                "canvas": "The local video view and settings. See VideoCanvas."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setupremotevideo",
        "name": "setupRemoteVideo",
        "description": "Initializes the video view of a remote user.This method initializes the video view of a remote stream on the local device. It affects only the video view that the local user sees. Call this method to bind the remote video stream to a video view and to set the rendering and mirror modes of the video view.\n   The application specifies the uid of the remote video in this method before the remote user joins the channel. If the remote uid is unknown to the application, set it after the application receives the onUserJoined callback.\n            To unbind the remote user from the view, set the view parameter in VideoCanvas to NULL.\n            Once the remote user leaves the channel, the SDK unbinds the remote user.\n   \n       \n           To update the rendering or mirror mode of the remote video view during a call, use the setRemoteRenderMode method.\n           If the Video Recording function is enabled, the Video Recording Service joins the channel as a dummy client, causing other clients to also receive the onUserJoined callback. Do not bind the dummy client to the application view because the dummy client does not send any video streams. If your application does not recognize the dummy client, bind the remote user to the view when the SDK triggers the onFirstRemoteVideoDecoded callback.",
        "parameters": [
            {
                "canvas": "\n      Pointer to the remote video view and settings. See VideoCanvas.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvideoencoderconfiguration",
        "name": "setVideoEncoderConfiguration",
        "description": "Sets the video encoder configuration.Sets the encoder configuration for the local video.\n   You can call this method either before or after joining a channel. If the user does not need to reset the video encoding properties after joining the channel, Agora recommends calling this method before enableVideo to reduce the time to render the first video frame.",
        "parameters": [
            {
                "config": "Video profile. See VideoEncoderConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvideoprofile",
        "name": "setVideoProfile",
        "description": "Sets the video encoder configuration.Deprecated:\n  This method is deprecated as of v2.3. Please use the setVideoEncoderConfiguration method instead.\n       \n   \n   This method sets the video encoder configuration. You can call this method either before or after joining a channel. If the user does not need to reset the video encoding properties after joining the channel, Agora recommends calling this method before enableVideo to reduce the time to render the first video frame.",
        "parameters": [
            {
                "profile": "The video profile. See VIDEO_PROFILE_TYPE."
            },
            {
                "swapWidthAndHeight": "The SDK outputs video with a fixed width and height according to the video profile (profile) you selected. This parameter sets whether to swap width and height of the video:\n  \n      truetrue: Swap the width and height.\n      falsefalse: (Default) Do not swap the width and height.\n  \n  "
            }
        ],
        "returns": "0: Success.\n        < 0: Failure."
    },
    {
        "id": "api_setvideoqualityparameters",
        "name": "setVideoQualityParameters",
        "description": "Sets the preferences for high-quality video. (LIVE_BROADCASTING only).Deprecated:\n                    Deprecated as of v2.4.0. Agora recommends using the degradationPreference parameter in the VideoEncoderConfigurationclass to set the preferences for high-quality video.",
        "parameters": [
            {
                "preferFrameRateOverImageQuality": "\n                        Whether to prioritize smoothness or image quality.\n                                true: Prioritizes smoothness.\n                                false: (Default) Prioritizes the image quality.\n                            \n                    "
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setvideosource",
        "name": "setVideoSource",
        "description": "Sets a custom video source.During real-time communication, the Agora SDK enables the default video input device, that is, the built-in camera to capture video. If you need a custom video source, implement the class firstIVideoSource, and call this method to add the custom video source to the SDK.\n   You can call this method either before or after joining a channel.",
        "parameters": [
            {
                "source": "A custom video source. For details, see IVideoSource."
            }
        ],
        "returns": "true: The custom video source is added to the SDK.\n       false: The custom video source is not added to the SDK."
    },
    {
        "id": "api_setvoicebeautifierparameters",
        "name": "setVoiceBeautifierParameters",
        "description": "Sets parameters for the preset voice beautifier effects.Since\n  v3.3.0\n       \n   \n   Call this method to set a gender characteristic and a reverberation effect for the singing beautifier effect. This method sets parameters for the local user who sends an audio stream. After setting the audio parameters, all users in the channel can hear the effect.\n   For better voice effects, Agora recommends that you call setAudioProfile and set scenario to AUDIO_SCENARIO_GAME_STREAMING(3) and profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter of setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT(6), otherwise, the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierParameters, Agora recommends not calling the following methods, because they can override setVoiceBeautifierParameters:\n setAudioEffectPreset\n setAudioEffectParameters\n setVoiceBeautifierPreset\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The options for the preset audio effect:\n SINGING_BEAUTIFIER: Singing beautifier effect.\n      \n  "
            },
            {
                "param1": "The gender characteristics options for the singing voice:\n 1: A male-sounding voice.\n 2: A female-sounding voice.\n      \n  "
            },
            {
                "param2": "The reverberation effect options for the singing voice:\n 1: The reverberation effect sounds like singing in a small room.\n 2: The reverberation effect sounds like singing in a large room.\n 3: The reverberation effect sounds like singing in a hall.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvoicebeautifierpreset",
        "name": "setVoiceBeautifierPreset",
        "description": "Sets a preset voice beautifier effect.Since\n  v3.2.0\n       \n   \n   Call this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting a voice beautifier effect, all users in the channel can hear the effect. You can set different audio effects for different scenarios. For details, see Set the Voice Beautifier and Audio Effects.\n   For better voice effects, Agora recommends that you call setAudioProfile and set scenario to AUDIO_SCENARIO_GAME_STREAMING(3) and profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY(4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO(5) before calling this method.\n   \n       \n  You can call this method either before or after joining a channel.\n  Do not set the profile parameter in setAudioProfile to AUDIO_PROFILE_SPEECH_STANDARD(1) or AUDIO_PROFILE_IOT(6), or the method will not take effect.\n  This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n  After calling setVoiceBeautifierPreset, Agora recommends not calling the following methods, because they can override setVoiceBeautifierPreset:\n setAudioEffectPreset\n setAudioEffectParameters\n setLocalVoiceReverbPreset\n setLocalVoiceChanger\n setLocalVoicePitch\n setLocalVoiceEqualization\n setLocalVoiceReverb\n setVoiceBeautifierParameters\n          setVoiceConversionPreset",
        "parameters": [
            {
                "preset": "The preset voice beautifier effect option: VOICE_BEAUTIFIER_PRESET."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_setvoiceconversionpreset",
        "name": "setVoiceConversionPreset",
        "description": "Sets a preset voice beautifier effect.Since\n                    v3.3.1\n                \n            \n            Call this method to set a preset voice beautifier effect for the local user who sends an audio stream. After setting an audio effect, all users in the channel can hear the effect. You can set different audio effects for different scenarios. See Set the Voice Beautifier and Audio Effects.\n            To achieve better audio effect quality, Agora recommends that you call and setsetAudioProfile the profile toAUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) orAUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5) and scenario to AUDIO_SCENARIO_GAME_STREAMING(3) before calling this method.\n            \n                \n                    You can call this method either before or after joining a channel.\n                    Do not setsetAudioProfile the profile parameter in to AUDIO_PROFILE_SPEECH_STANDARD(1)\n                    This method works best with the human voice. Agora does not recommend using this method for audio containing music.\n                    After calling setVoiceConversionPreset, Agora recommends not calling the following methods, because they can override setVoiceConversionPreset:\n                            setAudioEffectPreset\n                            setAudioEffectParameters\n                            setVoiceBeautifierPreset\n                            setVoiceBeautifierParameters\n                            setLocalVoiceReverbPreset\n                            setLocalVoiceChanger\n                            setLocalVoicePitch\n                            setLocalVoiceEqualization\n                            setLocalVoiceReverb",
        "parameters": [
            {
                "preset": "The options for the preset voice beautifier effects: VOICE_CONVERSION_PRESET."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_setvolumeofeffect",
        "name": "setVolumeOfEffect",
        "description": "Sets the volume of a specified audio effect.Call this method after playEffect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            },
            {
                "volume": "The playback volume. The value ranges from 0 to 100. The default value is 100, which represents the original volume."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiodeviceloopbacktest",
        "name": "startAudioDeviceLoopbackTest",
        "description": "Starts an audio device loopback test.This method tests whether the local audio sampling device and playback device are working properly. After calling this method, the audio sampling device records the local audio, and the audio playback device plays the sampled audio. The SDK triggers two independent onAudioVolumeIndication callbacks at the time interval set in this method, which reports the volume information of the sampling device (uid = 0) and the volume information of the playback device(uid = 1) respectively.\n   \n       Ensure that you call this method before joining a channel.\n       This method tests local audio devices and does not report the network conditions.",
        "parameters": [
            {
                "indicationInterval": "The time interval(ms) at which the SDK triggers the onAudioVolumeIndication callback. We recommend a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the onAudioVolumeIndication callback."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiomixing",
        "name": "startAudioMixing",
        "description": "Starts playing and mixing the music file.This method mixes the specified local or online audio file with the audio from the microphone, or replaces the microphone's audio with the specified local or remote audio file. A successful method call triggers the onAudioMixingStateChanged (PLAY) callback. When the audio mixing file playback finishes, the SDK triggers the onAudioMixingStateChanged (STOPPED) callback on the local client.\n   \n       \n           Call this method after joining a channel. If you need to call startAudioMixing multiple times, ensure that the time interval between calling this method is more than 500 ms.\n           If the local audio mixing file does not exist, or if the SDK does not support the file format or cannot access the music file URL, the SDK returns WARN_AUDIO_MIXING_OPEN_ERROR = 701.\n           If you need to play an online music file, Agora does not recommend using the redirected URL address. Some Android devices may fail to open a redirected URL address.",
        "parameters": [
            {
                "filePath": "The absolute path or URL address (including the suffixes of the filename) of the audio effect file. For example: C:\\music\\audio.mp4Supported audio formats include MP3, AAC, M4A, MP4, WAV, and 3GP. See .\n               "
            },
            {
                "loopback": "Whether to only play music files on the local client:\n          true: Only play music files on the local client so that only the local user can hear the music.\n          false: Publish music files to remote clients so that both the local user and remote users can hear the music.\n      \n  "
            },
            {
                "replace": "Whether to replace the audio captured by the microphone with a music file:\n          true: Replace the audio captured by the microphone with a music file. Users can only hear the music.\n          false: Do not replace the audio captured by the microphone with a music file. Users can hear both music and audio captured by the microphone.\n      \n  "
            },
            {
                "cycle": "The number of times the music file plays.\n          ≥ 0: The number of playback times. For example, 0 means that the SDK does not play the music file while 1 means that the SDK plays once.\n          -1: Play the music effect in an infinite loop.\n      \n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiorecording1",
        "name": "startAudioRecording [1/2]",
        "description": "Starts an audio recording on the client.Deprecated:\n  This method is deprecated as of v2.9.1. It has a fixed recording sample rate of 32 kHz. Please use the startAudioRecording method instead.\n       \n   \n   The Agora SDK allows recording during a call. This method records the audio of all the users in the channel and generates an audio recording file. Supported formats of the recording file are as follows:\n  .wav: Large file size with high fidelity.\n  .aac: Small file size with low fidelity.\n       \n   \n   Ensure that the directory for the recording file exists and is writable. This method should be called after the joinChannel method. The recording automatically stops when you call the leaveChannel method.",
        "parameters": [
            {
                "filePath": "The absolute path of the recording file specified by the user. The file path must include the file name and its format. For example: C:/music/audio.aac "
            },
            {
                "quality": "Recording configuration. For details, see AUDIO_RECORDING_QUALITY_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startaudiorecording2",
        "name": "startAudioRecording [2/2]",
        "description": "Starts an audio recording on the client.Since\n                    v2.9.1. This method replaces startAudioRecording[1/2].\n                \n            \n            \n   The Agora SDK allows recording during a call. After successfully calling this method, you can record the audio of all the users in the channel and get an audio recording file. Supported formats of the recording file are as follows:\n      .wav: Large file size with high fidelity.\n      .aac: Small file size with low fidelity.\n  \n       \n   \n       \n  Ensure that the directory you use to save the recording file exists and is writable.\n  This method should be called after the joinChannel method. The recording automatically stops when you call the leaveChannel method.\n  For better recording effects, set quality to or when sampleRate is 44.1 kHz or 48 kHzAUDIO_RECORDING_QUALITY_MEDIUMAUDIO_RECORDING_QUALITY_HIGH.",
        "parameters": [
            {
                "filePath": "The absolute path (including the suffixes of the filename) of the recording file. For example: C:\\music\\audio.aac."
            },
            {
                "sampleRate": "\n      The sample rate (kHz) of the recording file. Supported values are as follows:\n     16000\n     32000 (Default)\n     44100\n     48000\n \n      \n  "
            },
            {
                "quality": "Recording quality. For details, see AUDIO_RECORDING_QUALITY_TYPE."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startchannelmediarelay",
        "name": "startChannelMediaRelay",
        "description": "Starts relaying media streams across channels. This method can be used to implement scenarios such as co-host across channels.After a successful method call, the SDK triggers the onChannelMediaRelayStateChanged and onChannelMediaRelayEvent callbacks, and these callbacks return the state and events of the media stream relay.\n  If the onChannelMediaRelayStateChanged callback returns RELAY_STATE_RUNNING(2) and RELAY_OK(0), and the onChannelMediaRelayEvent callback returns RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL(4), it means that the SDK starts relaying media streams between the source channel and the destination channel.\n  If the onChannelMediaRelayStateChanged callback returns RELAY_STATE_FAILURE(3), an exception occurs during the media stream relay.\n       \n   \n   \n       \n  Call this method after joining the channel.\n  This method takes effect only when you are a host in a LIVE_BROADCASTING channel.\n  After a successful method call, if you want to call this method again, ensure that you call the stopChannelMediaRelay method to quit the current relay.\n  Contact support@agora.io (https://agora-ticket.agora.io/) before implementing this function.\n  We do not support string user accounts in this API.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. See ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startdevicetest",
        "name": "startDeviceTest",
        "description": "Starts the video-capture device test.This method tests whether the video-capture device is working properly. Before calling this method, ensure that you have already called the enableVideo method, and the window handle (hwnd) parameter is valid.",
        "parameters": [
            {
                "hwnd": "An input parameter. The window handle used to display the screen."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startechotest1",
        "name": "startEchoTest[1/2]",
        "description": "Starts an audio call test.Deprecated:\n                    This method is deprecated as of v2.4.0. We recommend using startEchoTest[2/2] to start an audio call test.\n                \n            \n            This method starts an audio call test to determine whether the audio devices (for example, headset and speaker) and the network connection are working properly. To conduct the test, the user speaks, and the recording is played back within 10 seconds. If the user can hear the recording within the interval, the audio devices and network connection are working properly.\n            \n                \n                    Call this method before joining a channel.\n                    After calling stopEchoTest, you must call startEchoTest to end the test. Otherwise, the app cannot perform the next echo test, and you cannot join the channel.\n                    In the `LIVE_BROADCASTING` profile, only a host can call this method.",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startechotest2",
        "name": "startEchoTest[2/2]",
        "description": "Starts an audio call test.This method starts an audio call test to determine whether the audio devices (for example, headset and speaker) and the network connection are working properly. To conduct the test, let the user speak for a while, and the recording is played back within the set interval. If the user can hear the recording within the interval, the audio devices and network connection are working properly.\n            \n                \n                    Call this method before joining a channel.\n                    After calling stopEchoTest, you must call startEchoTest to end the test. Otherwise, the app cannot perform the next echo test, and you cannot join the channel.\n                    In the `LIVE_BROADCASTING` profile, only a host can call this method.",
        "parameters": [
            {
                "intervalInSeconds": "The time interval (s) between when you speak and when the recording plays back."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startlastmileprobetest",
        "name": "startLastmileProbeTest",
        "description": "Starts the last-mile network probe test.Since\n                    v2.4.0\n                \n            \n            This method starts the last-mile network probe test before joining a channel to get the uplink and downlink last mile network statistics, including the bandwidth, packet loss, jitter, and round-trip time (RTT).\n            Once this method is enabled, the SDK returns the following callbacks:\n                    onLastmileQuality: The SDK triggers this callback within two seconds depending on the network conditions. This callback rates the network conditions and is more closely linked to the user experience.\n                    onLastmileProbeResult: The SDK triggers this callback within 30 seconds depending on the network conditions. This callback returns the real-time statistics of the network conditions and is more objective.\n                \n            \n            This method applies to the following scenarios:\n                    Before a user joins a channel, call this method to check the uplink network quality.\n                    In a live streaming channel, call this method to check the uplink network quality before an audience member switches to a host.\n                \n            \n            \n                \n                    This method consumes extra network traffic and may affect communication quality. We do not recommend calling this method and enableLastmileTest at the same time.\n                    Do not call other methods before receiving the onLastmileQuality and onLastmileProbeResult callbacks. Otherwise, the callbacks may be interrupted.\n                    A host should not call this method after joining a channel (when in a call).",
        "parameters": [
            {
                "config": "The configurations of the last-mile network probe test: LastmileProbeConfig."
            }
        ],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_startplaybackdevicetest",
        "name": "startPlaybackDeviceTest",
        "description": "Starts the audio playback device test.This method tests if the audio playback device works properly. Once a user starts the test, the SDK plays an audio file specified by the user. If the user can hear the audio, the playback device works properly.\n   After calling this method, the SDK triggers the onAudioVolumeIndication callback every 100 ms, reporting uid = 1 and the volume information of the playback device.\n   Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "testAudioFilePath": "Pointer to the path of the audio file for the audio playback device test in UTF-8.\n      Supported file formats: wav, mp3, m4a, and aac.\n      Supported file sample rates: 8000, 16000, 32000, 44100, and 48000 Hz.\n  "
            }
        ],
        "returns": "0: Success. Success, and you can hear the sound of the specified audio file.\n       < 0: Failure."
    },
    {
        "id": "api_startpreview",
        "name": "startPreview",
        "description": "Enables the local video preview.This method starts the local video preview before joining the channel. Before calling this method, ensure that you do the following:\n   \n       Call setupLocalVideo to set the local preview window;\n       Call enableVideo to enable the video.\n   \n   \n       \n           By default, the local preview enables the mirror mode.\n       After the local video preview is enabled, if you call leaveChannel to exit the channel, the local preview remains until you call stopPreview to disable it.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startrecordingdevicetest",
        "name": "startRecordingDeviceTest",
        "description": "Starts the audio capturing device test.This method tests whether the audio sampling device works properly. After calling this method, the SDK triggers the onAudioVolumeIndication callback at the time interval set in this method, which reports uid = 0 and the volume information of the capturing device.\n   Ensure that you call this method before joining a channel.",
        "parameters": [
            {
                "indicationInterval": "The time interval(ms) at which the SDK triggers the onAudioVolumeIndication callback. We recommend a setting greater than 200 ms. This value must not be less than 10 ms; otherwise, you can not receive the onAudioVolumeIndication callback."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapture",
        "name": "startScreenCapture",
        "description": "Starts screen sharing.Deprecated:\n  This method is deprecated as of v2.4.0. See the following methods instead:\n      startScreenCaptureByDisplayId\n      startScreenCaptureByWindowId\n  \n       \n   \n   This method shares the whole screen, a specified window, or the specified region:\n       Whole screen: Set windowId as 0 and rect as NULL.\n       A specified window: Set windowId as a value other than 0. Each window has a windowId that is not 0.\n       The specified region: Set windowId as 0 and rect as a value other than NULL. In this case, you can share the specified region, for example by dragging the mouse or implementing your own logic. The specified region is a region on the whole screen. Currently, sharing a specified region in a specific window is not supported.\n   \n   captureFreq is the captured frame rate once the screen-sharing function is enabled. The mandatory value ranges between 1 fps and 15 fps. No matter which of the above functions you enable, the SDK returns 0 when the execution succeeds, and an error code when the execution fails.",
        "parameters": [
            {
                "windowId": "The screen sharing area."
            },
            {
                "captureFreq": "(Mandatory) The captured frame rate. The value ranges between 1 fps and 15 fps."
            },
            {
                "rect": "Specifies the screen-sharing region: .Rect This parameter is valid when windowsId is set as 0. When rect is set asNULL , the whole screen is shared."
            },
            {
                "bitrate": "The bitrate of the screen share."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapturebydisplayid",
        "name": "startScreenCaptureByDisplayId",
        "description": "Shares the screen by specifying the display ID.Since\n  v2.4.0\n       \n   \n   This method shares a screen or part of the screen. You need to specify the ID of the screen to be shared in this method.\n   \n       This method applies to macOS only.\n       Call this method after joining a channel.",
        "parameters": [
            {
                "displayId": "The display ID of the screen to be shared. This parameter specifies which screen you want to share."
            },
            {
                "rectangle": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n      If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapturebyscreenrect",
        "name": "startScreenCaptureByScreenRect",
        "description": "Shares the whole or part of a screen by specifying the screen rect.Since\n  v2.4.0\n       \n   \n   This method shares a screen or part of the screen. You need to specify the area of the screen to be shared.\n   \n       \n  Call this method after joining a channel.\n  This method applies to Windows only.",
        "parameters": [
            {
                "screenRect": "Sets the relative location of the screen to the virtual screen."
            },
            {
                "regionRect": "(Optional) Sets the relative location of the region to the screen. If you do not set this parameter, the SDK shares the whole screen. See Rectangle. If the specified region overruns the screen, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen."
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_startscreencapturebywindowid",
        "name": "startScreenCaptureByWindowId",
        "description": "Shares the whole or part of a window by specifying the window ID.Since\n  v2.4.0\n       \n   \n   This method shares a window or part of the window. You need to specify the ID of the window to be shared.\n   \n       \n  Call this method after joining a channel.\n  \n   \n   \n       \n  \n      \n      \n      \n      \n      \n \n     System version\n     Software\n     Compatible versions\n     Support\n \n \n     win10\n     Chrome\n     76.0.3809.100\n     No\n \n \n     Office Word\n     18.1903.1152.0\n     Yes\n \n \n     Office Excel\n     No\n \n \n     Office PPT\n     Yes\n \n \n     WPS Word\n     11.1.0.9145\n     Yes\n \n \n     WPS Excel\n \n \n     WPS PPT\n \n \n     Media Player (come with the system)\n     All\n     Yes\n \n \n     win8\n     Chrome\n     All\n     Yes\n \n \n     Office Word\n     All\n     Yes\n \n \n     Office Excel\n \n \n     Office PPT\n \n \n     WPS Word\n     11.1.0.9098\n     Yes\n \n \n     WPS Excel\n \n \n     WPS PPT\n \n \n     Media Player (come with the system)\n     All\n     Yes\n \n \n     win7\n     Chrome\n     73.0.3683.103\n     No\n \n \n     Office Word\n     All\n     Yes\n \n \n     Office Excel\n \n \n     Office PPT\n \n \n     WPS Word\n     11.1.0.9098\n     No\n \n \n     WPS Excel\n \n \n     WPS PPT\n     11.1.0.9098\n     Yes\n \n \n     Media Player (come with the system)\n     All\n     No",
        "parameters": [
            {
                "windowId": "The ID of the window to be shared."
            },
            {
                "rectangle": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n  If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            },
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopalleffects",
        "name": "stopAllEffects",
        "description": "Stops playing all audio effects.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiodeviceloopbacktest",
        "name": "stopAudioDeviceLoopbackTest",
        "description": "Stops the audio device loopback test.Ensure that you call this method to stop the loopback test after calling the startAudioDeviceLoopbackTest method.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiomixing",
        "name": "stopAudioMixing",
        "description": "Stops playing and mixing the music file.This method stops the audio mixing. Call this method when you are in a channel.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopaudiorecording",
        "name": "stopAudioRecording",
        "description": "Stops the audio recording on the client.This method needs to be called before leaveChannel; otherwise, the recording automatically stops when you call the leaveChannel method.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopchannelmediarelay",
        "name": "stopChannelMediaRelay",
        "description": "Stops the media stream relay. Once the relay stops, the host quits all the destination channels.Since\n                    v2.9.0\n                \n            \n            \n   After a successful method call, the SDK triggers the onChannelMediaRelayStateChanged callback. If the callback reports RELAY_STATE_IDLE(0) and RELAY_OK(0), the host successfully stops the relay.\n   If the method call fails, the SDK triggers the onChannelMediaRelayStateChanged callback with the RELAY_ERROR_SERVER_NO_RESPONSE(2) or RELAY_ERROR_SERVER_CONNECTION_LOST(8) status code. You can callleaveChannel the method to leave the channel, and the media stream relay automatically stops.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopdevicetest",
        "name": "stopDeviceTest",
        "description": "Stops the video-capture device test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopechotest",
        "name": "stopEchoTest",
        "description": "Stops the audio call test.",
        "parameters": [],
        "returns": "0: Success.\n                \n                    < 0: Failure.\n                        -5(ERR_REFUSED): Failed to stop the echo test. The echo test may not be running."
    },
    {
        "id": "api_stopeffect",
        "name": "stopEffect",
        "description": "Stops playing a specified audio effect.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoplastmileprobetest",
        "name": "stopLastmileProbeTest",
        "description": "Stops the last-mile network probe test.Since\n                    v2.4.0",
        "parameters": [],
        "returns": "0: Success.\n                < 0: Failure."
    },
    {
        "id": "api_stopplaybackdevicetest",
        "name": "stopPlaybackDeviceTest",
        "description": "Stops the audio playback device test.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoppreview",
        "name": "stopPreview",
        "description": "Stops the local video preview.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stoprecordingdevicetest",
        "name": "stopRecordingDeviceTest",
        "description": "Stops the audio capturing device test.This method stops the audio capturing device test. You must call this method to stop the test after calling the startRecordingDeviceTest method.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_stopscreencapture",
        "name": "stopScreenCapture",
        "description": "Stops screen sharing.",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_switchcamera",
        "name": "switchCamera",
        "description": "Switches between front and rear cameras.This method needs to be called after the camera is started (for example, by calling startPreview or joinChannel).",
        "parameters": [],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_switchchannel1",
        "name": "switchChannel[1/2]",
        "description": "Switches to a different channel.This method allows the audience of a LIVE_BROADCASTING channel to switch to a different channel.\n   After the user successfully switches to another channel, the onLeaveChannel and onJoinChannelSuccess callbacks are triggered to indicate that the user has left the original channel and joined a new one.\n   Once the user switches to another channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.",
        "parameters": [
            {
                "token": "The token generated at your server.\n                                In scenarios with low security requirements, token is optional and can be set as NULL.\n                                In scenarios with high security requirements, set the value to the token generated from your server. If you enable the App Certificate, you must use a token to join the channel.\n                            \n                            Ensure that the App ID used for creating the token is the sameApp ID used by the initialize method for initializing the RTC engine.\n                        "
            },
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n                                All lowercase English letters: a to z.\n                                All uppercase English letters: A to Z.\n                                All numeric characters: 0 to 9.\n                                Space\n                                \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n                            \n  "
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -5(ERR_REFUSED): The request is rejected. The role of the remote user is not AUDIENCE.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -102(ERR_INVALID CHANNEL_NAME): The channel name is invalid. Please use a valid channel name.\n  -113(ERR_NOT_IN_CHANNEL): The user is not in the channel."
    },
    {
        "id": "api_switchchannel2",
        "name": "switchChannel[2/2]",
        "description": "Switches to a different channel, and configures whether to automatically subscribe to audio or video streams in the target channel.Since\n  v3.3.0\n       \n   \n   This method allows the audience of a LIVE_BROADCASTING channel to switch to a different channel.\n   After the user successfully switches to another channel, the onLeaveChannel and onJoinChannelSuccess callbacks are triggered to indicate that the user has left the original channel and joined a new one.\n   Once the user switches to another channel, the user subscribes to the audio and video streams of all the other users in the channel by default, giving rise to usage and billing calculation. If you do not want to subscribe to a specified stream or all remote streams, call the mute methods accordingly.",
        "parameters": [
            {
                "token": "The token generated at your server.\n      In scenarios with low security requirements, token is optional and can be set as NULL.\n      In scenarios with high security requirements, set the value to the token generated from your server. If you enable the App Certificate, you must use a token to join the channel.\n  \n      Ensure that the App ID used for creating the token is the same App ID used by the initialize method for initializing the RTC engine.\n  "
            },
            {
                "channelId": "\n      The channel name. This parameter signifies the channel in which users engage in real-time audio and video interaction. Under the premise of the same App ID, users who fill in the same channelId enter the same channel for audio and video interaction. The string length must be less than 64 bytes. Supported characters:\n All lowercase English letters: a to z.\n All uppercase English letters: A to Z.\n All numeric characters: 0 to 9.\n Space\n \"!\"、\"#\"、\"$\"、\"%\"、\"&\"、\"(\"、\")\"、\"+\"、\"-\"、\":\"、\";\"、\"<\"、\"=\"、\".\"、\">\"、\"?\"、\"@\"、\"[\"、\"]\"、\"^\"、\"_\"、\"{\"、\"}\"、\"|\"、\"~\"、\",\"\n      \n  "
            },
            {
                "options": "The channel media options. See ChannelMediaOptions."
            }
        ],
        "returns": "0(ERR_OK): Success.\n       < 0: Failure.\n  -1(ERR_FAILED): A general error occurs (no specified reason).\n  -2 (ERR_INVALID_ARGUMENT): The parameter is invalid.\n  -5(ERR_REFUSED): The request is rejected. The role of the remote user is not AUDIENCE.\n  -7(ERR_NOT_INITIALIZED): The SDK is not initialized.\n  -102(ERR_INVALID CHANNEL_NAME): The channel name is invalid. Please use a valid channel name.\n  -113(ERR_NOT_IN_CHANNEL): The user is not in the channel."
    },
    {
        "id": "api_unloadeffect",
        "name": "unloadEffect",
        "description": "Releases a specified preloaded audio effect from the memory.",
        "parameters": [
            {
                "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_updatechannelmediarelay",
        "name": "updateChannelMediaRelay",
        "description": "Updates the channels for media stream relay.After the media relay starts, if you want to relay the media stream to more channels, or leave the current relay channel, you can call the updateChannelMediaRelay method.\n   After a successful method call, the SDK triggers the onChannelMediaRelayEvent callback with the RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL(7) state code.\n   Call this method after the startChannelMediaRelay method to update the destination channel.",
        "parameters": [
            {
                "configuration": "The configuration of the media stream relay. For details, see ChannelMediaRelayConfiguration."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure."
    },
    {
        "id": "api_updatescreencaptureparameters",
        "name": "updateScreenCaptureParameters",
        "description": "Updates the screen sharing parameters.Since\n  v2.4.0",
        "parameters": [
            {
                "captureParams": "The screen sharing encoding parameters. The default video dimension is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges. See ScreenCaptureParameters."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_updatescreencaptureregion1",
        "name": "updateScreenCaptureRegion [1/2]",
        "description": "Updates the screen sharing region.Since\n  v2.4.0",
        "parameters": [
            {
                "rect": "(Optional) The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. It consists of the following parameters:\n      x: The horizontal offset from the top-left corner.\n      y: The vertical offset from the top-left corner.\n      width: The width of the region.\n      height: The height of the region.\n  \n      If the specified region overruns the window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole window.\n  "
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n  -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_updatescreencaptureregion2",
        "name": "updateScreenCaptureRegion [2/2]",
        "description": "Updates the screen sharing region.Deprecated:\n  This method is deprecated as of v2.4.0. Agora recommends using updateScreenCaptureRegion instead.",
        "parameters": [
            {
                "rect": "The relative location of the region to the screen or window. If you do not set this parameter, the SDK shares the whole screen. See Rect. If the specified region overruns the screen or window, the SDK shares only the region within it; if you set width or height as 0, the SDK shares the whole screen or window."
            }
        ],
        "returns": "0: Success.\n       < 0: Failure.\n      -3(ERR_NOT_READY): No screen or window is being shared."
    },
    {
        "id": "api_uploadlogfile",
        "name": "uploadLogFile",
        "description": "Uploads all SDK log files.Since\n  v3.3.0\n       \n   \n   Uploads all SDK log files from the client to the Agora server. After calling this method successfully, the SDK triggers the onUploadLogFile callback to report whether the log file is successfully uploaded to the Agora server.\n   This method cannot be called more than once per minute; otherwise, the SDK returns NULL.\n   For easier debugging, Agora recommends that you bind the uploadLogFile method to the UI element of your app, to instruct the user to upload a log file when a quality issue occurs.",
        "parameters": [],
        "returns": "The method call succeeds: Return the request ID. The request ID is the same as the requestId in the onUploadLogFile callback. You can use the requestId to match a specific upload with a callback.\n       The method callI fails: Returns NULL. Probably because the method call frequency exceeds the limit."
    },
    {
        "id": "class_audioframe",
        "name": "AudioFrame",
        "description": "The definition of AudioFrame.",
        "parameters": [
            {
                "type": "\n      The type of the audio frame. See AUDIO_FRAME_TYPE.\n      "
            },
            {
                "samples": "The number of samples per channel in the audio frame."
            },
            {
                "bytesPerSample": "The number of bytes per audio sample, which is usually 16-bit (2-byte)."
            },
            {
                "channels": "\n      The number of audio channels (the data are interleaved if stereo).\n     1: Mono.\n     2: Stereo.\n \n  "
            },
            {
                "samplesPerSec": "The number of samples per channel in the audio frame."
            },
            {
                "buffer": "\n      The data buffer of the audio frame. When the audio frame uses a stereo channel, the data buffer is interleaved.\n      The size of the data buffer is as follows: buffer = samples ×channels × bytesPerSample.\n  "
            },
            {
                "renderTimeMs": "\n      The timestamp (ms) of the external audio frame.\n      You can use this timestamp to restore the order of the captured audio frame, and synchronize audio and video frames in video scenarios, including scenarios where external video sources are used.\n  "
            },
            {
                "avsync_type": "A reserved parameter."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_audiovolumeinfo",
        "name": "AudioVolumeInfo",
        "description": "The volume information of users.",
        "parameters": [
            {
                "uid": "\n      The user ID.\n     In the local user's callback, uid = 0.\n     In the remote users' callback, uid is the ID of a remote user whose instantaneous volume is one of the three highest.\n \n      \n  "
            },
            {
                "volume": "The volume of the user. The value ranges between 0 (lowest volume) and 255 (highest volume). If the user callsstartAudioMixing , then volume is the volume after audio mixing."
            },
            {
                "vad": "\n      Voice activity status of the local user.\n     0: The local user is not speaking.\n     1: The local user is speaking.\n \n      \n      \n \n     The vad parameter cannot report the voice activity status of remote users. In the remote users' callback, the value of vad is always 0.\n     To use this parameter, you mustenableAudioVolumeIndication set report_vad totrue when calling .\n \n      \n  "
            },
            {
                "channelId": "The name of the channel where the user is in."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_beautyoptions",
        "name": "BeautyOptions",
        "description": "Image enhancement options.",
        "parameters": [
            {
                "lighteningContrastLevel": "The contrast level. See LIGHTENING_CONTRAST_LEVEL."
            },
            {
                "lighteningLevel": "The brightness level. The value ranges from 0.0 (original) to 1.0. This parameter adjusts the red saturation level."
            },
            {
                "smoothnessLevel": "The sharpness level. The value ranges between 0 (original) and 1. This parameter is usually used to remove blemishes."
            },
            {
                "rednessLevel": "The redness level. The value ranges between 0 (original) and 1. This parameter adjusts the red saturation level."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_cameracapturerconfiguration",
        "name": "CameraCapturerConfiguration",
        "description": "Camera capture preference.",
        "parameters": [
            {
                "preference": "Camera capture preference settings. See CAPTURER_OUTPUT_PREFERENCE."
            },
            {
                "captureWidth": "\n                        \n                            \n                                Since\n                                v3.3.0\n                            \n                        \n                        The width (px) of the video image captured by the local camera. To customize the width of the video image, set preference as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3) first, and then use captureWidth.\n                    "
            },
            {
                "captureHeight": "\n                        \n                            \n                                Since\n                                v3.3.0\n                            \n                        \n                        The height (px) of the video image captured by the local camera. To customize the height of the video image, set preference as CAPTURER_OUTPUT_PREFERENCE_MANUAL(3) first, and then use captureHeight.\n                    "
            },
            {
                "cameraDirection": "\n      Camera direction. See CAMERA_DIRECTION.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediainfo",
        "name": "ChannelMediaInfo",
        "description": "The definition of ChannelMediaInfo.",
        "parameters": [
            {
                "channelName": "The channel name."
            },
            {
                "token": "The token that enables the user to join the channel."
            },
            {
                "uid": "The user ID."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediaoptions",
        "name": "ChannelMediaOptions",
        "description": "The channel media options.",
        "parameters": [
            {
                "autoSubscribeAudio": "Whether to automatically subscribe to all remote audio streams when the user joins a channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteAudioStreams method. After joining the channel, you can call the muteAllRemoteAudioStreams method to set whether to subscribe to audio streams in the channel."
            },
            {
                "audioSubscribeVideo": "Whether to subscribe to video streams when the user joins the channel:\n      true: (Default) Subscribe.\n      false: Do not subscribe.\n  This member serves a similar function to the muteAllRemoteVideoStreams method. After joining the channel, you can call the muteAllRemoteVideoStreams method to set whether to subscribe to video streams in the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_channelmediarelayconfiguration",
        "name": "ChannelMediaRelayConfiguration",
        "description": "The definition of ChannelMediaRelayConfiguration.",
        "parameters": [
            {
                "srcInfo": "\n                        Pointer to the information of the source channel:ChannelMediaInfo. It contains the following members:\n                                channelName: The name of the source channel. The default value is NULL, which means the SDK applies the name of the current channel.\n                                uid: The unique ID to identify the relay stream in the source channel. The default value is 0, which means the SDK generates a random UID. You must set it as 0.\n                                token: The token for joining the source channel. It is generated with the channelName and uid you set in srcInfo.\n                                        If you have not enabled the App Certificate, set this parameter as the default value NULL, which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid, and the uid must be set as 0.\n                                    \n                                \n                            \n                        \n                    "
            },
            {
                "destInformation": "\n                        Pointer to the information of the destination channel: ChannelMediaInfo. It contains the following members:\n                                channelName: The name of the destination channel.\n                                uid: The unique ID to identify the relay stream in the destination channel. The value ranges from 0 to (232-1). To avoid UID conflicts, this uid must be different from any other UIDs in the destination channel. The default value is 0, which means the SDK generates a random UID. Do not set this parameter as the `uid` of the host in the destination channel, and ensure that this `uid` is different from any other `uid` in the channel.\n                                token: The token for joining the destination channel. It is generated with the channelName and uid you set in destInfos.\n                                        If you have not enabled the App Certificate, set this parameter as the default value NULL, which means the SDK applies the App ID.\n                                        If you have enabled the App Certificate, you must use the token generated with the channelName and uid.\n                                    \n                                \n                            \n                        \n                    "
            },
            {
                "destCount": "The number of destination channels. The default value is 0, and the value range is from 0 to 4. Ensure that the value of this parameter corresponds to the number of ChannelMediaInfo structs you define in destInfos."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_clientroleoptions",
        "name": "ClientRoleOptions",
        "description": "The detailed options of a user.",
        "parameters": [
            {
                "audienceLatencyLevel": "The latency level of an audience member in interactive live streaming. See AUDIENCE_LATENCY_LEVEL_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_datastreamconfig",
        "name": "DataStreamConfig",
        "description": "The configurations for the data stream.The following table shows the SDK behaviors under different parameter settings:\n   \n       \n  \n  \n  \n  \n      \n syncWithAudio\n ordered\n SDK behaviors\n      \n      \n false\n false\n The SDK triggers the onStreamMessage callback immediately after the receiver receives a data packet.\n      \n      \n true\n false\n If the data packet delay is within the audio delay, the SDK triggers the onStreamMessage callback when the synchronized audio packet is played out. If the data packet delay exceeds the audio delay, the SDK triggers the onStreamMessage callback as soon as the data packet is received.\n      \n      \n false\n true\n In this case, the data packet is not synchronized with the audio packet. If the delay of a data packet is within five seconds, the SDK corrects the order of the data packet.\n      \n      \n true\n true\n If the delay of a data packet exceeds five seconds, the SDK discards the data packet. If the delay of a data packet exceeds the audio delay, the SDK discards this data packet.",
        "parameters": [
            {
                "syncWithAudio": "\n                        Whether to synchronize the data packet with the published audio packet.\n                                true: Synchronize the data packet with the audio packet.\n                                false: Do not synchronize the data packet with the audio packet.\n                            When you set the data packet to synchronize with the audio, then if the data packet delay is within the audio delay, the SDK triggers the onStreamMessage callback when the synchronized audio packet is played out. Do not set this parameter as true if you need the receiver to receive the data packet immediately. Agora recommends that you set this parameter to `true` only when you need to implement specific functions, for example lyric synchronization.\n                    "
            },
            {
                "ordered": "\n                        Whether the SDK guarantees that the receiver receives the data in the sent order.\n                                true: Guarantee that the receiver receives the data in the sent order.\n                                false: Do not guarantee that the receiver receives the data in the sent order.\n                            Do not set this parameter as true if you need the receiver to receive the data packet immediately.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_encryptionconfig",
        "name": "EncryptionConfig",
        "description": "Configurations of built-in encryption.",
        "parameters": [
            {
                "encryptionMode": "Encryption mode. The default encryption mode is AES_128_XTS. See ENCRYPTION_MODE."
            },
            {
                "encryptionKey": "\n      Encryption key in string type.\n      If you do not set an encryption key or set it as NULL, you cannot use the built-in encryption, and the SDK returns ERR_INVALID_ARGUMENT (-2).\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_externalvideoframe",
        "name": "ExternalVideoFrame",
        "description": "The external video frame.",
        "parameters": [
            {
                "type": "\n      The buffer type. See VIDEO_BUFFER_TYPE.\n      "
            },
            {
                "format": "The pixel format. See VIDEO_PIXEL_FORMAT."
            },
            {
                "buffer": "The video buffer."
            },
            {
                "stride": "Line spacing of the incoming video frame, which must be in pixels instead of bytes. For textures, it is the width of the texture."
            },
            {
                "height": "Height of the incoming video frame."
            },
            {
                "cropLeft": "[Raw data related parameter] The number of pixels trimmed from the left. The default value is 0."
            },
            {
                "cropTop": "[Raw data related parameter] The number of pixels trimmed from the top. The default value is 0."
            },
            {
                "cropRight": "[Raw data related parameter] The number of pixels trimmed from the right. The default value is 0."
            },
            {
                "cropBottom": "[Raw data related parameter] The number of pixels trimmed from the bottom. The default value is 0."
            },
            {
                "rotation": "[Raw data related parameter] The clockwise rotation of the video frame. You can set the rotation angle as 0, 90, 180, or 270. The default value is 0."
            },
            {
                "timestamp": "Timestamp (ms) of the incoming video frame. An incorrect timestamp results in frame loss or unsynchronized audio and video."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_iaudiodevicecollection",
        "name": "IAudioDeviceCollection",
        "description": "The IAudioDeviceCollection interface.  enables you to get device-related information.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_iaudiodevicemanager",
        "name": "IAudioDeviceManager",
        "description": "Audio device management methods.IAudioDeviceManager allows for audio device interface testing. You can get an IAudioDeviceManager interface by instantiating the IAudioDeviceManager class.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_iaudioframeobserver",
        "name": "IAudioFrameObserver",
        "description": "The audio frame observer.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ichannel",
        "name": "IChannel",
        "description": "Call createChannel to create an IChannel object.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ichanneleventhandler",
        "name": "IChannelEventHandler",
        "description": " IChannelEventHandler is used by the SDK to send IChannel event notifications to your app.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_imediaengine",
        "name": "IMediaEngine",
        "description": "IMediaEngine Class.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_imetadataobserver",
        "name": "IMetadataObserver",
        "description": "Metadata observer.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_injectstreamconfig",
        "name": "InjectStreamConfig",
        "description": "Configurations of injecting an external audio or video stream.Agora will soon stop the service for injecting online media streams on the client. If you have not implemented this service, Agora recommends that you do not use it. For details, see .",
        "parameters": [
            {
                "width": "The width of the external video stream after injecting. The default value is 0, which represents the same width as the original."
            },
            {
                "height": "The height of the external video stream after injecting. The default value is 0, which represents the same height as the original."
            },
            {
                "videoGop": "The GOP (in frames) of injecting the external video stream. The default value is 30 frames."
            },
            {
                "videoFramerate": "The frame rate (fps) of injecting the external video stream. The default rate is 15 fps."
            },
            {
                "videoBitrate": "\n                        The bitrate (Kbps) of injecting the external video stream. The default value is 400 Kbps.\n                        The bitrate setting is closely linked to the video resolution. If the bitrate you set is beyond a reasonable range, the SDK sets it within a reasonable range.\n                    "
            },
            {
                "audioSampleRate": "The sampling rate (Hz) of injecting the external audio stream. The default value is 48000 Hz. See AUDIO_SAMPLE_RATE_TYPE.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioBitrate": "\n                        The bitrate (Kbps) of injecting the external audio stream. The default value is 48 Kbps.\n                        Agora recommends using the default value.\n                    "
            },
            {
                "audioChannels": "\n                        The number of channels of the external audio stream after injecting.\n                                1: Mono (default)\n                                2: Stereo.\n                            \n                        \n                        Agora recommends using the default value.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_ipacketobserver",
        "name": "IPacketObserver",
        "description": "Definition of IPacketObserver.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_rtcengine",
        "name": "IRtcEngine",
        "description": "The basic interface class of the Agora Native SDK that implements the core functions of real-time communication.IRtcEngine provides the main methods that your app can call.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_irtcengine2",
        "name": "IRtcEngine2",
        "description": "Inherited from IRtcEngine.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_rtcengineeventhandler",
        "name": "IRtcEngineEventHandler",
        "description": " The IRtcEngineEventHandler interface class is used by the SDK to send event notifications to your app. Your app can get those notifications through methods that inherit this interface class.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ivideodevicecollection",
        "name": "IVideoDeviceCollection",
        "description": " You can get information related to video devices through this interface class.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ivideodevicemanager",
        "name": "IVideoDeviceManager",
        "description": "Video device management methods.IVideoDeviceManager provides the interfaces related to testing video devices. You can get an IVideoDeviceManager interface by instantiating the IVideoDeviceManager class.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ivideoframeconsumer",
        "name": "IVideoFrameConsumer",
        "description": "IVideoFrameConsumer is used by the SDK to receive the video frames you capture.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ivideoframeobserver",
        "name": "IVideoFrameObserver",
        "description": "The class for video frame observers.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_ivideosource",
        "name": "IVideoSource",
        "description": "The IVideoSource class. You can use it to customize the video source.",
        "parameters": [],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeconfig",
        "name": "LastmileProbeConfig",
        "description": "Configurations of the last-mile network test.",
        "parameters": [
            {
                "probeUplink": "Sets whether to test the uplink network. Some users, for example, the audience members in a LIVE_BROADCASTING channel, do not need such a test.\n true: Test.\n false: Not test.\n      \n      \n  "
            },
            {
                "probeDownlink": "\n      Sets whether to test the downlink network:\n     true: Test.\n     false: Not test.\n \n      \n  "
            },
            {
                "expectedUplinkBitrate": "The expected maximum uplink bitrate (bps) of the local user. The value range is [100000, 5000000]. Agora recommends referring to setVideoEncoderConfiguration to set the value."
            },
            {
                "expectedDownlinkBitrate": "The expected maximum downlink bitrate (bps) of the local user. The value range is [100000,5000000]."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileprobeonewayresult",
        "name": "LastmileProbeOneWayResult",
        "description": "Results of the uplink or downlink last-mile network test.",
        "parameters": [
            {
                "packetLossRate": "The packet loss rate (%)."
            },
            {
                "jitter": "The network jitter (ms)."
            },
            {
                "availableBandwidth": "The estimated available bandwidth (bps)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_lastmileproberesult",
        "name": "LastmileProbeResult",
        "description": "Results of the uplink and downlink last-mile network tests.",
        "parameters": [
            {
                "state": "The status of the last-mile network tests. See LASTMILE_PROBE_RESULT_STATE."
            },
            {
                "uplinkReport": "Results of the uplink last-mile network test. See LastmileProbeOneWayResult."
            },
            {
                "downlinkReport": "Results of the downlink last-mile network test. See LastmileProbeOneWayResult."
            },
            {
                "rtt": "The round-trip time (ms)."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_livetranscoding",
        "name": "LiveTranscoding",
        "description": "Transcoding configurations for CDN live streaming.",
        "parameters": [
            {
                "width": "\n                        The width of the output media stream in pixels. The default value is 360.\n                        \n                            When the output media stream is video, ensure that width is set to 64 or higher. Otherwise, the Agora server adjusts the value to 64.\n                            When the output media stream is audio, setwidth to 0.\n                        \n                    "
            },
            {
                "height": "\n      The height of the output media stream in pixels. The default value is 640.\n      \n When the output media stream is video, ensure that height is set to 64 or higher. Otherwise, the Agora server adjusts the value to 64.\n When the output media stream is audio, set height to 0.\n      \n  "
            },
            {
                "videoBitrate": "The video bitrate (Kbps) of the output media stream. The default value is 400. You can refer to  to set this paramter."
            },
            {
                "videoFrameRate": "The video frame rate (fps) of the output media stream. The default value is 15, and the value range is [1,30].The Agora server adjusts any value over 30 fps to 30 fps."
            },
            {
                "lowLatency": "\n      \n \n     Deprecated\n     This attribute is deprecated since v2.8.0, and Agora does not recommend it.\n \n      \n      \n true: Low latency with unassured quality.\n false: (Default) High latency with assured quality.\n      \n  "
            },
            {
                "videoGop": "The video GOP (Group of Pictures) of the output media stream. The default value is 30."
            },
            {
                "videoCodecProfile": "\n  The video encoding specifications of the output media stream. See VIDEO_CODEC_PROFILE_TYPE.\n  If you set this parameter to other values, Agora adjusts it to the default value.\n       "
            },
            {
                "backgroundColor": "The video background color of the output media stream. The format is a hexadecimal integer defined by RGB without the # symbol. For example, 0xFFB6C1 represents light pink. The default value is 0x000000 (black)."
            },
            {
                "userCount": "The number of hosts involved in transcoding. The default value is 0."
            },
            {
                "transcodingUsers": "\n      Transcoding configurations of each host. One live streaming channel supports up to 17 hosts. See TranscodingUser.\n  "
            },
            {
                "transcodingExtraInfo": "The user SEI information embedded in the output media stream. This parameter is used to send SEI information to the CDN. The maximum length is 4096 bytes. See ."
            },
            {
                "metadata": "\n      \n \n     Deprecated:\n     This attribute is deprecated.\n \n      The metadata sent to the CDN client."
            },
            {
                "watermark": "The video watermark of the output media stream. Ensure that the format of the watermark image is PNG. See RtcImage."
            },
            {
                "backgroundImage": "The video background image of the output media stream. See RtcImage."
            },
            {
                "audioSampleRate": "The audio sampling rate (Hz) of the output media stream. See AUDIO_SAMPLE_RATE_TYPE."
            },
            {
                "audioBitrate": "The audio bitrate (Kbps) of the output media stream. The default value is 48, and the maximum is 128."
            },
            {
                "audioChannels": "The number of audio channels of the output media stream. The default value is 1. Agora recommends setting it to 1 or 2.\n      1: (Default) Mono\n      2: Stereo.\n      3: Three audio channels\n      4: Four audio channels\n      5: Five audio channels\n      \n  "
            },
            {
                "audioCodecProfile": "The audio codec of the media stream. See AUDIO_CODEC_PROFILE_TYPE."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localaudiostats",
        "name": "LocalAudioStats",
        "description": "Local audio statistics.",
        "parameters": [
            {
                "numChannels": "The number of audio channels."
            },
            {
                "sentSampleRate": "The sampling rate (Hz) of sending the local user's audio stream."
            },
            {
                "sentBitrate": "The average bitrate (Kbps) of sending the local user's audio stream."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the local client to the Agora edge server before applying the anti-packet loss strategies."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_localvideostats",
        "name": "LocalVideoStats",
        "description": "Local video stream statistics.",
        "parameters": [
            {
                "sentBitrate": "\n      The actual bitrate (Kbps) while sending the local video stream.This value does not include the bitrate while resending the video after packet loss.\n  "
            },
            {
                "sentFrameRate": "The actual frame rate (Kbps) while sending the local video stream.This value does not include the frame rate while resending the video after packet loss."
            },
            {
                "encoderOutputFrameRate": "The output frame rate (fps) of the local video encoder."
            },
            {
                "rendererOutputFrameRate": "The output frame rate (fps) of the local video renderer."
            },
            {
                "targetBitrate": "The target bitrate (Kbps) of the current encoder. This is an estimate made by the SDK based on the current network conditions."
            },
            {
                "targetFrameRate": "The target frame rate (fps) of the current encoder."
            },
            {
                "qualityAdaptIndication": "Quality adaption of the local video stream in the reported interval (in terms of the target frame rate and target bitrate). See QUALITY_ADAPT_INDICATION."
            },
            {
                "encodedBitrate": "\n      The bitrate (Kbps) while encoding the local video stream.This value does not include the bitrate while resending the video after packet loss.\n  "
            },
            {
                "encodedFrameWidth": "The width of the encoded video (px)."
            },
            {
                "encodedFrameHeight": "The height of the encoded video (px)."
            },
            {
                "encodedFrameCount": "The number of sent video frames, represented by an aggregate value."
            },
            {
                "CodecType: Encoding type of the sent audio.": "The codec type of the local video stream. See VIDEO_CODEC_TYPE."
            },
            {
                "txPacketLossRate": "The video packet loss rate (%) from the local client to the Agora edge server before applying the anti-packet loss strategies."
            },
            {
                "captureFrameRate": "The capture frame rate (fps) of the local video stream."
            },
            {
                "captureBrightnessLevel": "\n      \n \n     Since\n     v3.3.0\n \n      \n      The brightness level of the image captured by the local camera. See CAPTURE_BRIGHTNESS_LEVEL_TYPE.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_logconfig",
        "name": "LogConfig",
        "description": "The configuration of the SDK log files.Since\n  v3.3.0",
        "parameters": [
            {
                "filePath": "The absolute path of the log files.\n  The default paths for different platforms are as follows:\n      Android: /storage/emulated/0/Android/data/<package name>/files/agorasdk.log\n      iOS: App Sandbox/Library/caches/agorasdk.log\n      macOS:\n If Sandbox is enabled: App Sandbox/Library/Logs/agorasdk.log, for example, /Users/<username>/Library/Containers/<App Bundle Identifier>/Data/Library/Logs/agorasdk.log.\n If Sandbox is disabled: ~/Library/Logs/agorasdk.log\n      \n      Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log。\n  \n  Ensure that the directory for the log files exists and is writable. You can use this parameter to rename the log files."
            },
            {
                "fileSize": "The size (KB) of a log file. The default value is 2014 KB. If you set fileSize to 1024 KB, the maximum aggregate size of the log files output by the SDK is 5 MB. If you set fileSize to less than 1024 KB, the setting is invalid, and the maximum size of a log file is still 1024 KB."
            },
            {
                "level": "The output level of the SDK log file. See LOG_LEVEL."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_metadata",
        "name": "Metadata",
        "description": "Media metadata",
        "parameters": [
            {
                "uid": "\n      The user ID.\n For the receiver: The user ID of the user who sent the Metadata.\n     For the sender: ignore it.\n \n  "
            },
            {
                "size": "The buffer size of the sent or received Metadata."
            },
            {
                "buffer": "The buffer address of the sent or received Metadata ."
            },
            {
                "timeStampMs": "The timestamp (ms) of the Metadata."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_packet",
        "name": "Packet",
        "description": " Definition of Packet.",
        "parameters": [
            {
                "buffer": "\n      The buffer address of the sent or received data.\n      Agora recommends setting buffer to a value larger than 2048 bytes. Otherwise, you may encounter undefined behaviors (such as crashes).\n  "
            },
            {
                "size": "The buffer size of the sent or received data."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rect",
        "name": "Rect",
        "description": "The screen-shared area.Deprecated:\n  This class is deprecated. Please use the updateScreenCaptureRegion [1/2] method to update the shared area.",
        "parameters": [
            {
                "top": "The coordinate of the top side of the shared area on the vertical axis."
            },
            {
                "left": "The coordinate of the left side of the shared area on the horizontal axis."
            },
            {
                "bottom": "The coordinate of the bottom side of the shared area on the vertical axis."
            },
            {
                "right": "The coordinate of the right side of the shared area on the horizontal axis."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rectangle",
        "name": "Rectangle",
        "description": "The relative location of the screen-shared area to the screen or window. If you do not set this parameter, the SDK shares the whole screen or window. ",
        "parameters": [
            {
                "x": "The horizontal offset from the top-left corner."
            },
            {
                "y": "The vertical offset from the top-left corner."
            },
            {
                "width": "The width of the shared area."
            },
            {
                "height": "The height of the shared area."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remoteaudiostats",
        "name": "RemoteAudioStats",
        "description": "Audio statistics of the remote user.",
        "parameters": [
            {
                "uid": "The ID of the remote user sending the stream."
            },
            {
                "quality": "The quality of the audio stream sent by the user. See QUALITY_TYPE."
            },
            {
                "networkTransportDelay": "The network delay (ms) from the audio sender to the receiver."
            },
            {
                "jitterBufferDelay": "\n      The network delay (ms) from the audio receiver to the jitter buffer.This parameter does not take effect if the receiver is an audience member and AUDIENCE_LATENCY_LEVEL_TYPE is 1.\n  "
            },
            {
                "audioLossRate": "The frame loss rate (%) of the remote audio stream in the reported interval."
            },
            {
                "numChannels": "The number of audio channels."
            },
            {
                "receivedSampleRate": "The sampling rate of the received remote audio stream in the reported interval."
            },
            {
                "receivedBitrate": "The average bitrate (Kbps) of the received audio stream in the reported interval."
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote audio stream after the remote user joins the channel. In a session, audio freeze occurs when the audio frame loss rate reaches 4%."
            },
            {
                "frozenRate": "The total audio freeze time as a percentage (%) of the total time when the audio is available. The audio is available means that the remote user neither stops sending the audio stream nor disables the audio module after joining the channel."
            },
            {
                "totalActiveTime": "The total time (ms) when the remote user in the COMMUNICATION profile or the remote host in the LIVE_BROADCASTING profile neither stops sending the audio stream nor disables the audio module after joining the channel."
            },
            {
                "publishDuration": "The total duration (ms) of the published remote audio stream."
            },
            {
                "qoeQuality": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Quality of experience (QoE) of the local user when receiving the remote audio streamEXPERIENCE_QUALITY_TYPE.\n  "
            },
            {
                "qualityChangedReason": "\n      \n \n     Since\n     v3.3.0\n \n      \n      The reason for poor QoE of the local user when receiving the remote audio streamEXPERIENCE_POOR_REASON.\n  "
            },
            {
                "mosValue": "\n               \n                   \n                       Since\n                       v3.3.1\n                   \n               \n               The quality of the remote audio stream in the reported interval. The quality is determined by the Agora real-time audio MOS (Mean Opinion Score) measurement method. The return value range is [0, 500]. Dividing the return value by 100 gets the MOS score, which ranges from 0 to 5. The higher the score, the better the audio quality.\n               \n               The subjective perception of audio quality corresponding to the Agora real-time audio MOS scores is as follows:\n                                \n                                    MOS score\n                                    Perception of audio quality\n                                \n                                \n                                    Greater than 4\n                                    Excellent. The audio sounds clear and smooth.\n                                \n                                \n                                    From 3.5 to 4\n                                    Good. The audio has some perceptible impairment but still sounds clear.\n                                \n                                \n                                    From 3 to 3.5\n                                    Fair. The audio freezes occasionally and requires attentive listening.\n                                \n                                \n                                    From 2.5 to 3\n                                    Poor. The audio sounds choppy and requires considerable effort to understand.\n                                \n                                \n                                    From 2 to 2.5\n                                    Bad. The audio has occasional noise. Consecutive audio dropouts occur, resulting in some information loss. The users can communicate only with difficulty.\n                                \n                                \n                                    Less than 2\n                                    Very bad. The audio has persistent noise. Consecutive audio dropouts are frequent, resulting in severe information loss. Communication is nearly impossible.\n                                \n                            \n           "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_remotevideostats",
        "name": "RemoteVideoStats",
        "description": "Statistics of the remote video stream.",
        "parameters": [
            {
                "uid": "The user ID of the remote user sending the video stream."
            },
            {
                "delay": "\n      \n \n     Deprecated:\n     In scenarios where audio and video are synchronized, you can get the video delay data from networkTransportDelay and jitterBufferDelay in RemoteAudioStats.\n \n      \n      The video delay (ms).\n  "
            },
            {
                "width": "The width (pixels) of the video."
            },
            {
                "height": "The height (pixels) of the video."
            },
            {
                "receivedBitrate": "The bitrate (Kbps) of receiving the remote video since the last count."
            },
            {
                "decoderOutputFrameRate": "The frame rate (fps) of decoding the remote video."
            },
            {
                "rendererOutputFrameRate": "The frame rate (fps) of rendering the remote video."
            },
            {
                "packetLossRate": "The packet loss rate (%) of the remote video after using the anti-packet-loss technology."
            },
            {
                "rxStreamType": "The type of the video stream. See REMOTE_VIDEO_STREAM_TYPE."
            },
            {
                "totalFrozenTime": "The total freeze time (ms) of the remote video stream after the remote user joins the channel. In a video session where the frame rate is set to no less than 5 fps, video freeze occurs when the time interval between two adjacent renderable video frames is more than 500 ms."
            },
            {
                "frozenRate": "The total video freeze time as a percentage (%) of the total time when the video is available. The video is available means that the remote user neither stops sending the video stream nor disables the video module after joining the channel."
            },
            {
                "totalActiveTime": "The total time (ms) when the remote user in the COMMUNICATION profile or the remote host in the LIVE_BROADCASTING profile neither stops sending the video stream nor disables the video module after joining the channel."
            },
            {
                "publishDuration": "The total duration (ms) of the published remote video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcengineconfig",
        "name": "RtcEngineContext",
        "description": "Configurations of initializing the SDK.",
        "parameters": [
            {
                "eventHandler": "The event handler of the Agora SDK. See IRtcEngineEventHandler."
            },
            {
                "mAppId": "The App ID issued by Agora for your app development project. Only users who use the same App ID can join the same channel and communicate with each other.\n      An App ID can only be used to create one IRtcEngine instance. If you need to change the App ID, you must call release destroy the current IRtcEngine, and then call initialize to recreateIRtcEngine.\n  "
            },
            {
                "context": "The video window handler. Once set, this parameter enables you to plug or unplug the video devices while they are powered."
            },
            {
                "areaCode": "The region for connection. This advanced feature applies to scenarios that have regional restrictions. See AREA_CODE for details about supported regions.\n  After specifying the region, the SDK connects to the Agora servers within that region."
            },
            {
                "logConfig": "The configuration of the log files. See LogConfig.\n  By default, the SDK outputs five log files: agorasdk.log, agorasdk_1.log, agorasdk_2.log, agorasdk_3.log, and agorasdk_4.log.\n  Each log file has a default size of 512 KB and is encoded in UTF-8 format. The SDK writes the latest log in agorasdk.log. When agorasdk.log is full, the SDK deletes the log file with the earliest modification time among the other four, renames agorasdk.log to the name of the deleted log file, and create a new agorasdk.log to record the latest log."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcimage",
        "name": "RtcImage",
        "description": "Image properties.This class sets the properties of the watermark and background images in the live video.",
        "parameters": [
            {
                "url": "\n      The HTTP/HTTPS URL address of the image in the live video. The maximum length of this parameter is 1024 bytes.\n      "
            },
            {
                "x": "The x coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "y": "The y coordinate (pixel) of the image on the video frame (taking the upper left corner of the video frame as the origin)."
            },
            {
                "width": "The width (pixel) of the image on the video frame."
            },
            {
                "height": "The height (pixel) of the image on the video frame."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_rtcstats",
        "name": "RtcStats",
        "description": "Statistics of a call session.",
        "parameters": [
            {
                "duration": "\n      Call duration of the local user in seconds, represented by an aggregate value.\n      "
            },
            {
                "txBytes": "The number of bytes sent."
            },
            {
                "rxBytes": "The number of bytes received."
            },
            {
                "txAudioBytes": "The total number of audio bytes sent, represented by an aggregate value."
            },
            {
                "txVideoBytes": "The total number of video bytes sent, represented by an aggregate value."
            },
            {
                "rxAudioBytes": "The total number of audio bytes received, represented by an aggregate value."
            },
            {
                "rxVideoBytes": "The total number of video bytes received, represented by an aggregate value."
            },
            {
                "txKBitRate": "The bitrate (Kbps) of sending data."
            },
            {
                "rxKBitRate": "The bitrate (Kbps) of receiving data."
            },
            {
                "rxAudioKBitRate": "The bitrate (Kbps) of receiving the audio."
            },
            {
                "txAudioKBitRate": "The bitrate (Kbps) of sending the audio packet."
            },
            {
                "rxVideoKBitRate": "The bitrate (Kbps) of receiving the video."
            },
            {
                "txVideoKBitRate": "The bitrate (Kbps) of sending the video."
            },
            {
                "lastmileDelay": "The client-to-server delay (milliseconds)."
            },
            {
                "txPacketLossRate": "The packet loss rate (%) from the client to the Agora server before using the anti-packet-loss method."
            },
            {
                "rxPacketLossRate": "The packet loss rate (%) from the Agora server to the client before using the anti-packet-loss method."
            },
            {
                "userCount": "The number of users in the channel.\n      For COMMUNICATION profile: The number of users in the channel.\n      For LIVE_BROADCASTING profile:\n If the local user is an audience member: The number of users in the channel = The number of hosts in the channel + 1.\n If the user is a host: The number of users in the channel = The number of hosts in the channel.\n      \n  \n  "
            },
            {
                "cpuAppUsage": "The CPU usage (%) of the application."
            },
            {
                "cpuTotalUsage": "\n      The system CPU usage (%).\n      In the multi-kernel environment, this member represents the average CPU usage. The value = 100 - System Idle Progress in Task Manager.\n  "
            },
            {
                "gatewayRtt": "The round-trip time delay from the client to the local router."
            },
            {
                "memoryAppUsageRatio": "\n      The memory occupied by the application (%).\n      This value is for reference only. Due to system limitations, you may not get this value.\n  "
            },
            {
                "memoryTotalUsageRatio": "\n      The memory occupied by the system (%).\n      This value is for reference only. Due to system limitations, you may not get this value.\n  "
            },
            {
                "memoryAppUsageInKbytes": "\n      The memory occupied by the application (KB).\n      This value is for reference only. Due to system limitations, you may not get this value.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_screencaptureparameters",
        "name": "ScreenCaptureParameters",
        "description": "Screen sharing configurations.",
        "parameters": [
            {
                "dimensions": "The maximum dimensions of encoding the shared region. See VideoDimensions. The default value is 1920 x 1080, that is, 2,073,600 pixels. Agora uses the value of this parameter to calculate the charges.\n                        If the screen dimensions are different from the value of this parameter, Agora applies the following strategies for encoding. Suppose dimensions are set to 1920 x 1080:\n                                If the value of the screen dimensions is lower than that of dimensions, for example, 1000 x 1000 pixels, the SDK uses 1000 x 1000 pixels for encoding.\n                                If the value of the screen dimensions is higher than that of dimensions, for example, 2000 x 1500, the SDK uses the maximum value next to 1920 x 1080 with the aspect ratio of the screen dimension (4:3) for encoding, that is, 1440 x 1080.\n                            \n                    "
            },
            {
                "frameRate": "The frame rate (fps) of the shared region. The default value is 5. Agora does not recommend setting it to a value greater than 15."
            },
            {
                "bitrate": "The bitrate (Kbps) of the shared region. The default value is 0, which represents that the SDK works out a bitrate according to the dimensions of the current screen."
            },
            {
                "captureMouseCursor": "\n                        \n                            \n                                Since\n                                v2.4.1\n                            \n                        \n                        Sets whether to capture the mouse in screen sharing:\n                                true: (Default) Capture the mouse.\n                                false: Do not capture the mouse.\n                            "
            },
            {
                "windowFocus": "\n                        \n                            Since\n                            v3.1.0\n                        \n                    Sets whether to bring the window to the front when calling the startScreenCaptureByWindowId method to share it:\n                            true: Bring the window to the front.\n                            false: (Default) Do not bring the window to the front.\n                        "
            },
            {
                "excludeWindowList": "\n                        \n                            \n                                Since\n                                v3.1.0\n                            \n                        \n                        The ID list of the windows to be blocked. When calling startScreenCaptureByDisplayId to start screen sharing, you can use this parameter to block a specified window. When calling updateScreenCaptureParameters to update screen sharing configurations, you can use this parameter to dynamically block a specified window."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_transcodinguser",
        "name": "TranscodingUser",
        "description": "Transcoding configurations of each host.",
        "parameters": [
            {
                "uid": "\n  The user ID of the host.\n       "
            },
            {
                "x": "\n  The x coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, width], where width is the width set in LiveTranscoding."
            },
            {
                "y": "The y coordinate (pixel) of the host's video on the output video frame (taking the upper left corner of the video frame as the origin). The value range is [0, height], where height is the height set in LiveTranscoding."
            },
            {
                "width": "The width (pixel) of the host's video."
            },
            {
                "height": "\n                        The height (pixel) of the host's video.\n                    "
            },
            {
                "zOrder": "\n                        The layer number of the host's video. The value ranges from 0 to 100.\n                                0: (Default) The host's video is the bottom layer.\n                                100: The host's video is the top layer.\n                            \n                        \n                        \n                            \n                                If the value is beyond this range, the SDK reports the error code ERR_INVALID_ARGUMENT.\n                                As of v2.3, the SDK supports setting zOrder to 0.\n                            \n                        \n                    "
            },
            {
                "alpha": "\n                        The transparency of the host's video. The value ranges between 0.0 and 1.0.\n                                0.0: Completely transparent.\n                                1.0: (Default) Opaque.\n                            \n                        \n                    "
            },
            {
                "audioChannel": "\n                        The audio channel used by the host's audio in the output audio. The default value is 0, and the value range is [0, 5].\n                                0: (Recommended) The defaut setting, which supports dual channels at most and depends on the upstream of the host.\n                                1: The host's audio uses the FL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                2: The host's audio uses the FC audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                3: The host's audio uses the FR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                4: The host's audio uses the BL audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                5: The host's audio uses the BR audio channel. If the host's upstream uses multiple audio channels, the Agora server mixes them into mono first.\n                                0xFF or a value greater than 5: The host's audio is muted, and the Agora server removes the host's audio.\n                            \n                            If the value is not 0, a special player is required.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_userinfo",
        "name": "UserInfo",
        "description": "The user information.Since\n  v2.8.0",
        "parameters": [
            {
                "uid": "The user ID."
            },
            {
                "userAccount": "The user account."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videocanvas",
        "name": "VideoCanvas",
        "description": "Video display configurations.",
        "parameters": [
            {
                "view": "The video display window (view)."
            },
            {
                "renderMode": "The rendering mode of the video. See RENDER_MODE_TYPE."
            },
            {
                "channelId": "\n      \n \n     Since\n     v3.0.0\n \n      \n      The unique channel name in the string format. Supported characters are (89 in total):\n     All lowercase English letters: a to z.\n     All uppercase English letters: A to Z.\n     All numeric characters: 0 to 9.\n     The space character.\n     Other symbols: \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\" , \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\",\" ~\", \",\".\n \n \n     \nThe default value is the empty string \"\". If the user joins the channel through the IRtcEngine method of the joinChannel class, set this parameter to the default value. In this case, VideoCanvas sets the user's view in the channel.\nIf the user joins the channel using the joinChannel method of the IChannel class, set this parameter to the channelId of the IChannel object. In this case, VideoCanvas sets the user's view in the channel corresponding to the channelId.\n     \n \n      \n  "
            },
            {
                "uid": "The user ID."
            },
            {
                "mirrorMode": "\n      \n \n     Since\n     v3.0.0\n \n      \n      The mirror mode of the view. See VIDEO_MIRROR_MODE_TYPE.\n     \nFor the local user:\n        If the user uses the front camera, the mirror mode is enabled by default.\n        If the user uses the rear camera, the mirror mode is disabled by default.\n    \n\nFor the remote user: The SDK disables the mirror mode by default.\n     \n \n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videodimensions",
        "name": "VideoDimensions",
        "description": "Video dimensions.",
        "parameters": [
            {
                "width": "\n      The width of the video in pixels.\n      "
            },
            {
                "height": "The height of the video in pixels."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videoencoderconfiguration",
        "name": "VideoEncoderConfiguration",
        "description": "Video encoder configurations.",
        "parameters": [
            {
                "dimensions": "\n      The dimensions of the encoded video (px). See VideoDimensions. This parameter is used to measure encoding quality and expressed in the form of length × width. The default value is 640 × 360. You can set a custom value."
            },
            {
                "frameRate": "\n      The frame rate (fps) of encoding the video. See FRAME_RATE. The default value is 15.\n  "
            },
            {
                "minFramerate": "The minimum frame rate of encoding the video. The default value is -1."
            },
            {
                "bitrate": "\n      The bitrate (Kbps) of encoding the video.\n      You can refer to the table below to set your bitrate according to your app scenario. If the bitrate you set is beyond a reasonable range, the SDK sets it within a reasonable range. You can also choose from the following options:\n      \n  : (Recommended) Standard bitrate mode In this mode, the video bitrate of the LIVE_BROADCASTING profile is twice that of the COMMUNICATION profile.\n : Adaptive bitrate mode In this mode, the bitrate differs between the LIVE_BROADCASTING and COMMUNICATION profiles. If you choose this mode in the LIVE_BROADCASTING profile, the video frame rate may be lower than the set value.\n      \n      Agora uses different video codecs for different profiles to optimize user experience. The COMMUNICATION profile prioritizes smoothness while the LIVE_BROADCASTING profile prioritizes video quality (a higher bitrate). Therefore, Agora recommends setting this parameter as . You can also set the bitrate value of the LIVE_BROADCASTING profile to twice the bitrate value of the COMMUNICATION profile.\n      \n \n     \n     \n     \n     \n     \n\n    Resolution\n    Frame rate (fps)\n    Bitrate (Kbps) for COMMUNICATION\n    Bitrate (Kbps) for LIVE_BROADCASTING\n\n     \n     \n\n    160 × 120\n    15\n    65\n    130\n\n\n    120 × 120\n    15\n    50\n    100\n\n\n    320 × 180\n    15\n    140\n    280\n\n\n    180 × 180\n    15\n    100\n    200\n\n\n    240 × 180\n    15\n    120\n    240\n\n\n    320 × 240\n    15\n    200\n    400\n\n\n    240 × 240\n    15\n    140\n    280\n\n\n    424 × 240\n    15\n    220\n    440\n\n\n    640 × 360\n    15\n    400\n    800\n\n\n    360 × 360\n    15\n    260\n    520\n\n\n    640 × 360\n    30\n    600\n    1200\n\n\n    360 × 360\n    30\n    400\n    800\n\n\n    480 × 360\n    15\n    320\n    640\n\n\n    480 × 360\n    30\n    490\n    980\n\n\n    640 × 480\n    15\n    500\n    1000\n\n\n    480 × 480\n    15\n    400\n    800\n\n\n    640 × 480\n    30\n    750\n    1500\n\n\n    480 × 480\n    30\n    600\n    1200\n\n\n    848 × 480\n    15\n    610\n    1220\n\n\n    848 × 480\n    30\n    930\n    1860\n\n\n    640 × 480\n    10\n    400\n    800\n\n\n    1280 × 720\n    15\n    1130\n    2260\n\n\n    1280 × 720\n    30\n    1710\n    3420\n\n\n    960 × 720\n    15\n    910\n    1820\n\n\n    960 × 720\n    30\n    1380\n    2760\n\n\n    1920 × 1080\n    15\n    2080\n    4160\n\n\n    1920 × 1080\n    30\n    3150\n    6300\n\n\n    1920 × 1080\n    60\n    4780\n    6500\n\n     \n \n      \n  "
            },
            {
                "minBitrate": "\n      The minimum bitrate (Kbps) of encoding the video.\n      The SDK automatically adjusts the encoding bitrate to adapt to the network conditions. Using a value greater than the default value forces the video encoder to output high-quality images but may cause more packet loss and hence sacrifice the smoothness of the video transmission. That said, unless you have special requirements for image quality, Agora does not recommend changing this value.\n      This parameter only applies to the LIVE_BROADCASTING profile.\n  "
            },
            {
                "orientationMode": "The orientation mode of the encoded video. See ORIENTATION_MODE."
            },
            {
                "degradationPreference": "Video degradation preferences when the bandwidth is a constraint. For details, see DEGRADATION_PREFERENCE."
            },
            {
                "mirrorMode": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Sets the mirror mode of the published local video stream. It only affects the video that the remote user sees. See VIDEO_MIRROR_MODE_TYPE.\n      The mirror mode is disabled by default.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "class_videoframe",
        "name": "VideoFrame",
        "description": "Configurations of the video frameThe video data format is YUV420. Note that the buffer provides a pointer to a pointer. This interface cannot modify the pointer of the buffer but can modify the content of the buffer.",
        "parameters": [
            {
                "type": "The type of the video frameVIDEO_FRAME_TYPE."
            },
            {
                "width": "The width of the video in pixels."
            },
            {
                "height": "The height of the video in pixels."
            },
            {
                "yStride": "The line span of the Y buffer within the YUV data."
            },
            {
                "uStride": "The line span of the U buffer within the YUV data."
            },
            {
                "vStride": "The line span of the V buffer within the YUV data."
            },
            {
                "yBuffer": "The pointer to the Y buffer pointer within the YUV data."
            },
            {
                "uBuffer": "The pointer to the U buffer pointer within the YUV data."
            },
            {
                "vBuffer": "The pointer to the V buffer pointer within the YUV data."
            },
            {
                "rotation": "Sets the clockwise rotation of the video frame before rendering. Supported values include 0, 90, 180, and 270 degrees."
            },
            {
                "renderTimeMs": "The timestamp (ms) of the external audio frame. It is mandatory. You can use it to restore the order of the captured audio frame, or synchronize audio and video frames in video-related scenarios (including scenarios where external video sources are used)."
            },
            {
                "avsync_type": "A reserved parameter."
            }
        ],
        "returns": ""
    },
    {
        "id": "class_watermarkoptions",
        "name": "WatermarkOptions",
        "description": "Configurations of the watermark image.",
        "parameters": [
            {
                "visibleInPreview": "\n      Whether the watermark image is visible in the local video preview:\n     true: (Default) The watermark image is visible in the preview.\n     false: The watermark image is not visible in the preview.\n \n      \n  "
            },
            {
                "positionInLandscapeMode": "\n      The area to display the watermark image in landscape mode. See Rectangle:\n     x: The horizontal offset from the top-left corner.\n     y: The vertical offset from the top-left corner.\n     width: The width (pixels) of the area.\n     height: The height (pixels) of the area.\n For details about the landscape mode, see Set the Video Profile.\n  "
            },
            {
                "positionInPortraitMode": "\n      The area to display the watermark image in portrait mode. See Rectangle:\n     x: The horizontal offset from the top-left corner.\n     y: The vertical offset from the top-left corner.\n     width: The width (pixels) of the area.\n     height: The height (pixels) of the area.\n For details about the portrait mode, see Set the Video Profile.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_areacode",
        "name": "AREA_CODE",
        "description": "The region for connection, i.e., the region where the server the SDK connects to is located.",
        "parameters": [
            {
                "AREA_CODE_CN": "Mainland China."
            },
            {
                "AREA_CODE_NA": "North America."
            },
            {
                "AREA_CODE_EU": "Europe."
            },
            {
                "AREA_CODE_AS": "Asia, excluding Mainland China."
            },
            {
                "AREA_CODE_JP": "Japan."
            },
            {
                "AREA_CODE_IN": "India."
            },
            {
                "AREA_CODE_GLOB": "(Default) Global."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiencelatencyleveltype",
        "name": "AUDIENCE_LATENCY_LEVEL_TYPE",
        "description": "The latency level of an audience member in interactive live streaming. This enum takes effect only when the user role is set toCLIENT_ROLE_AUDIENCE .",
        "parameters": [
            {
                "AUDIENCE_LATENCY_LEVEL_LOW_LATENCY": "1: Low latency."
            },
            {
                "AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY": "2: (Default) Ultra low latency."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiocodecprofiletype",
        "name": "AUDIO_CODEC_PROFILE_TYPE",
        "description": "The codec type of the output audio stream for CDN live streaming. The default value is LC_ACC.",
        "parameters": [
            {
                "AUDIO_CODEC_PROFILE_LC_AAC": "0: (Default) LC-AAC, which is the low-complexity audio codec type."
            },
            {
                "AUDIO_CODEC_PROFILE_HE_AAC": "1: HE-AAC, which is the high-efficiency audio codec type."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioeffectpreset",
        "name": "AUDIO_EFFECT_PRESET",
        "description": "Voice effect presets.For better voice effects, Agora recommends setting the profile parameter of setAudioProfile to \n   \n       \n  AUDIO_PROFILE_MUSIC_HIGH_QUALITY\n       \n   \n         or \n   \n       \n  AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO\n       \n   \n         before using the following presets:\n   \n       ROOM_ACOUSTICS_KTV\n       ROOM_ACOUSTICS_VOCAL_CONCERT\n       ROOM_ACOUSTICS_STUDIO\n       ROOM_ACOUSTICS_PHONOGRAPH\n       ROOM_ACOUSTICS_SPACIAL\n       ROOM_ACOUSTICS_ETHEREAL\n       VOICE_CHANGER_EFFECT_UNCLE\n       VOICE_CHANGER_EFFECT_OLDMAN\n       VOICE_CHANGER_EFFECT_BOY\n       VOICE_CHANGER_EFFECT_SISTER\n       VOICE_CHANGER_EFFECT_GIRL\n       VOICE_CHANGER_EFFECT_PIGKING\n       VOICE_CHANGER_EFFECT_HULK\n       PITCH_CORRECTION",
        "parameters": [
            {
                "AUDIO_EFFECT_OFF": "Turn off voice effects, that is, use the original voice."
            },
            {
                "ROOM_ACOUSTICS_KTV": "The voice effect typical of a KTV venue."
            },
            {
                "ROOM_ACOUSTICS_VOCAL_CONCERT": "The voice effect typical of a concert hall."
            },
            {
                "ROOM_ACOUSTICS_STUDIO": "The voice effect typical of a recording studio."
            },
            {
                "ROOM_ACOUSTICS_PHONOGRAPH": "The voice effect typical of a vintage phonograph."
            },
            {
                "ROOM_ACOUSTICS_VIRTUAL_STEREO": "\n      The virtual stereo effect, which renders monophonic audio as stereo audio.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "ROOM_ACOUSTICS_SPACIAL": "A more spatial voice effect."
            },
            {
                "ROOM_ACOUSTICS_ETHEREAL": "A more ethereal voice effect."
            },
            {
                "ROOM_ACOUSTICS_3D_VOICE": "\n      A 3D voice effect that makes the voice appear to be moving around the user. The default movement cycle is 10 seconds. After setting this effect, you can call setAudioEffectParameters to modify the movement period.\n      \n      \n Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_STANDARD_STEREO or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n If the 3D voice effect is enabled, users need to use stereo audio playback devices to hear the anticipated voice effect.\n      \n      \n  "
            },
            {
                "VOICE_CHANGER_EFFECT_UNCLE": "\n      A middle-aged man's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_OLDMAN": "A senior man's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_BOY": "\n      A boy's voice.\n      Agora recommends using this preset to process a male-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_SISTER": "\n      A young woman's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_GIRL": "\n      A girl's voice.\n      Agora recommends using this preset to process a female-sounding voice; otherwise, you may not hear the anticipated voice effect.\n  "
            },
            {
                "VOICE_CHANGER_EFFECT_PIGKING": "The voice of Pig King, a character in Journey to the West who has a voice like a growling bear."
            },
            {
                "VOICE_CHANGER_EFFECT_HULK": "The Hulk's voice."
            },
            {
                "STYLE_TRANSFORMATION_RNB": "\n      The voice effect typical of R&B music.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "STYLE_TRANSFORMATION_POPULAR": "\n      The voice effect typical of popular music.\n      Before using this preset, set the profile parameter of setAudioProfile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO. Otherwise, the preset setting is invalid.\n  "
            },
            {
                "PITCH_CORRECTION": "A pitch correction effect that corrects the user's pitch based on the pitch of the natural C major scale. After setting this voice effect, you can call setAudioEffectParameters to adjust the basic mode of tuning and the pitch of the main tone."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioequalizationbandfrequency",
        "name": "AUDIO_EQUALIZATION_BAND_FREQUENCY",
        "description": "The midrange frequency for audio equalization.",
        "parameters": [
            {
                "AUDIO_EQUALIZATION_BAND_31": "0: 31 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_62": "1: 62 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_125": "2: 125 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_250": "3: 250 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_500": "4: 500 Hz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_1K": "5: 1 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_2K": "6: 2 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_4K": "7: 4 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_8K": "8: 8 kHz"
            },
            {
                "AUDIO_EQUALIZATION_BAND_16K": "9: 16 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioframetype",
        "name": "AUDIO_FRAME_TYPE",
        "description": "Audio frame type.",
        "parameters": [
            {
                "FRAME_TYPE_PCM16": "0: PCM 16"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingerrortype",
        "name": "AUDIO_MIXING_ERROR_TYPE",
        "description": "Errors that may occur when playing a music file.",
        "parameters": [
            {
                "AUDIO_MIXING_ERROR_CAN_NOT_OPEN": "The SDK cannot open the music file."
            },
            {
                "AUDIO_MIXING_ERROR_TOO_FREQUENT_CALL": "The SDK opens the music file too frequently."
            },
            {
                "AUDIO_MIXING_ERROR_INTERRUPTED_EOF": "The playback of the music file is interrupted."
            },
            {
                "AUDIO_MIXING_ERROR_OK": "710: The music file is playing."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiomixingstatetype",
        "name": "AUDIO_MIXING_STATE_TYPE",
        "description": "The playback state of the music file.",
        "parameters": [
            {
                "AUDIO_MIXING_STATE_PLAYING": "\n      710: The music file is playing.\n      This state indicates that the SDK is in one of the following situations:\n The SDK successfully calls startAudioMixing to play the music file.\n The SDK successfully calls resumeAudioMixing to resume playing the music file.\n      \n      \n  "
            },
            {
                "AUDIO_MIXING_STATE_PAUSED": "\n      711: The music file pauses playing.\n      This state indicates that the SDK successfully calls pauseAudioMixing to pause playing the music file.\n  "
            },
            {
                "AUDIO_MIXING_STATE_STOPPED": "\n      713: The music file stops playing.\n      This state indicates that the SDK successfully calls stopAudioMixing to stop playing the music file.\n  "
            },
            {
                "AUDIO_MIXING_STATE_FAILED": "\n      714: An error occurs during the playback of the audio mixing file.\n      For details about the error type, see AUDIO_MIXING_ERROR_TYPE.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioprofiletype",
        "name": "AUDIO_PROFILE_TYPE",
        "description": "The audio profile, including the sampling rate, bitrate, encoding mode, and the number of channels.",
        "parameters": [
            {
                "AUDIO_PROFILE_DEFAULT": "\n      0: The default audio profile.\n For the LIVE_BROADCASTING profile: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps.\n \n  "
            },
            {
                "AUDIO_PROFILE_SPEECH_STANDARD": "1: A sampling rate of 32 kHz, audio encoding, mono, and a bitrate of up to 18 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_STANDARD": "2: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 64 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_STANDARD_STEREO": "3: A sampling rate of 48 kHz, music encoding, stereo, and a bitrate of up to 80 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_HIGH_QUALITY": "4: A sampling rate of 48 kHz, music encoding, mono, and a bitrate of up to 96 Kbps."
            },
            {
                "AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO": "5: A sampling rate of 48 kHz, music encoding, stereo, and a bitrate of up to 128 Kbps."
            },
            {
                "AUDIO_PROFILE_NUM": "Enumerator boundary."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiorecordingqualitytype",
        "name": "AUDIO_RECORDING_QUALITY_TYPE",
        "description": "Recording quality.",
        "parameters": [
            {
                "AUDIO_RECORDING_QUALITY_LOW": "0: Low quality. The sample rate is 32 kHz, and the file size is around 1.2 MB after 10 minutes of recording."
            },
            {
                "AUDIO_RECORDING_QUALITY_MEDIUM": "1: Medium quality. The sample rate is 32 kHz, and the file size is around 2 MB after 10 minutes of recording."
            },
            {
                "AUDIO_RECORDING_QUALITY_HIGH": "2: High quality. The sample rate is 32 kHz, and the file size is around 3.75 MB after 10 minutes of recording."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbpreset",
        "name": "AUDIO_REVERB_PRESET",
        "description": "Voice reverb presets.Deprecated:\n                        Deprecated as of v3.2.0.",
        "parameters": [
            {
                "AUDIO_REVERB_OFF": "Turn off voice reverb, that is, to use the original voice."
            },
            {
                "AUDIO_REVERB_FX_KTV": "The reverb style typical of a KTV venue (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_VOCAL_CONCERT": "The reverb style typical of a concert hall (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_UNCLE": "A middle-aged man's voice."
            },
            {
                "AUDIO_REVERB_FX_SISTER": "The reverb style typical of a young woman's voice."
            },
            {
                "AUDIO_REVERB_FX_STUDIO": "The reverb style typical of a recording studio (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_POPULAR": "The reverb style typical of popular music (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_RNB": "The reverb style typical of R&B music (enhanced)."
            },
            {
                "AUDIO_REVERB_FX_PHONOGRAPH": "The voice effect typical of a vintage phonograph."
            },
            {
                "AUDIO_REVERB_POPULAR": "The voice effect typical of popular music."
            },
            {
                "AUDIO_REVERB_RNB": "The voice effect typical of R&B music."
            },
            {
                "AUDIO_REVERB_ROCK": "The reverb style typical of rock music."
            },
            {
                "AUDIO_REVERB_HIPHOP": "The reverb style typical of hip-hop music."
            },
            {
                "AUDIO_REVERB_VOCAL_CONCERT": "The voice effect typical of a concert hall."
            },
            {
                "AUDIO_REVERB_KTV": "The voice effect typical of a KTV venue."
            },
            {
                "AUDIO_REVERB_STUDIO": "The voice effect typical of a recording studio."
            },
            {
                "AUDIO_VIRTUAL_STEREO": "The reverberation of the virtual stereo. The virtual stereo is an effect that renders the monophonic audio as the stereo audio, so that all users in the channel can hear the stereo voice effect."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioreverbtype",
        "name": "AUDIO_REVERB_TYPE",
        "description": "Audio reverberation types.",
        "parameters": [
            {
                "AUDIO_REVERB_DRY_LEVEL": "0: The level of the dry signal (dB). The value is between -20 and 10."
            },
            {
                "AUDIO_REVERB_WET_LEVEL": "1: The level of the early reflection signal (wet signal) (dB). The value is between -20 and 10."
            },
            {
                "AUDIO_REVERB_ROOM_SIZE": "2: The room size of the reflection. The value is between 0 and 100."
            },
            {
                "AUDIO_REVERB_WET_DELAY": "3: The length of the initial delay of the wet signal (ms). The value is between 0 and 200."
            },
            {
                "AUDIO_REVERB_STRENGTH": "4: The reverberation strength. The value is between 0 and 100."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioroutetype",
        "name": "AUDIO_ROUTE_TYPE",
        "description": "The type of the audio route.",
        "parameters": [
            {
                "AUDIO_ROUTE_DEFAULT": "The default audio route."
            },
            {
                "AUDIO_ROUTE_HEADSET": "The headset."
            },
            {
                "AUDIO_ROUTE_EARPIECE": "The earpiece."
            },
            {
                "AUDIO_ROUTE_HEADSET_NO_MIC": "The headset with no microphone."
            },
            {
                "AUDIO_ROUTE_SPEAKERPHONE": "The built-in speaker on a mobile device."
            },
            {
                "AUDIO_ROUTE_LOUDSPEAKER": "The external speaker."
            },
            {
                "AUDIO_ROUTE_BLUETOOTH": "The bluetooth headset."
            },
            {
                "AUDIO_ROUTE_USB": "The USB peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_HDMI": "The HDMI peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_DISPLAYPORT": "The DisplayPort peripheral (macOS only)."
            },
            {
                "AUDIO_ROUTE_AIRPLAY": "Apple AirPlay (macOS only)."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiosampleratetype",
        "name": "AUDIO_SAMPLE_RATE_TYPE",
        "description": "The audio sampling rate of the stream to be pushed to the CDN.",
        "parameters": [
            {
                "AUDIO_SAMPLE_RATE_32000": "32000: 32 kHz"
            },
            {
                "AUDIO_SAMPLE_RATE_44100": "44100: 44.1 kHz"
            },
            {
                "AUDIO_SAMPLE_RATE_48000": "48000: (Default) 48 kHz"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audioscenariotype",
        "name": "AUDIO_SCENARIO_TYPE",
        "description": "Audio application scenarios.",
        "parameters": [
            {
                "AUDIO_SCENARIO_DEFAULT": "0: The default audio scenario."
            },
            {
                "AUDIO_SCENARIO_CHATROOM_ENTERTAINMENT": "1: Entertainment scenario where users need to frequently switch the user role."
            },
            {
                "AUDIO_SCENARIO_EDUCATION": "2: Education scenario where users want smoothness and stability."
            },
            {
                "AUDIO_SCENARIO_GAME_STREAMING": "3: High-quality audio chatroom scenario where hosts mainly play music."
            },
            {
                "AUDIO_SCENARIO_SHOWROOM": "4: Showroom scenario where a single host wants high-quality audio."
            },
            {
                "AUDIO_SCENARIO_CHATROOM_GAMING": "5: Gaming scenario for group chat that only contains the human voice."
            },
            {
                "AUDIO_SCENARIO_IOT": "6: IoT (Internet of Things) scenario where users use IoT devices with low power consumption."
            },
            {
                "AUDIO_SCENARIO_MEETING": "\n      \n \n     Since\n     v3.2.0\n \n      \n      8: Meeting scenario that mainly contains the human voice.\n  "
            },
            {
                "AUDIO_SCENARIO_NUM": "The number of elements in the enumeration."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_audiosessionoperationrestriction",
        "name": "AUDIO_SESSION_OPERATION_RESTRICTION",
        "description": "The operational permission of the SDK on the audio session.",
        "parameters": [
            {
                "AUDIO_SESSION_OPERATION_RESTRICTION_NONE": "No restriction, the SDK has full control of the audio session operations."
            },
            {
                "AUDIO_SESSION_OPERATION_RESTRICTION_SET_CATEGORY": "The SDK does not change the audio session category."
            },
            {
                "AUDIO_SESSION_OPERATION_RESTRICTION_CONFIGURE_SESSION": "The SDK does not change any setting of the audio session (category, mode, categoryOptions)."
            },
            {
                "AUDIO_SESSION_OPERATION_RESTRICTION_DEACTIVATE_SESSION": "The SDK keeps the audio session active when leaving a channel."
            },
            {
                "AUDIO_SESSION_OPERATION_RESTRICTION_ALL": "The SDK does not configure the audio session anymore."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_cameradirection",
        "name": "CAMERA_DIRECTION",
        "description": "The camera direction.",
        "parameters": [
            {
                "CAMERA_REAR": "The rear camera."
            },
            {
                "CAMERA_FRONT": "The front camera."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_capturebrightnessleveltype",
        "name": "CAPTURE_BRIGHTNESS_LEVEL_TYPE",
        "description": "The brightness level of the video image captured by the local camera.Since\n                    v3.3.0",
        "parameters": [
            {
                "CAPTURE_BRIGHTNESS_LEVEL_INVALID": "-1: The SDK does not detect the brightness level of the video image. Wait a few seconds to get the brightness level from captureBrightnessLevel in the next callback."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_NORMAL": "0: The brightness level of the video image is normal."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_BRIGHT": "1: The brightness level of the video image is too bright."
            },
            {
                "CAPTURE_BRIGHTNESS_LEVEL_DARK": "2: The brightness level of the video image is too dark."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_captureroutputpreference",
        "name": "CAPTURER_OUTPUT_PREFERENCE",
        "description": "Camera capture preference.",
        "parameters": [
            {
                "CAPTURER_OUTPUT_PREFERENCE_AUTO": "0: (Default) Automatically adjust the camera capture preference. The SDK adjusts the camera output parameters according to the system performance and network conditions to balance CPU consumption and video preview quality."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_PERFORMANCE": "1: Prioritizes the system performance. The SDK chooses the dimension and frame rate of the local camera capture closest to those set by setVideoEncoderConfiguration. In this case, the local preview quality depends on the encoder."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_PREVIEW": "2: Prioritizes the local preview quality. The SDK chooses higher camera output parameters to improve the local video preview quality. This option requires extra CPU and RAM usage for video pre-processing."
            },
            {
                "CAPTURER_OUTPUT_PREFERENCE_MANUAL": "\n                        \n                            \n                                Since\n                                v3.3.0\n                            \n                        \n                        3: Allows you to customize the width and height of the video image captured by the local camera.\n                    "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayerror",
        "name": "CHANNEL_MEDIA_RELAY_ERROR",
        "description": "The error code of the channel media replay.",
        "parameters": [
            {
                "RELAY_OK": "0: No error."
            },
            {
                "RELAY_ERROR_SERVER_ERROR_RESPONSE": "1: An error occurs in the server response."
            },
            {
                "RELAY_ERROR_SERVER_NO_RESPONSE": "\n      2: No server response.\n      You can call leaveChannel to leave the channel.\n      This error can also occur if your project has not enabled co-host token authentication. Contact support@agora.io to enable the co-host token authentication service before starting a channel media relay.\n  "
            },
            {
                "RELAY_ERROR_NO_RESOURCE_AVAILABLE": "3: The SDK fails to access the service, probably due to limited resources of the server."
            },
            {
                "RELAY_ERROR_FAILED_JOIN_SRC": "4: Fails to send the relay request."
            },
            {
                "RELAY_ERROR_FAILED_JOIN_DEST": "5: Fails to accept the relay request."
            },
            {
                "RELAY_ERROR_FAILED_PACKET_RECEIVED_FROM_SRC": "6: The server fails to receive the media stream."
            },
            {
                "RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST": "7: The server fails to send the media stream."
            },
            {
                "RELAY_ERROR_SERVER_CONNECTION_LOST": "8: The SDK disconnects from the server due to poor network connections. You can call the leaveChannel method to leave the channel."
            },
            {
                "RELAY_ERROR_INTERNAL_ERROR": "9: An internal error occurs in the server."
            },
            {
                "RELAY_ERROR_SRC_TOKEN_EXPIRED": "10: The token of the source channel has expired."
            },
            {
                "RELAY_ERROR_DEST_TOKEN_EXPIRED": "11: The token of the destination channel has expired."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelayevent",
        "name": "CHANNEL_MEDIA_RELAY_EVENT",
        "description": "The event code of channel media relay.",
        "parameters": [
            {
                "RELAY_EVENT_NETWORK_DISCONNECTED": "0: The user disconnects from the server due to a poor network connection."
            },
            {
                "RELAY_EVENT_NETWORK_CONNECTED": "1: The user is connected to the server."
            },
            {
                "RELAY_EVENT_PACKET_JOINED_SRC_CHANNEL": "2: The user joins the source channel."
            },
            {
                "RELAY_EVENT_PACKET_JOINED_DEST_CHANNEL": "3: The user joins the destination channel."
            },
            {
                "RELAY_EVENT_PACKET_SENT_TO_DEST_CHANNEL": "4: The SDK starts relaying the media stream to the destination channel."
            },
            {
                "RELAY_EVENT_PACKET_RECEIVED_VIDEO_FROM_SRC": "5: The server receives the audio stream from the source channel."
            },
            {
                "RELAY_EVENT_PACKET_RECEIVED_AUDIO_FROM_SRC": "6: The server receives the audio stream from the source channel."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL": "7: The destination channel is updated."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_REFUSED": "8: The destination channel update fails due to internal reasons."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_NOT_CHANGE": "9: The destination channel does not change, which means that the destination channel fails to be updated."
            },
            {
                "RELAY_EVENT_PACKET_UPDATE_DEST_CHANNEL_IS_NULL": "10: The destination channel name is NULL."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelmediarelaystate",
        "name": "CHANNEL_MEDIA_RELAY_STATE",
        "description": "The state code of the channel media relay.",
        "parameters": [
            {
                "RELAY_STATE_IDLE": "0: The initial state. After you successfully stop the channel media relay by calling stopChannelMediaRelay, the onChannelMediaRelayStateChanged callback returns this state."
            },
            {
                "RELAY_STATE_CONNECTING": "1: The SDK tries to relay the media stream to the destination channel."
            },
            {
                "RELAY_STATE_RUNNING": "2: The SDK successfully relays the media stream to the destination channel."
            },
            {
                "RELAY_STATE_FAILURE": "3: An error occurs. See code in onChannelMediaRelayStateChanged for the error code."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_channelprofiletype",
        "name": "CHANNEL_PROFILE_TYPE",
        "description": "The channel profile.",
        "parameters": [
            {
                "CHANNEL_PROFILE_COMMUNICATION": "0: (Default) The communication profile. This profile applies to scenarios such as an audio call or video call, where all users can publish and subscribe to streams. It is suitable for application scenarios such as voice calls and group video chats."
            },
            {
                "CHANNEL_PROFILE_LIVE_BROADCASTING": "1: Live streaming. In this profile, you can set the role of users as the host or audience by calling setClientRole. A host both publishes and subscribes to streams, while an audience subscribes to streams only. This profile applies to scenarios such as a chat room or interactive video streaming."
            },
            {
                "CHANNEL_PROFILE_GAME": "2: Gaming. Agora does not recommend using this setting."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_clientroletype",
        "name": "CLIENT_ROLE_TYPE",
        "description": "User roles in a live broadcast.",
        "parameters": [
            {
                "CLIENT_ROLE_BROADCASTER": "1: Host. A host can both send and receive streams."
            },
            {
                "CLIENT_ROLE_AUDIENCE": "2: (Default) Audience. An audience member can only receive streams."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_cloudproxytype",
        "name": "CLOUD_PROXY_TYPE",
        "description": "The cloud proxy type.",
        "parameters": [
            {
                "NONE_PROXY": "0: Do not use cloud proxy."
            },
            {
                "UDP_PROXY": "1: Use cloud proxy with the UDP protocol."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionchangedreasontype",
        "name": "CONNECTION_CHANGED_REASON_TYPE",
        "description": "Reasons causing the change of the connection state.",
        "parameters": [
            {
                "CONNECTION_CHANGED_CONNECTING": "0: The SDK is connecting to the Agora edge server."
            },
            {
                "CONNECTION_CHANGED_JOIN_SUCCESS": "1: The SDK has joined the channel successfully."
            },
            {
                "CONNECTION_CHANGED_INTERRUPTED": "2: The connection between the SDK and the Agora edge server is interrupted."
            },
            {
                "CONNECTION_CHANGED_BANNED_BY_SERVER": "3: The connection between the SDK and the Agora edge server is banned by the Agora edge server. This error occurs when the user is kicked out of the channel by the server."
            },
            {
                "CONNECTION_CHANGED_JOIN_FAILED": "4: The SDK fails to join the channel. When the SDK fails to join the channel for more than 20 minutes, this error occurs and the SDK stops reconnecting to the channel."
            },
            {
                "CONNECTION_CHANGED_LEAVE_CHANNEL": "5: The SDK has left the channel."
            },
            {
                "CONNECTION_CHANGED_INVALID_APP_ID": "6: The connection failed because the App ID is not valid. Please rejoin the channel with a valid App ID."
            },
            {
                "CONNECTION_CHANGED_INVALID_CHANNEL_NAME": "7: The connection failed since channel name is not valid. Please rejoin the channel with a valid channel name."
            },
            {
                "CONNECTION_CHANGED_INVALID_TOKEN": "8: The connection failed because the token is not valid. Typical reasons include:\n      The App Certificate for the project is enabled in Agora Console, but you do not use a token when joining the channel. If you enable the App Certificate, you must use a token to join the channel.\n      The uid specified when calling joinChannel to join the channel is inconsistent with the uid passed in when generating the token.\n  "
            },
            {
                "CONNECTION_CHANGED_TOKEN_EXPIRED": "9: The connection failed since token is expired."
            },
            {
                "CONNECTION_CHANGED_REJECTED_BY_SERVER": "10: The connection is rejected by server. Typical reasons include:\n      The user is already in the channel and still calls a method, for example, joinChannel, to join the channel. Stop calling this method to clear this error.\n      The user tries to join the channel when calling startEchoTest for a call test. The user needs to call the channel after the call test ends.\n  \n  "
            },
            {
                "CONNECTION_CHANGED_SETTING_PROXY_SERVER": "11: The connection state changed to reconnecting because the SDK has set a proxy server."
            },
            {
                "CONNECTION_CHANGED_RENEW_TOKEN": "12: The connection state changed because the token is renewed."
            },
            {
                "CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED": "13: The IP address of the client has changed, possibly because the network type, IP address, or port has been changed."
            },
            {
                "CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT": "14: Timeout for the keep-alive of the connection between the SDK and the Agora edge server. The connection state changes to state CONNECTION_STATE_RECONNECTING."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_connectionstatetype",
        "name": "CONNECTION_STATE_TYPE",
        "description": "Connection states.",
        "parameters": [
            {
                "CONNECTION_STATE_DISCONNECTED": "1: The SDK is disconnected from the Agora edge server. The state indicates the SDK is in one of the following phases:\n      The initial state before calling the joinChannel method.\n      The app calls the leaveChannel method.\n  \n  "
            },
            {
                "CONNECTION_STATE_CONNECTING": "2: The SDK is connecting to the Agora edge server. This state indicates that the SDK is establishing a connection with the specified channel after the app calls joinChannel.\n      If the SDK successfully joins the channel, it triggers the onConnectionStateChanged callback and the connection state switches to CONNECTION_STATE_CONNECTED.\n      After the connection is established, the SDK also initializes the media and triggers onJoinChannelSuccess when everything is ready.\n  \n  "
            },
            {
                "CONNECTION_STATE_CONNECTED": "3: The SDK is connected to the Agora edge server. This state also indicates that the user has joined a channel and can now publish or subscribe to a media stream in the channel. If the connection to the Agora edge server is lost because, for example, the network is down or switched, the SDK automatically tries to reconnect and triggers onConnectionStateChanged that indicates the connection state switches to CONNECTION_STATE_RECONNECTING."
            },
            {
                "CONNECTION_STATE_RECONNECTING": "4: The SDK keeps reconnecting to the Agora edge server. The SDK keeps rejoining the channel after being disconnected from a joined channel because of network issues.\n      If the SDK cannot rejoin the channel within 10 seconds, it triggers onConnectionLost, stays in the CONNECTION_STATE_RECONNECTING state, and keeps rejoining the channel.\n      If the SDK fails to rejoin the channel 20 minutes after being disconnected from the Agora edge server, the SDK triggers the onConnectionStateChanged callback, switches to the CONNECTION_STATE_FAILED state, and stops rejoining the channel.\n  "
            },
            {
                "CONNECTION_STATE_FAILED": "5: The SDK fails to connect to the Agora edge server or join the channel. This state indicates that the SDK stops trying to rejoin the channel. You must call leaveChannel to leave the channel.\n      You can call joinChannel to rejoin the channel.\n      If the SDK is banned from joining the channel by the Agora edge server through the RESTful API, the SDK triggers the onConnectionStateChanged callback.\n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_degradationpreference",
        "name": "DEGRADATION_PREFERENCE",
        "description": "Video degradation preferences when the bandwidth is a constraint.",
        "parameters": [
            {
                "MAINTAIN_QUALITY": "0: (Default) Degrade the frame rate in order to maintain the video quality."
            },
            {
                "MAINTAIN_FRAMERATE": "1: Degrade the video quality in order to maintain the frame rate."
            },
            {
                "MAINTAIN_BALANCED": "2: Reserved for future use."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_encryptionmode",
        "name": "ENCRYPTION_MODE",
        "description": "The built-in encryption mode.",
        "parameters": [
            {
                "AES_128_XTS": "1: (Default) 128-bit AES encryption, XTS mode."
            },
            {
                "AES_128_ECB": "2: 128-bit AES encryption, ECB mode."
            },
            {
                "AES_256_XTS": "3: 256-bit AES encryption, XTS mode."
            },
            {
                "AES_128_GCM": "\n               \n                   \n                       Since\n                       v3.3.1\n                   \n               \n               5: 128-bit AES encryption, GCM mode."
            },
            {
                "AES_256_GCM": "\n               \n                   \n                       Since\n                       v3.3.1\n                   \n               \n               6: 256-bit AES encryption, GCM mode."
            },
            {
                "MODE_END": "Enumerator boundary."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencepoorreason",
        "name": "EXPERIENCE_POOR_REASON",
        "description": "Reasons why the QoE of the local user when receiving a remote audio stream is poor.Since\n                v3.3.0",
        "parameters": [
            {
                "EXPERIENCE_REASON_NONE": "0: No reason, indicating a good QoE of the local user."
            },
            {
                "REMOTE_NETWORK_QUALITY_POOR": "1: The remote user's network quality is poor."
            },
            {
                "LOCAL_NETWORK_QUALITY_POOR": "2: The local user's network quality is poor."
            },
            {
                "WIRELESS_SIGNAL_POOR": "4: The local user's Wi-Fi or mobile network signal is weak."
            },
            {
                "WIFI_BLUETOOTH_COEXIST": "8: The local user enables both Wi-Fi and bluetooth, and their signals interfere with each other. As a result, audio transmission quality is undermined."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_experiencequalitytype",
        "name": "EXPERIENCE_QUALITY_TYPE",
        "description": "The Quality of Experience (QoE) of the local user when receiving a remote audio stream.Since\n                v3.3.0",
        "parameters": [
            {
                "EXPERIENCE_QUALITY_GOOD": "0: The QoE of the local user is good."
            },
            {
                "EXPERIENCE_QUALITY_BAD": "1: The QoE of the local user is poor."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_framerate",
        "name": "FRAME_RATE",
        "description": "Video frame rates.",
        "parameters": [
            {
                "FRAME_RATE_FPS_1": "1: 1 fps"
            },
            {
                "FRAME_RATE_FPS_7": "7: 7 fps"
            },
            {
                "FRAME_RATE_FPS_10": "10: 10 fps"
            },
            {
                "FRAME_RATE_FPS_15": "15: (Default) 15 fps"
            },
            {
                "FRAME_RATE_FPS_24": "24: 24 fps"
            },
            {
                "FRAME_RATE_FPS_30": "30: 30 fps"
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_injectstreamstatus",
        "name": "INJECT_STREAM_STATUS",
        "description": "States of importing an external video stream in the interactive live streaming.",
        "parameters": [
            {
                "INJECT_STREAM_STATUS_START_SUCCESS": "0: The external video stream is imported successfully."
            },
            {
                "INJECT_STREAM_STATUS_START_ALREADY_EXISTS": "1: The external video stream already exists."
            },
            {
                "INJECT_STREAM_STATUS_START_UNAUTHORIZED": "2: The external video stream to be imported is unauthorized."
            },
            {
                "INJECT_STREAM_STATUS_START_TIMEDOUT": "3: A timeout occurs when importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_START_FAILED": "4: The SDK fails to import the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_SUCCESS": "5: The SDK successfully stops importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_NOT_FOUND": "6: The external video stream to be stopped importing is not found."
            },
            {
                "INJECT_STREAM_STATUS_STOP_UNAUTHORIZED": "7: The external video stream to be stopped importing is unauthorized."
            },
            {
                "INJECT_STREAM_STATUS_STOP_TIMEDOUT": "8: A timeout occurs when stopping importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_STOP_FAILED": "9: The SDK fails to stop importing the external video stream."
            },
            {
                "INJECT_STREAM_STATUS_BROKEN": "10: The external video stream is corrupted."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_interfaceidtype",
        "name": "INTERFACE_ID_TYPE",
        "description": "interface class.",
        "parameters": [
            {
                "AGORA_IID_AUDIO_DEVICE_MANAGER": "IAudioDeviceManager interface class."
            },
            {
                "AGORA_IID_VIDEO_DEVICE_MANAGER": "IVideoDeviceManager interface class."
            },
            {
                "AGORA_IID_RTC_ENGINE_PARAMETER": "This interface class is deprecated."
            },
            {
                "AGORA_IID_MEDIA_ENGINE": "IMediaEngine interface class."
            },
            {
                "AGORA_IID_SIGNALING_ENGINE": "This interface class is deprecated."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lastmileproberesultstate",
        "name": "LASTMILE_PROBE_RESULT_STATE",
        "description": "States of the last-mile network probe test.",
        "parameters": [
            {
                "LASTMILE_PROBE_RESULT_COMPLETE": "1: The last-mile network probe test is complete."
            },
            {
                "LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE": "2: The last-mile network probe test is incomplete because the bandwidth estimation is not available due to limited test resources."
            },
            {
                "LASTMILE_PROBE_RESULT_UNAVAILABLE": "3: The last-mile network probe test is not carried out, probably due to poor network conditions."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_lighteningcontrastlevel",
        "name": "LIGHTENING_CONTRAST_LEVEL",
        "description": "The contrast level.",
        "parameters": [
            {
                "LIGHTENING_CONTRAST_LOW": "Low contrast level."
            },
            {
                "LIGHTENING_CONTRAST_NORMAL": "(Default) Normal contrast level."
            },
            {
                "LIGHTENING_CONTRAST_HIGH": "High contrast level."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamerror",
        "name": "LOCAL_AUDIO_STREAM_ERROR",
        "description": "Local audio state error codes.",
        "parameters": [
            {
                "LOCAL_AUDIO_STREAM_ERROR_OK": "0: The local audio is normal."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_FAILURE": "1: No specified reason for the local audio failure."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_DEVICE_NO_PERMISSION": "2: No permission to use the local audio device."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_DEVICE_BUSY": "3: The microphone is in use."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_RECORD_FAILURE": "4: The local audio capturing fails. Check whether the capturing device is working properly."
            },
            {
                "LOCAL_AUDIO_STREAM_ERROR_ENCODE_FAILURE": "5: The local audio encoding fails."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localaudiostreamstate",
        "name": "LOCAL_AUDIO_STREAM_STATE",
        "description": "Local audio state types.",
        "parameters": [
            {
                "LOCAL_AUDIO_STREAM_STATE_STOPPED": "0: The local audio is in the initial state."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_RECORDING": "1: The capturing device starts successfully."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_ENCODING": "2: The first audio frame encodes successfully."
            },
            {
                "LOCAL_AUDIO_STREAM_STATE_FAILED": "3: The local audio fails to start."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamerror",
        "name": "LOCAL_VIDEO_STREAM_ERROR",
        "description": "Local video state error codes.",
        "parameters": [
            {
                "LOCAL_VIDEO_STREAM_ERROR_OK": "0: The local video is normal."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_FAILURE": "1: No specified reason for the local video failure."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_DEVICE_NO_PERMISSION": "2: No permission to use the local video capturing device."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_DEVICE_BUSY": "3: The local video capturing device is in use."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_CAPTURE_FAILURE": "5: The local video encoding fails."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_MINIMIZED": "11: When calling startScreenCaptureByWindowId to share the window, the shared window is in a minimized state."
            },
            {
                "LOCAL_VIDEO_STREAM_ERROR_SCREEN_CAPTURE_WINDOW_CLOSED": "\n      The error code indicates that a window shared by the window ID has been closed, or a full-screen window shared by the window ID has exited full-screen mode. After exiting full-screen mode, remote users cannot see the shared window. To prevent remote users from seeing a black screen, Agora recommends that you immediately stop screen sharing.\n      Common scenarios for reporting this error code:\n When the local user closes the shared window, the SDK reports this error code.\n     The local user shows some slides in full-screen mode first, and then shares the windows of the slides. After the user exits full-screen mode, the SDK reports this error code.\n     The local user watches web video or reads web document in full-screen mode first, and then shares the window of the web video or document. After the user exits full-screen mode, the SDK reports this error code.\n      \n  "
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_localvideostreamstate",
        "name": "LOCAL_VIDEO_STREAM_STATE",
        "description": "Local video state types.",
        "parameters": [
            {
                "LOCAL_VIDEO_STREAM_STATE_STOPPED": "0: The local video is in the initial state."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_CAPTURING": "1: The local video capturing device starts successfully. The SDK also reports this state when you call startScreenCaptureByWindowId to share a maximized window."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_ENCODING": "2: The first video frame is successfully encoded."
            },
            {
                "LOCAL_VIDEO_STREAM_STATE_FAILED": "3: Fails to start the local video."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_logfiltertype",
        "name": "LOG_FILTER_TYPE",
        "description": "The log output level.",
        "parameters": [
            {
                "LOG_FILTER_OFF": "0: Do not output any log information."
            },
            {
                "LOG_FILTER_DEBUG": "0x080f: Output all log information. Set your log filter as DEBUG if you want to get the most complete log file."
            },
            {
                "LOG_FILTER_INFO": "0x000f: Output CRITICAL, ERROR, WARNING, and INFO level log information. We recommend setting your log filter as this level."
            },
            {
                "LOG_FILTER_WARN": "0x000e: Output CRITICAL, ERROR, and WARNING level log information."
            },
            {
                "LOG_FILTER_ERROR": "0x000c: Output CRITICAL and ERROR level log information."
            },
            {
                "LOG_FILTER_CRITICAL": "0x0008: Output CRITICAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_loglevel",
        "name": "LOG_LEVEL",
        "description": "Sets the log output level of the SDK.Since\n  v3.3.0",
        "parameters": [
            {
                "LOG_LEVEL_NONE": "0: Do not output any log information."
            },
            {
                "LOG_LEVEL_INFO": "0x0001: (Default) Output FATAL, ERROR, WARN, and INFO level log information. We recommend setting your log filter as this level."
            },
            {
                "LOG_LEVEL_WARN": "0x0002: Output FATAL, ERROR, and WARN level log information."
            },
            {
                "LOG_LEVEL_ERROR": "0x0004: Output FATAL and ERROR level log information."
            },
            {
                "LOG_LEVEL_FATAL": "0x0008: Output FATAL level log information."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_maxchannelidlengthtype",
        "name": "MAX_CHANNEL_ID_LENGTH_TYPE",
        "description": "The maximum length of the channel name.",
        "parameters": [
            {
                "MAX_CHANNEL_ID_LENGTH": "The maximum length of the channel name is 64 bytes."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_maxdeviceidlengthtype",
        "name": "MAX_DEVICE_ID_LENGTH_TYPE",
        "description": "The maximum length of the device ID.",
        "parameters": [
            {
                "MAX_DEVICE_ID_LENGTH": "The maximum length of the device ID is 512 bytes."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_maxuseraccountlengthtype",
        "name": "MAX_USER_ACCOUNT_LENGTH_TYPE",
        "description": "The maximum length of the user account.",
        "parameters": [
            {
                "MAX_USER_ACCOUNT_LENGTH": "The maximum length of the user account is 256 bytes."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicestatetype",
        "name": "MEDIA_DEVICE_STATE_TYPE",
        "description": "Media device states.",
        "parameters": [
            {
                "MEDIA_DEVICE_STATE_ACTIVE": "1: The device is in use."
            },
            {
                "MEDIA_DEVICE_STATE_DISABLED": "2: The device is disabled."
            },
            {
                "MEDIA_DEVICE_STATE_NOT_PRESENT": "4: The device is not found."
            },
            {
                "MEDIA_DEVICE_STATE_UNPLUGGED": "8: The device is unplugged."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediadevicetype",
        "name": "MEDIA_DEVICE_TYPE",
        "description": "Media device types.",
        "parameters": [
            {
                "UNKNOWN_AUDIO_DEVICE": "-1: Unknown device type."
            },
            {
                "AUDIO_PLAYOUT_DEVICE": "0: Audio playback device."
            },
            {
                "AUDIO_RECORDING_DEVICE": "1: Audio capturing device."
            },
            {
                "VIDEO_RENDER_DEVICE": "2: Video renderer."
            },
            {
                "VIDEO_CAPTURE_DEVICE": "3: Video capturer."
            },
            {
                "AUDIO_APPLICATION_PLAYOUT_DEVICE": "4: Application audio playback device."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_mediasourcetype",
        "name": "MEDIA_SOURCE_TYPE",
        "description": "Audio device type.Deprecated",
        "parameters": [
            {
                "AUDIO_PLAYOUT_SOURCE": "0: Audio playback device."
            },
            {
                "AUDIO_RECORDING_SOURCE": "1: Audio capturing device."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_metadatatype",
        "name": "METADATA_TYPE",
        "description": "Metadata type of the observer. We only support video metadata for now.",
        "parameters": [
            {
                "UNKNOWN_METADATA": "Metadata The metadata type is unknown."
            },
            {
                "VIDEO_METADATA": "Metadata The metadata type is video."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_networktype",
        "name": "NETWORK_TYPE",
        "description": "Network type.",
        "parameters": [
            {
                "NETWORK_TYPE_UNKNOWN": "-1: The network type is unknown."
            },
            {
                "NETWORK_TYPE_DISCONNECTED": "0: The SDK disconnects from the network."
            },
            {
                "NETWORK_TYPE_LAN": "1: The network type is LAN."
            },
            {
                "NETWORK_TYPE_WIFI": "2: The network type is Wi-Fi (including hotspots)."
            },
            {
                "NETWORK_TYPE_MOBILE_2G": "3: The network type is mobile 2G."
            },
            {
                "NETWORK_TYPE_MOBILE_3G": "4: The network type is mobile 3G."
            },
            {
                "NETWORK_TYPE_MOBILE_4G": "5: The network type is mobile 4G."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_orientationmode",
        "name": "ORIENTATION_MODE",
        "description": "Video output orientation modes.",
        "parameters": [
            {
                "ORIENTATION_MODE_ADAPTIVE": "\n      0: (Default) The output video always follows the orientation of the captured video. The receiver takes the rotational information passed on from the video encoder. This mode applies to scenarios where video orientation can be adjusted on the receiver.\n      \n If the captured video is in landscape mode, the output video is in landscape mode.\n If the captured video is in portrait mode, the output video is in portrait mode.\n      \n  "
            },
            {
                "ORIENTATION_FIXED_LANDSCAPE": "1: In this mode, the SDK always outputs videos in landscape (horizontal) mode. If the captured video is in portrait mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            },
            {
                "ORIENTATION_FIXED_PORTRAIT": "2: In this mode, the SDK always outputs video in portrait (portrait) mode. If the captured video is in landscape mode, the video encoder crops it to fit the output. Applies to situations where the receiving end cannot process the rotational information. For example, CDN live streaming."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_prioritytype",
        "name": "PRIORITY_TYPE",
        "description": "The priority of the remote user.",
        "parameters": [
            {
                "PRIORITY_HIGH": "The user's priority is high."
            },
            {
                "PRIORITY_NORMAL": "(Default) The user's priority is normal."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualityadaptindication",
        "name": "QUALITY_ADAPT_INDICATION",
        "description": "Quality change of the local video in terms of target frame rate and target bit rate since last count.",
        "parameters": [
            {
                "ADAPT_NONE": "The quality stays the same."
            },
            {
                "ADAPT_UP_BANDWIDTH": "The quality improves because the network bandwidth increases."
            },
            {
                "ADAPT_DOWN_BANDWIDTH": "The quality worsens because the network bandwidth decreases."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualityreportformattype",
        "name": "QUALITY_REPORT_FORMAT_TYPE",
        "description": "Formats of the quality report.",
        "parameters": [
            {
                "QUALITY_REPORT_JSON": "0: The quality report in JSON format."
            },
            {
                "QUALITY_REPORT_HTML": "1: The quality report in HTML format."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_qualitytype",
        "name": "QUALITY_TYPE",
        "description": "Network quality types.",
        "parameters": [
            {
                "QUALITY_UNKNOWN": "0: The network quality is unknown."
            },
            {
                "QUALITY_EXCELLENT": "1: The network quality is excellent."
            },
            {
                "QUALITY_GOOD": "2: The network quality is quite good, but the bitrate may be slightly lower than excellent."
            },
            {
                "QUALITY_POOR": "3: Users can feel the communication slightly impaired."
            },
            {
                "QUALITY_BAD": "4: Users cannot communicate smoothly."
            },
            {
                "QUALITY_VBAD": "5: The quality is so bad that users can barely communicate."
            },
            {
                "QUALITY_DOWN": "6: The network is down and users cannot communicate at all."
            },
            {
                "QUALITY_UNSUPPORTED": "7: Users cannot detect the network quality. (Not in use.)"
            },
            {
                "QUALITY_DETECTING": "8: Detecting the network quality."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rawaudioframeopmodetype",
        "name": "RAW_AUDIO_FRAME_OP_MODE_TYPE",
        "description": "The usa mode of the audio data returned in the onRecordAudioFrame or onPlaybackAudioFrame callback.",
        "parameters": [
            {
                "RAW_AUDIO_FRAME_OP_MODE_READ_ONLY": "0: Read-only mode: Users only read the AudioFrame data without modifying anything. For example, when users acquire the data with the Agora SDK, then push the RTMP or RTMPS streams."
            },
            {
                "RAW_AUDIO_FRAME_OP_MODE_WRITE_ONLY": "1: Write-only mode: Users replace the AudioFrame data with their own data and pass the data to the SDK for encoding. For example, when users acquire the data."
            },
            {
                "RAW_AUDIO_FRAME_OP_MODE_READ_WRITE": "2: Read and write mode: Users read the data from AudioFrame, modify it, and then play it. For example, when users have their own sound-effect processing module and perform some voice pre-processing, such as a voice change."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostate",
        "name": "REMOTE_AUDIO_STATE",
        "description": "Remote audio states.",
        "parameters": [
            {
                "REMOTE_AUDIO_STATE_STOPPED": "0: The local audio is in the initial state. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_LOCAL_MUTED, REMOTE_AUDIO_STATE_REASON_REMOTE_MUTED or REMOTE_AUDIO_STATE_REASON_REMOTE_OFFLINE."
            },
            {
                "REMOTE_AUDIO_STATE_STARTING": "1: The first remote audio packet is received."
            },
            {
                "REMOTE_AUDIO_STATE_DECODING": "2: The remote audio stream is decoded and plays normally. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_NETWORK_RECOVERY, REMOTE_AUDIO_STATE_REASON_LOCAL_UNMUTED or REMOTE_AUDIO_STATE_REASON_REMOTE_UNMUTED."
            },
            {
                "REMOTE_AUDIO_STATE_FROZEN": "3: The remote audio is frozen. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_NETWORK_CONGESTION."
            },
            {
                "REMOTE_AUDIO_STATE_FAILED": "4: The remote audio fails to start. The SDK reports this state in the case of REMOTE_AUDIO_STATE_REASON_INTERNAL."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remoteaudiostatereason",
        "name": "REMOTE_AUDIO_STATE_REASON",
        "description": "The reason for the remote audio state change.",
        "parameters": [
            {
                "REMOTE_AUDIO_STATE_REASON_INTERNAL": "0: The SDK reports this reason when the audio state changes."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_NETWORK_CONGESTION": "1: Network congestion."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_NETWORK_RECOVERY": "2: Network recovery."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_LOCAL_MUTED": "3： The local user stops receiving the remote audio stream or disables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote audio stream or enables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_MUTED": "5: The remote user stops sending the audio stream or disables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the audio stream or enables the audio module."
            },
            {
                "REMOTE_AUDIO_STATE_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostate",
        "name": "REMOTE_VIDEO_STATE",
        "description": "The state of the remote video.",
        "parameters": [
            {
                "REMOTE_VIDEO_STATE_STOPPED": "0: The remote video is in the initial state. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED, REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED or REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE."
            },
            {
                "REMOTE_VIDEO_STATE_STARTING": "1: The first remote video packet is received."
            },
            {
                "REMOTE_VIDEO_STATE_DECODING": "2: The remote video stream is decoded and plays normally. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY, REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED, REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY."
            },
            {
                "REMOTE_VIDEO_STATE_FROZEN": "3: The remote video is frozen. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK."
            },
            {
                "REMOTE_VIDEO_STATE_FAILED": "4: The remote video fails to start. The SDK reports this state in the case of REMOTE_VIDEO_STATE_REASON_INTERNAL."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostatereason",
        "name": "REMOTE_VIDEO_STATE_REASON",
        "description": "The reason for the remote video state change.",
        "parameters": [
            {
                "REMOTE_VIDEO_STATE_REASON_INTERNAL": "0: The SDK reports this reason when the video state changes."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION": "1: Network congestion."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY": "2: Network recovery."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED": "3: The local user stops receiving the remote video stream or disables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote video stream or enables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED": "5: The remote user stops sending the video stream or disables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the video stream or enables the video module."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK": "8: The remote audio-and-video stream falls back to the audio-only stream due to poor network conditions."
            },
            {
                "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY": "9: The remote audio-only stream switches back to the audio-and-video stream after the network conditions improve."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_remotevideostreamtype",
        "name": "REMOTE_VIDEO_STREAM_TYPE",
        "description": "The type of video streams.",
        "parameters": [
            {
                "REMOTE_VIDEO_STREAM_HIGH": "0: High-quality video stream."
            },
            {
                "REMOTE_VIDEO_STREAM_LOW": "1: Low-quality video stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rendermodetype",
        "name": "RENDER_MODE_TYPE",
        "description": "Video display modes.",
        "parameters": [
            {
                "RENDER_MODE_HIDDEN": "1: Uniformly scale the video until one of its dimensions fits the boundary (zoomed to fit). One dimension of the video may have clipped contents."
            },
            {
                "RENDER_MODE_FIT": "1: Uniformly scale the video until one of its dimension fits the boundary (zoomed to fit). Fit mode. Areas that are not filled due to disparity in the aspect ratio are filled with black."
            },
            {
                "RENDER_MODE_ADAPTIVE": "\n      \n \n     Deprecated:\n     3: This mode is deprecated.\n \n      "
            },
            {
                "RENDER_MODE_FILL": "4: The fill mode. In this mode, the SDK stretches or zooms the video to fill the display window."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreamingevent",
        "name": "RTMP_STREAMING_EVENT",
        "description": "Events during the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE": "An error occurs when you add a background image or a watermark image to the RTMP or RTMPS stream."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreamlifecycletype",
        "name": "RTMP_STREAM_LIFE_CYCLE_TYPE",
        "description": "Lifecycle of the CDN live video stream.Deprecated",
        "parameters": [
            {
                "RTMP_STREAM_LIFE_CYCLE_BIND2CHANNEL": "Bind to the channel lifecycle. If all hosts leave the channel, the CDN live streaming stops after 30 seconds."
            },
            {
                "RTMP_STREAM_LIFE_CYCLE_BIND2OWNER": "Bind to the owner of the RTMP stream. If the owner leaves the channel, the CDN live streaming stops immediately."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublisherror",
        "name": "RTMP_STREAM_PUBLISH_ERROR",
        "description": "Error codes of the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAM_PUBLISH_ERROR_OK": "The RTMP or RTMPS streaming publishes successfully."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_INVALID_ARGUMENT": "Invalid argument used. Please check the parameter setting. For example, if you do not call setLiveTranscoding to set the transcoding parameters before calling addPublishStreamUrl, the SDK returns this error."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_ENCRYPTED_STREAM_NOT_ALLOWED": "Check whether you set the parameters in the setLiveTranscoding method properly."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_CONNECTION_TIMEOUT": "The RTMP or RTMPS streaming is encrypted and cannot be published. Call addPublishStreamUrl to re-publish the stream."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_INTERNAL_SERVER_ERROR": "An error occurs in Agora's streaming server. Call the addPublishStreamUrl method to publish the stream again."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_RTMP_SERVER_ERROR": "An error occurs in the CDN server."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_TOO_OFTEN": "The RTMP or RTMPS streaming publishes too frequently."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_REACH_LIMIT": "The host has published more than 10 URLs. Delete the unnecessary URLs before adding new ones."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_NOT_AUTHORIZED": "The host manipulates other hosts' streams. For example, the host updates or stops other hosts' streams. Check your app logic."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_STREAM_NOT_FOUND": "Agora's server fails to find the RTMP or RTMPS streaming."
            },
            {
                "RTMP_STREAM_PUBLISH_ERROR_FORMAT_NOT_SUPPORTED": "The URL format is incorrect. Please check the format."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_rtmpstreampublishstate",
        "name": "RTMP_STREAM_PUBLISH_STATE",
        "description": "States of the RTMP or RTMPS streaming.",
        "parameters": [
            {
                "RTMP_STREAM_PUBLISH_STATE_IDLE": "The RTMP or RTMPS streaming has not started or has ended. This state is also triggered after you remove an RTMP or RTMPS stream from the CDN by calling removePublishStreamUrl."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_CONNECTING": "The SDK is connecting to Agora's streaming server and the CDN server. This state is triggered after you call the addPublishStreamUrl method."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_RUNNING": "The RTMP or RTMPS streaming publishes. The SDK successfully publishes the RTMP or RTMPS streaming and returns this state."
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_RECOVERING": "\n      The RTMP or RTMPS streaming is recovering. When exceptions occur to the CDN, or the streaming is interrupted, the SDK tries to resume RTMP or RTMPS streaming and returns this state.\n      \n If the SDK successfully resumes the streaming, RTMP_STREAM_PUBLISH_STATE_RUNNING (2) returns.\n If the streaming does not resume within 60 seconds or server errors occur, RTMP_STREAM_PUBLISH_STATE_FAILURE (4) returns. You can also reconnect to the server by calling the removePublishStreamUrl and addPublishStreamUrl methods.\n      \n  "
            },
            {
                "RTMP_STREAM_PUBLISH_STATE_FAILURE": "The RTMP or RTMPS streaming fails. See the error code for the detailed error information. You can also call the addPublishStreamUrl method to publish the RTMP or RTMPS stream again."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamfallbackoptions",
        "name": "STREAM_FALLBACK_OPTIONS",
        "description": "Stream fallback options.",
        "parameters": [
            {
                "STREAM_FALLBACK_OPTION_DISABLED": "0: No fallback behavior for the local/remote video stream when the uplink/downlink network conditions are poor. The quality of the stream is not guaranteed."
            },
            {
                "STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW": "1: Under poor downlink network conditions, the remote video stream, to which you subscribe, falls back to the low-quality (low resolution and low bitrate) video stream. This option is only valid for setRemoteSubscribeFallbackOption and is invalid for setLocalPublishFallbackOption."
            },
            {
                "STREAM_FALLBACK_OPTION_AUDIO_ONLY": "2: Under poor uplink network conditions, the published video stream falls back to audio only. Under poor downlink network conditions, the remote video stream, to which you subscribe, first falls back to the low-quality (low resolution and low bitrate) video stream; and then to an audio-only stream if the network conditions worsen."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streampublishstate",
        "name": "STREAM_PUBLISH_STATE",
        "description": "The publishing state.",
        "parameters": [
            {
                "PUB_STATE_IDLE": "0: The initial publishing state after joining the channel."
            },
            {
                "PUB_STATE_NO_PUBLISHED": "\n      1: Fails to publish the local stream. Possible reasons:\n The local user calls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending the local media stream.\n The local user calls disableAudio or disableVideo to disable the local audio or video module.\n The local user calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n     The role of the local user is audience.\n \n  "
            },
            {
                "PUB_STATE_PUBLISHING": "2: Publishing."
            },
            {
                "PUB_STATE_PUBLISHED": "3: Publishes successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_streamsubscribestate",
        "name": "STREAM_SUBSCRIBE_STATE",
        "description": "The subscribing state.",
        "parameters": [
            {
                "SUB_STATE_IDLE": "0: The initial subscribing state after joining the channel."
            },
            {
                "SUB_STATE_NO_SUBSCRIBED": "\n      1: Fails to subscribe to the remote stream. Possible reasons:\n     The remote user:\nCalls muteLocalAudioStream(true) or muteLocalVideoStream(true) to stop sending local media stream.\nCalls disableAudio or disableVideo to disable the local audio or video module.\n    Calls enableLocalAudio(false) or enableLocalVideo(false) to disable the local audio or video capture.\n    The role of the remote user is audience.\n\n     The local user calls the following methods to stop receiving remote streams:\n    Calls muteRemoteAudioStream(true), muteAllRemoteAudioStreams(true) or setDefaultMuteAllRemoteAudioStreams(true) to stop receiving the remote audio streams.\n    Calls muteRemoteVideoStream(true), muteAllRemoteVideoStreams(true) or setDefaultMuteAllRemoteVideoStreams(true) to stop receiving the remote video streams.\n\n \n  "
            },
            {
                "SUB_STATE_SUBSCRIBING": "2: Subscribing."
            },
            {
                "SUB_STATE_SUBSCRIBED": "3: Subscribes to and receives the remote stream successfully."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_uploaderrorreason",
        "name": "UPLOAD_ERROR_REASON",
        "description": "The reason for the upload failure.",
        "parameters": [
            {
                "UPLOAD_SUCCESS": "0: Successfully upload the log files."
            },
            {
                "UPLOAD_NET_ERROR": "1: Network error. Check the network connection and call uploadLogFile again to upload the log file."
            },
            {
                "UPLOAD_SERVER_ERROR": "2: An error occurs in the Agora server. Try uploading the log files later."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_userofflinereasontype",
        "name": "USER_OFFLINE_REASON_TYPE",
        "description": "Reasons for a user being offline.",
        "parameters": [
            {
                "USER_OFFLINE_QUIT": "0: The user quits the call."
            },
            {
                "USER_OFFLINE_DROPPED": "1: The SDK times out and the user drops offline because no data packet is received within a certain period of time.\n      If the user quits the call and the message is not passed to the SDK (due to an unreliable channel), the SDK assumes the user dropped offline."
            },
            {
                "USER_OFFLINE_BECOME_AUDIENCE": "2: The user switches the client role from the host to the audience."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videobuffertype",
        "name": "VIDEO_BUFFER_TYPE",
        "description": "The video buffer type.",
        "parameters": [
            {
                "VIDEO_BUFFER_RAW_DATA": "1: The video buffer in the format of raw data."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocapturetype",
        "name": "VIDEO_CAPTURE_TYPE",
        "description": "The capture type of the custom video source.",
        "parameters": [
            {
                "VIDEO_CAPTURE_UNKNOWN": "Unknown type."
            },
            {
                "VIDEO_CAPTURE_CAMERA": "(Default) Video captured by the camera."
            },
            {
                "VIDEO_CAPTURE_SCREEN": "Video for screen sharing."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodecprofiletype",
        "name": "VIDEO_CODEC_PROFILE_TYPE",
        "description": "Video codec profile types.",
        "parameters": [
            {
                "VIDEO_CODEC_PROFILE_BASELINE": "66: Baseline video codec profile. Generally used for video calls on mobile phones."
            },
            {
                "VIDEO_CODEC_PROFILE_MAIN": "77: Main video codec profile. Generally used in mainstream electronics such as MP4 players, portable video players, PSP, and iPads."
            },
            {
                "VIDEO_CODEC_PROFILE_HIGH": "100: (Default) High video codec profile. Generally used in high-resolution live streaming or television."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocodectype",
        "name": "VIDEO_CODEC_TYPE",
        "description": "Video codec types",
        "parameters": [
            {
                "VIDEO_CODEC_VP8": "Standard VP8."
            },
            {
                "VIDEO_CODEC_H264": "Standard H.264."
            },
            {
                "VIDEO_CODEC_EVP": "Enhanced VP8."
            },
            {
                "VIDEO_CODEC_E264": "Enhanced H.264."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videocontenthint",
        "name": "VideoContentHint",
        "description": "Content hints for screen sharing.",
        "parameters": [
            {
                "CONTENT_HINT_NONE": "(Default) No content hint."
            },
            {
                "CONTENT_HINT_MOTION": "Motion-intensive content. Choose this option if you prefer smoothness or when you are sharing a video clip, movie, or video game."
            },
            {
                "CONTENT_HINT_DETAILS": "Motionless content. Choose this option if you prefer sharpness or when you are sharing a picture, PowerPoint slide, or text."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videoframetype",
        "name": "VIDEO_FRAME_TYPE",
        "description": "The video frame type.",
        "parameters": [
            {
                "FRAME_TYPE_YUV420": "The video data format is YUV420."
            },
            {
                "FRAME_TYPE_YUV422": "1: YUV422."
            },
            {
                "FRAME_TYPE_RGBA": "2: RGBA."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videomirrormodetype",
        "name": "VIDEO_MIRROR_MODE_TYPE",
        "description": "Video mirror modes.",
        "parameters": [
            {
                "VIDEO_MIRROR_MODE_AUTO": "(Default) The SDK enables the mirror mode."
            },
            {
                "VIDEO_MIRROR_MODE_ENABLED": "1: Enable mirror mode."
            },
            {
                "VIDEO_MIRROR_MODE_DISABLED": "2: Disable mirror mode."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videoobserverposition",
        "name": "VIDEO_OBSERVER_POSITION",
        "description": "The frame position of the video observer.",
        "parameters": [
            {
                "POSITION_POST_CAPTURER": "1: The post-capturer position, which corresponds to the video data in the onCaptureVideoFrame callback."
            },
            {
                "POSITION_PRE_RENDERER": "2: The pre-renderer position, which corresponds to the video data in the onRenderVideoFrame callback."
            },
            {
                "POSITION_PRE_ENCODER": "4: The pre-encoder position, which corresponds to the video data in the onPreEncodeVideoFrame callback."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videopixelformat",
        "name": "VIDEO_PIXEL_FORMAT",
        "description": "The video pixel format.",
        "parameters": [
            {
                "VIDEO_PIXEL_UNKNOWN": "0: The format is known."
            },
            {
                "VIDEO_PIXEL_I420": "1: The format is I420."
            },
            {
                "VIDEO_PIXEL_BGRA": "2: The format is BGRA."
            },
            {
                "VIDEO_PIXEL_NV21": "3: The format is NV21."
            },
            {
                "VIDEO_PIXEL_RGBA": "4: The format is RGBA."
            },
            {
                "VIDEO_PIXEL_IMC2": "5: The format is IMC2."
            },
            {
                "VIDEO_PIXEL_ARGB": "7: The format is ARGB."
            },
            {
                "VIDEO_PIXEL_NV12": "8: The format is NV12."
            },
            {
                "VIDEO_PIXEL_I422": "16: The format is I422."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_videoprofiletype",
        "name": "VIDEO_PROFILE_TYPE",
        "description": "The video profile.",
        "parameters": [
            {
                "VIDEO_PROFILE_LANDSCAPE_120P": "0: 160 × 120, frame rate 15 fps, bitrate 65 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_120P_3": "2: 120 × 120, frame rate 15 fps, bitrate 50 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P": "10: 320 × 180, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P_3": "12: 180 × 180, frame rate 15 fps, bitrate 100 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_180P_4": "13: 240 × 180, frame rate 15 fps, bitrate 120 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P": "20: 320 × 240, frame rate 15 fps, bitrate 200 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P_3": "22: 240 × 240, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_240P_4": "23: 424 × 240, frame rate 15 fps, bitrate 220 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P": "30: 640 × 360, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_3": "32: 360 × 360, frame rate 15 fps, bitrate 260 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_4": "33: 640 × 360, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_6": "35: 360 × 360, frame rate 30 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_7": "36: 480 × 360, frame rate 15 fps, bitrate 320 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_8": "37: 480 × 360, frame rate 30 fps, bitrate 490 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_9": "\n      38: 640 × 360, frame rate 15 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_10": "39: 640 × 360, frame rate 24 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_360P_11": "100: 640 × 360, frame rate 24 fps, bitrate 1000 Kbps.\n      This profile applies only to the live streaming channel profile."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P": "40: 640 × 480, frame rate 15 fps, bitrate 500 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_3": "42: 480 × 480, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_4": "43: 640 × 480, frame rate 30 fps, bitrate 750 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_6": "45: 480 × 480, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_8": "47: 848 × 480, frame rate 15 fps, bitrate 610 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_9": "48: 848 × 480, frame rate 30 fps, bitrate 930 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_480P_10": "49: 640 × 480, frame rate 10 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P": "50: 1280 × 720, frame rate 15 fps, bitrate 1130 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_3": "52: 1280 × 720, frame rate 30 fps, bitrate 1710 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_5": "54: 960 × 720, frame rate 15 fps, bitrate 910 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_720P_6": "55: 960 × 720, frame rate 30 fps, bitrate 1380 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P": "60: 1920 × 1080, frame rate 15 fps, bitrate 2080 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P_3": "60: 1920 × 1080, frame rate 30 fps, bitrate 3150 Kbps."
            },
            {
                "VIDEO_PROFILE_LANDSCAPE_1080P_5": "64: 1920 × 1080, frame rate 60 fps, bitrate 4780 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_120P": "1000: 120 × 160, frame rate 15 fps, bitrate 65 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_120P_3": "1002: 120 × 120, frame rate 15 fps, bitrate 50 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P": "1010: 180 × 320, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P_3": "1012: 180 × 180, frame rate 15 fps, bitrate 100 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_180P_4": "1013: 180 × 240, frame rate 15 fps, bitrate 120 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P": "1020: 240 × 320, frame rate 15 fps, bitrate 200 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P_3": "1022: 240 × 240, frame rate 15 fps, bitrate 140 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_240P_4": "1023: 240 × 424, frame rate 15 fps, bitrate 220 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P": "1030: 360 × 640, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_3": "1032: 360 × 360, frame rate 15 fps, bitrate 260 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_4": "1033: 360 × 640, frame rate 15 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_6": "1035: 360 × 360, frame rate 30 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_7": "1036: 360 × 480, frame rate 15 fps, bitrate 320 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_8": "1037: 360 × 480, frame rate 30 fps, bitrate 490 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_9": "\n      1038: 360 × 640, frame rate 15 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_10": "\n      1039: 360 × 640, frame rate 24 fps, bitrate 800 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_360P_11": "\n      1100: 360 × 640, frame rate 24 fps, bitrate 1000 Kbps.\n      This profile applies only to the live streaming channel profile.\n  "
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P": "1040: 480 × 640, frame rate 15 fps, bitrate 500 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_3": "1042: 480 × 480, frame rate 15 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_4": "1043: 480 × 640, frame rate 30 fps, bitrate 750 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_6": "1045: 480 × 480, frame rate 30 fps, bitrate 600 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_8": "1047: 480 × 848, frame rate 15 fps, bitrate 610 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_9": "1048: 480 × 848, frame rate 30 fps, bitrate 930 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_480P_10": "1049: 480 × 640, frame rate 10 fps, bitrate 400 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P": "1050: 720 × 1280, frame rate 15 fps, bitrate 1130 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_3": "1052: 720 × 1280, frame rate 30 fps, bitrate 1710 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_5": "1054: 720 × 960, frame rate 15 fps, bitrate 910 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_720P_6": "1055: 720 × 960, frame rate 30 fps, bitrate 1380 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P": "1060: 1080 × 1920, frame rate 15 fps, bitrate 2080 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P_3": "1062: 1080 × 1920, frame rate 30 fps, bitrate 3150 Kbps."
            },
            {
                "VIDEO_PROFILE_PORTRAIT_1080P_5": "1064: 1080 × 1920, frame rate 60 fps, bitrate 4780 Kbps."
            },
            {
                "VIDEO_PROFILE_DEFAULT": "(Default) 640 × 360, frame rate 15 fps, bitrate 400 Kbps."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicebeautifierpreset",
        "name": "VOICE_BEAUTIFIER_PRESET",
        "description": "The options for SDK preset voice beautifier effects.",
        "parameters": [
            {
                "VOICE_BEAUTIFIER_OFF": "Turn off voice beautifier effects and use the original voice."
            },
            {
                "CHAT_BEAUTIFIER_MAGNETIC": "A more magnetic voice.\n      Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion."
            },
            {
                "CHAT_BEAUTIFIER_FRESH": "\n      A fresher voice.\n      Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n  "
            },
            {
                "CHAT_BEAUTIFIER_VITALITY": "\n      A more vital voice.\n      Agora recommends using this enumerator to process a female-sounding voice; otherwise, you may experience vocal distortion.\n  "
            },
            {
                "SINGING_BEAUTIFIER": "\n      \n \n     Since\n     v3.3.0\n \n      \n      Singing beautifier effect.\n      \n If you call setVoiceBeautifierPreset(SINGING_BEAUTIFIER), you can beautify a male-sounding voice and add a reverberation effect that sounds like singing in a small room. Agora recommends using this enumerator to process a male-sounding voice; otherwise, you may experience vocal distortion.\n If you call setVoiceBeautifierParameters(SINGING_BEAUTIFIER, param1, param2), you can beautify a male- or female-sounding voice and add a reverberation effect.\n      \n  "
            },
            {
                "TIMBRE_TRANSFORMATION_VIGOROUS": "A more vigorous voice."
            },
            {
                "TIMBRE_TRANSFORMATION_DEEP": "A deep voice."
            },
            {
                "TIMBRE_TRANSFORMATION_MELLOW": "A mellower voice."
            },
            {
                "TIMBRE_TRANSFORMATION_FALSETTO": "Falsetto."
            },
            {
                "TIMBRE_TRANSFORMATION_FULL": "A fuller voice."
            },
            {
                "TIMBRE_TRANSFORMATION_CLEAR": "A clearer voice."
            },
            {
                "TIMBRE_TRANSFORMATION_RESOUNDING": "A more resounding voice."
            },
            {
                "TIMBRE_TRANSFORMATION_RINGING": "A more ringing voice."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voicechangerpreset",
        "name": "VOICE_CHANGER_PRESET",
        "description": "Local voice changer options.",
        "parameters": [
            {
                "VOICE_CHANGER_OFF": "The original voice (no local voice change)."
            },
            {
                "VOICE_CHANGER_OLDMAN": "The voice of an old man."
            },
            {
                "VOICE_CHANGER_BABYBOY": "The voice of a little boy."
            },
            {
                "VOICE_CHANGER_BABYGIRL": "The voice of a little girl."
            },
            {
                "VOICE_CHANGER_ZHUBAJIE": "The voice of Zhu Bajie, a character in Journey to the West who has a voice like that of a growling bear."
            },
            {
                "VOICE_CHANGER_ETHEREAL": "The ethereal voice."
            },
            {
                "VOICE_CHANGER_HULK": "The voice of Hulk."
            },
            {
                "VOICE_BEAUTY_VIGOROUS": "A more vigorous voice."
            },
            {
                "VOICE_BEAUTY_DEEP": "A deeper voice."
            },
            {
                "VOICE_BEAUTY_MELLOW": "A mellower voice."
            },
            {
                "VOICE_BEAUTY_FALSETTO": "Falsetto."
            },
            {
                "VOICE_BEAUTY_FULL": "A fuller voice."
            },
            {
                "VOICE_BEAUTY_CLEAR": "A clearer voice."
            },
            {
                "VOICE_BEAUTY_RESOUNDING": "A more resounding voice."
            },
            {
                "VOICE_BEAUTY_RINGING": "A more ringing voice."
            },
            {
                "VOICE_BEAUTY_SPACIAL": "A more spatially resonant voice."
            },
            {
                "GENERAL_BEAUTY_VOICE_MALE_MAGNETIC": "(For male only) A more magnetic voice. Do not use it when the speaker is a female; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_FRESH": "(For female only) A fresher voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            },
            {
                "GENERAL_BEAUTY_VOICE_FEMALE_VITALITY": "(For female only) A more vital voice. Do not use it when the speaker is a male; otherwise, voice distortion occurs."
            }
        ],
        "returns": ""
    },
    {
        "id": "enum_voice_conversion_preset",
        "name": "VOICE_CONVERSION_PRESET",
        "description": "The options for SDK preset voice conversion effects.Since\n                    v3.3.1",
        "parameters": [
            {
                "VOICE_CONVERSION_OFF": "Turn off voice conversion effects and use the original voice."
            },
            {
                "VOICE_CHANGER_NEUTRAL": "A gender-neutral voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "VOICE_CHANGER_SWEET": "A sweet voice. To avoid audio distortion, ensure that you use this enumerator to process a female-sounding voice."
            },
            {
                "VOICE_CHANGER_SOLID": "A steady voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            },
            {
                "VOICE_CHANGER_BASS": "A deep voice. To avoid audio distortion, ensure that you use this enumerator to process a male-sounding voice."
            }
        ],
        "returns": ""
    }
]